{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "posted-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "import or_suite\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-score",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fifty-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'Random'\n",
    "problem = 'default'\n",
    "dir_path = '../data/allocation_%s_%s'%(algorithm,problem)\n",
    "dir_path = dir_path+'/trajectory.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hawaiian-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/allocation_Random_default/traj.obj\n"
     ]
    }
   ],
   "source": [
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infinite-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_path, 'rb') as f:\n",
    "    x = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specialized-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'iter': 0,\n",
       "  'episode': 1,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[82.98765  , 29.853357 ],\n",
       "         [ 2.5732195, 46.680195 ],\n",
       "         [46.33792  , 70.02638  ]], dtype=float32),\n",
       "  'reward': 4.1063101390097545,\n",
       "  'newState': (array([-31.89878845, -46.55993652]), array([37, 43, 12])),\n",
       "  'info': {'type': array([37, 43, 12])}},\n",
       " {'iter': 0,\n",
       "  'episode': 1,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-31.89878845, -46.55993652]), array([37, 43, 12])),\n",
       "  'action': array([[-23.697594  , -25.98542   ],\n",
       "         [-28.32305   ,  -4.221448  ],\n",
       "         [ -0.70971596,  -1.3844278 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 20.83157349, -14.96864128]), array([ 8,  9, 11])),\n",
       "  'info': {'type': array([ 8,  9, 11])}},\n",
       " {'iter': 0,\n",
       "  'episode': 1,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 20.83157349, -14.96864128]), array([ 8,  9, 11])),\n",
       "  'action': array([[ 1.8607888, 13.78018  ],\n",
       "         [ 6.518222 , 15.275486 ],\n",
       "         [ 7.5723186,  8.840684 ]], dtype=float32),\n",
       "  'reward': 2.1529664379849134,\n",
       "  'newState': (array([  4.8802433 , -52.86499214]), array([ 5, 15,  0])),\n",
       "  'info': {'type': array([ 5, 15,  0])}},\n",
       " {'iter': 0,\n",
       "  'episode': 2,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.8150532, 3.4030101],\n",
       "         [3.649585 , 4.760087 ],\n",
       "         [2.9076123, 3.0068479]], dtype=float32),\n",
       "  'reward': 1.2248579569798406,\n",
       "  'newState': (array([91.62774944, 88.83005524]), array([16,  1, 12])),\n",
       "  'info': {'type': array([16,  1, 12])}},\n",
       " {'iter': 0,\n",
       "  'episode': 2,\n",
       "  'step': 1,\n",
       "  'oldState': (array([91.62774944, 88.83005524]), array([16,  1, 12])),\n",
       "  'action': array([[57.4642   , 31.966078 ],\n",
       "         [25.721403 ,  2.2637107],\n",
       "         [25.49781  , 69.61651  ]], dtype=float32),\n",
       "  'reward': 4.148157025603151,\n",
       "  'newState': (array([-17.0556612 , -15.01624298]), array([ 7, 45,  6])),\n",
       "  'info': {'type': array([ 7, 45,  6])}},\n",
       " {'iter': 0,\n",
       "  'episode': 2,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-17.0556612 , -15.01624298]), array([ 7, 45,  6])),\n",
       "  'action': array([[ -3.0573056,  -6.631837 ],\n",
       "         [ -9.008841 , -10.303631 ],\n",
       "         [-14.490932 ,  -9.687466 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 9.50141811, 11.60668945]), array([25, 20, 37])),\n",
       "  'info': {'type': array([25, 20, 37])}},\n",
       " {'iter': 0,\n",
       "  'episode': 3,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[9.410356  , 0.03753159],\n",
       "         [4.592163  , 7.612469  ],\n",
       "         [4.9764376 , 2.2824972 ]], dtype=float32),\n",
       "  'reward': 2.103557732104823,\n",
       "  'newState': (array([81.02104378, 90.06750202]), array([18, 20, 11])),\n",
       "  'info': {'type': array([18, 20, 11])}},\n",
       " {'iter': 0,\n",
       "  'episode': 3,\n",
       "  'step': 1,\n",
       "  'oldState': (array([81.02104378, 90.06750202]), array([18, 20, 11])),\n",
       "  'action': array([[23.452173, 77.10139 ],\n",
       "         [49.749523, 25.172134],\n",
       "         [87.66989 , 28.824678]], dtype=float32),\n",
       "  'reward': 3.54368123159686,\n",
       "  'newState': (array([-79.85053825, -41.03070354]), array([42, 28, 29])),\n",
       "  'info': {'type': array([42, 28, 29])}},\n",
       " {'iter': 0,\n",
       "  'episode': 3,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-79.85053825, -41.03070354]), array([42, 28, 29])),\n",
       "  'action': array([[ -4.8728456, -40.57163  ],\n",
       "         [-11.065798 , -15.576452 ],\n",
       "         [-15.198616 ,  -5.675591 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-48.71327782,  20.79296589]), array([14,  4, 23])),\n",
       "  'info': {'type': array([14,  4, 23])}},\n",
       " {'iter': 0,\n",
       "  'episode': 4,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 0.4221245 , 19.483805  ],\n",
       "         [11.781058  ,  0.49284023],\n",
       "         [ 4.617752  , 11.438845  ]], dtype=float32),\n",
       "  'reward': -0.5536918253897372,\n",
       "  'newState': (array([83.1790657, 68.5845108]), array([23, 41, 49])),\n",
       "  'info': {'type': array([23, 41, 49])}},\n",
       " {'iter': 0,\n",
       "  'episode': 4,\n",
       "  'step': 1,\n",
       "  'oldState': (array([83.1790657, 68.5845108]), array([23, 41, 49])),\n",
       "  'action': array([[64.84555 , 66.311584],\n",
       "         [64.30713 , 75.15567 ],\n",
       "         [52.42814 , 57.35491 ]], dtype=float32),\n",
       "  'reward': 4.453849702216353,\n",
       "  'newState': (array([ -98.40174484, -130.23766327]), array([30, 32, 22])),\n",
       "  'info': {'type': array([30, 32, 22])}},\n",
       " {'iter': 0,\n",
       "  'episode': 4,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -98.40174484, -130.23766327]), array([30, 32, 22])),\n",
       "  'action': array([[-46.801617, -47.019707],\n",
       "         [-50.663128,  -8.778737],\n",
       "         [-93.18196 , -18.824171]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 92.24495316, -55.61505127]), array([13, 41,  9])),\n",
       "  'info': {'type': array([13, 41,  9])}},\n",
       " {'iter': 0,\n",
       "  'episode': 5,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[29.59871 , 57.36859 ],\n",
       "         [18.284025, 83.13979 ],\n",
       "         [ 4.546613, 62.060616]], dtype=float32),\n",
       "  'reward': 4.033868838238261,\n",
       "  'newState': (array([  47.57065201, -102.56900024]), array([ 7, 22,  1])),\n",
       "  'info': {'type': array([ 7, 22,  1])}},\n",
       " {'iter': 0,\n",
       "  'episode': 5,\n",
       "  'step': 1,\n",
       "  'oldState': (array([  47.57065201, -102.56900024]), array([ 7, 22,  1])),\n",
       "  'action': array([[28.560175, 24.205112],\n",
       "         [34.923874, 23.12687 ],\n",
       "         [46.30266 , 18.813585]], dtype=float32),\n",
       "  'reward': 3.224738645374344,\n",
       "  'newState': (array([ -62.21606064, -168.71456909]), array([ 0, 17,  8])),\n",
       "  'info': {'type': array([ 0, 17,  8])}},\n",
       " {'iter': 0,\n",
       "  'episode': 5,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -62.21606064, -168.71456909]), array([ 0, 17,  8])),\n",
       "  'action': array([[-49.797367 , -48.60677  ],\n",
       "         [-48.96223  ,  -3.6794057],\n",
       "         [-29.26696  , -10.998167 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  65.81048965, -105.43022919]), array([24, 13, 47])),\n",
       "  'info': {'type': array([24, 13, 47])}},\n",
       " {'iter': 0,\n",
       "  'episode': 6,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[45.893044, 45.846016],\n",
       "         [ 8.280039, 24.413301],\n",
       "         [38.86282 , 10.623552]], dtype=float32),\n",
       "  'reward': 3.465831844361488,\n",
       "  'newState': (array([ 6.96409607, 19.11713409]), array([42,  8, 30])),\n",
       "  'info': {'type': array([42,  8, 30])}},\n",
       " {'iter': 0,\n",
       "  'episode': 6,\n",
       "  'step': 1,\n",
       "  'oldState': (array([ 6.96409607, 19.11713409]), array([42,  8, 30])),\n",
       "  'action': array([[13.287513  ,  3.9446523 ],\n",
       "         [ 3.7872257 ,  8.015809  ],\n",
       "         [ 4.0213118 ,  0.34817728]], dtype=float32),\n",
       "  'reward': 2.119216822261624,\n",
       "  'newState': (array([-14.13195419,   6.80849552]), array([7, 3, 6])),\n",
       "  'info': {'type': array([7, 3, 6])}},\n",
       " {'iter': 0,\n",
       "  'episode': 6,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-14.13195419,   6.80849552]), array([7, 3, 6])),\n",
       "  'action': array([[3.5496297, 4.902798 ],\n",
       "         [6.40094  , 6.333856 ],\n",
       "         [0.8841369, 6.3308764]], dtype=float32),\n",
       "  'reward': 1.6414134293465286,\n",
       "  'newState': (array([-24.9666605 , -10.75903606]), array([21, 49,  3])),\n",
       "  'info': {'type': array([21, 49,  3])}},\n",
       " {'iter': 0,\n",
       "  'episode': 7,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.8164794, -9.689528 ],\n",
       "         [-6.848177 , -5.836297 ],\n",
       "         [-8.065507 , -7.4939184]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([117.73016357, 123.01974487]), array([ 4, 24, 49])),\n",
       "  'info': {'type': array([ 4, 24, 49])}},\n",
       " {'iter': 0,\n",
       "  'episode': 7,\n",
       "  'step': 1,\n",
       "  'oldState': (array([117.73016357, 123.01974487]), array([ 4, 24, 49])),\n",
       "  'action': array([[ 27.742714,  39.85216 ],\n",
       "         [117.526985,  75.144356],\n",
       "         [ 64.16224 , 113.62164 ]], dtype=float32),\n",
       "  'reward': 4.815657426650259,\n",
       "  'newState': (array([ -91.70178223, -105.59841919]), array([43, 12, 26])),\n",
       "  'info': {'type': array([43, 12, 26])}},\n",
       " {'iter': 0,\n",
       "  'episode': 7,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -91.70178223, -105.59841919]), array([43, 12, 26])),\n",
       "  'action': array([[-17.472645, -58.218422],\n",
       "         [-53.418648, -86.843605],\n",
       "         [-79.19063 , -70.07897 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 58.38014221, 109.54257202]), array([16, 45, 41])),\n",
       "  'info': {'type': array([16, 45, 41])}},\n",
       " {'iter': 0,\n",
       "  'episode': 8,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[46.307987, 14.868171],\n",
       "         [95.211174, 10.322009],\n",
       "         [25.91945 , 62.56428 ]], dtype=float32),\n",
       "  'reward': 3.0062517041041232,\n",
       "  'newState': (array([-67.43861389,  12.2455368 ]), array([18, 15,  0])),\n",
       "  'info': {'type': array([18, 15,  0])}},\n",
       " {'iter': 0,\n",
       "  'episode': 8,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-67.43861389,  12.2455368 ]), array([18, 15,  0])),\n",
       "  'action': array([[8.609113 , 8.774753 ],\n",
       "         [6.621794 , 1.7292459],\n",
       "         [9.038755 , 9.313205 ]], dtype=float32),\n",
       "  'reward': 1.4232140608775543,\n",
       "  'newState': (array([-91.70827675,  -7.57166672]), array([ 4, 25, 47])),\n",
       "  'info': {'type': array([ 4, 25, 47])}},\n",
       " {'iter': 0,\n",
       "  'episode': 8,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-91.70827675,  -7.57166672]), array([ 4, 25, 47])),\n",
       "  'action': array([[-6.155824 , -5.0794272],\n",
       "         [-4.8986497, -0.1475851],\n",
       "         [-2.4745703, -2.7839592]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-78.1792326 ,   0.43930435]), array([34, 23,  7])),\n",
       "  'info': {'type': array([34, 23,  7])}},\n",
       " {'iter': 0,\n",
       "  'episode': 9,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.12503985, 0.00079581],\n",
       "         [0.27507275, 0.12527864],\n",
       "         [0.11408067, 0.14050938]], dtype=float32),\n",
       "  'reward': -2.0351868022119253,\n",
       "  'newState': (array([99.4858067 , 99.73341617]), array([26, 25, 40])),\n",
       "  'info': {'type': array([26, 25, 40])}},\n",
       " {'iter': 0,\n",
       "  'episode': 9,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.4858067 , 99.73341617]), array([26, 25, 40])),\n",
       "  'action': array([[18.204405, 34.914783],\n",
       "         [31.463345, 54.336422],\n",
       "         [16.759287, 16.888292]], dtype=float32),\n",
       "  'reward': 3.4720963376163283,\n",
       "  'newState': (array([33.05877423, -6.40607968]), array([22,  9,  3])),\n",
       "  'info': {'type': array([22,  9,  3])}},\n",
       " {'iter': 0,\n",
       "  'episode': 9,\n",
       "  'step': 2,\n",
       "  'oldState': (array([33.05877423, -6.40607968]), array([22,  9,  3])),\n",
       "  'action': array([[33.0129    ,  1.6868044 ],\n",
       "         [ 6.1557565 , 24.85811   ],\n",
       "         [13.819138  ,  0.44609973]], dtype=float32),\n",
       "  'reward': 3.3477617374541047,\n",
       "  'newState': (array([-19.92902255, -33.39709416]), array([39, 23, 36])),\n",
       "  'info': {'type': array([39, 23, 36])}},\n",
       " {'iter': 0,\n",
       "  'episode': 10,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -7.5630236, -16.67861  ],\n",
       "         [-15.144014 ,  -7.499325 ],\n",
       "         [-10.115751 ,  -1.6246233]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([132.82279205, 125.8025589 ]), array([27, 37, 19])),\n",
       "  'info': {'type': array([27, 37, 19])}},\n",
       " {'iter': 0,\n",
       "  'episode': 10,\n",
       "  'step': 1,\n",
       "  'oldState': (array([132.82279205, 125.8025589 ]), array([27, 37, 19])),\n",
       "  'action': array([[46.22358 , 96.35545 ],\n",
       "         [22.260408, 65.58684 ],\n",
       "         [47.247704, 24.221727]], dtype=float32),\n",
       "  'reward': 4.089219686116851,\n",
       "  'newState': (array([ 17.0911026 , -60.36145782]), array([38,  8, 32])),\n",
       "  'info': {'type': array([38,  8, 32])}},\n",
       " {'iter': 0,\n",
       "  'episode': 10,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 17.0911026 , -60.36145782]), array([38,  8, 32])),\n",
       "  'action': array([[16.154037 ,  2.4811368],\n",
       "         [ 7.299116 , 14.076935 ],\n",
       "         [ 1.3804181, 14.528056 ]], dtype=float32),\n",
       "  'reward': 2.7617695337926356,\n",
       "  'newState': (array([ -7.74246979, -91.44758606]), array([34, 10, 23])),\n",
       "  'info': {'type': array([34, 10, 23])}},\n",
       " {'iter': 0,\n",
       "  'episode': 11,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-6.3507233 , -3.4173446 ],\n",
       "         [-5.994871  , -0.90465564],\n",
       "         [-4.974553  , -6.02061   ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([117.32014847, 110.34260941]), array([15, 47, 23])),\n",
       "  'info': {'type': array([15, 47, 23])}},\n",
       " {'iter': 0,\n",
       "  'episode': 11,\n",
       "  'step': 1,\n",
       "  'oldState': (array([117.32014847, 110.34260941]), array([15, 47, 23])),\n",
       "  'action': array([[109.427864  ,  58.177746  ],\n",
       "         [ 49.075836  ,  98.89875   ],\n",
       "         [  0.50298256,  71.69851   ]], dtype=float32),\n",
       "  'reward': 4.526813175773189,\n",
       "  'newState': (array([ -41.68651962, -118.43238449]), array([25,  7, 28])),\n",
       "  'info': {'type': array([25,  7, 28])}},\n",
       " {'iter': 0,\n",
       "  'episode': 11,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -41.68651962, -118.43238449]), array([25,  7, 28])),\n",
       "  'action': array([[-23.572622  , -18.65375   ],\n",
       "         [-32.293274  , -21.579308  ],\n",
       "         [ -0.64652115, -20.46726   ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 14.82590103, -57.73206711]), array([10, 46, 32])),\n",
       "  'info': {'type': array([10, 46, 32])}},\n",
       " {'iter': 0,\n",
       "  'episode': 12,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 8.032537 ,  7.841991 ],\n",
       "         [ 9.736534 , 12.081401 ],\n",
       "         [ 4.419816 ,  7.7088313]], dtype=float32),\n",
       "  'reward': 2.3443721514671862,\n",
       "  'newState': (array([77.81111145, 72.36777687]), array([24, 23,  1])),\n",
       "  'info': {'type': array([24, 23,  1])}},\n",
       " {'iter': 0,\n",
       "  'episode': 12,\n",
       "  'step': 1,\n",
       "  'oldState': (array([77.81111145, 72.36777687]), array([24, 23,  1])),\n",
       "  'action': array([[24.743933, 51.326782],\n",
       "         [63.574318, 19.779543],\n",
       "         [21.459297, 58.247486]], dtype=float32),\n",
       "  'reward': 3.1256498187476254,\n",
       "  'newState': (array([-31.96643829, -56.98602867]), array([49, 13,  3])),\n",
       "  'info': {'type': array([49, 13,  3])}},\n",
       " {'iter': 0,\n",
       "  'episode': 12,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-31.96643829, -56.98602867]), array([49, 13,  3])),\n",
       "  'action': array([[-30.021786 , -18.821894 ],\n",
       "         [-17.031818 ,  -9.934508 ],\n",
       "         [-13.7041025, -29.804228 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([28.7912674 ,  1.57460213]), array([ 0, 13,  6])),\n",
       "  'info': {'type': array([ 0, 13,  6])}},\n",
       " {'iter': 0,\n",
       "  'episode': 13,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 3.7028391 , 16.51907   ],\n",
       "         [ 5.6153097 ,  9.937926  ],\n",
       "         [ 0.62295574, 25.530304  ]], dtype=float32),\n",
       "  'reward': 1.9978080365615771,\n",
       "  'newState': (array([90.05889606, 48.01269913]), array([21,  6,  2])),\n",
       "  'info': {'type': array([21,  6,  2])}},\n",
       " {'iter': 0,\n",
       "  'episode': 13,\n",
       "  'step': 1,\n",
       "  'oldState': (array([90.05889606, 48.01269913]), array([21,  6,  2])),\n",
       "  'action': array([[40.847767, 25.990627],\n",
       "         [34.573334,  5.147613],\n",
       "         [16.92687 , 80.272736]], dtype=float32),\n",
       "  'reward': 3.3410905953369507,\n",
       "  'newState': (array([ -2.28907299, -63.3982811 ]), array([12, 27, 21])),\n",
       "  'info': {'type': array([12, 27, 21])}},\n",
       " {'iter': 0,\n",
       "  'episode': 13,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -2.28907299, -63.3982811 ]), array([12, 27, 21])),\n",
       "  'action': array([[-0.9688366 , -1.5238646 ],\n",
       "         [-1.7038962 , -0.6158325 ],\n",
       "         [-0.44781193, -0.8125919 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  0.83147168, -60.44599199]), array([11,  7, 13])),\n",
       "  'info': {'type': array([11,  7, 13])}},\n",
       " {'iter': 0,\n",
       "  'episode': 14,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.06932234, 0.6586406 ],\n",
       "         [0.03076001, 0.11958252],\n",
       "         [0.54931086, 0.20433183]], dtype=float32),\n",
       "  'reward': -2.20992481340077,\n",
       "  'newState': (array([99.3506068 , 99.01744503]), array([ 8, 11, 12])),\n",
       "  'info': {'type': array([ 8, 11, 12])}},\n",
       " {'iter': 0,\n",
       "  'episode': 14,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.3506068 , 99.01744503]), array([ 8, 11, 12])),\n",
       "  'action': array([[96.192406, 30.516243],\n",
       "         [13.35418 , 78.75109 ],\n",
       "         [15.813344, 90.57974 ]], dtype=float32),\n",
       "  'reward': 4.534377545603846,\n",
       "  'newState': (array([ -26.00932515, -100.82963139]), array([43, 20, 30])),\n",
       "  'info': {'type': array([43, 20, 30])}},\n",
       " {'iter': 0,\n",
       "  'episode': 14,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -26.00932515, -100.82963139]), array([43, 20, 30])),\n",
       "  'action': array([[ -7.7893076, -25.81575  ],\n",
       "         [ -5.0615835,  -4.238629 ],\n",
       "         [ -2.8132906,  -4.1216426]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-10.34514344, -66.65360981]), array([36, 39,  7])),\n",
       "  'info': {'type': array([36, 39,  7])}},\n",
       " {'iter': 0,\n",
       "  'episode': 15,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-8.873631 , -1.5742956],\n",
       "         [-7.3626485, -5.5631833],\n",
       "         [-9.289053 , -2.4285614]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([125.5253315 , 109.56604004]), array([45,  4, 48])),\n",
       "  'info': {'type': array([45,  4, 48])}},\n",
       " {'iter': 0,\n",
       "  'episode': 15,\n",
       "  'step': 1,\n",
       "  'oldState': (array([125.5253315 , 109.56604004]), array([45,  4, 48])),\n",
       "  'action': array([[87.59738 , 26.975721],\n",
       "         [60.612076, 75.43476 ],\n",
       "         [19.136026, 36.993763]], dtype=float32),\n",
       "  'reward': 4.246338897212946,\n",
       "  'newState': (array([-41.820158  , -29.83821106]), array([18, 32, 13])),\n",
       "  'info': {'type': array([18, 32, 13])}},\n",
       " {'iter': 0,\n",
       "  'episode': 15,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-41.820158  , -29.83821106]), array([18, 32, 13])),\n",
       "  'action': array([[ -5.4721403, -24.726435 ],\n",
       "         [-10.76324  ,  -7.280213 ],\n",
       "         [-14.604725 , -16.24098  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-10.98005295,  18.4094162 ]), array([10, 23, 17])),\n",
       "  'info': {'type': array([10, 23, 17])}},\n",
       " {'iter': 0,\n",
       "  'episode': 16,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 1.8188547, 15.103818 ],\n",
       "         [12.721414 , 13.777081 ],\n",
       "         [ 0.8354049,  9.629593 ]], dtype=float32),\n",
       "  'reward': 1.874586714880674,\n",
       "  'newState': (array([84.62432671, 61.48950958]), array([ 7, 24, 10])),\n",
       "  'info': {'type': array([ 7, 24, 10])}},\n",
       " {'iter': 0,\n",
       "  'episode': 16,\n",
       "  'step': 1,\n",
       "  'oldState': (array([84.62432671, 61.48950958]), array([ 7, 24, 10])),\n",
       "  'action': array([[36.622456, 73.75564 ],\n",
       "         [56.357056, 30.78904 ],\n",
       "         [12.851748, 32.347393]], dtype=float32),\n",
       "  'reward': 3.5504200625114244,\n",
       "  'newState': (array([-21.20692635, -75.402565  ]), array([28, 20, 32])),\n",
       "  'info': {'type': array([28, 20, 32])}},\n",
       " {'iter': 0,\n",
       "  'episode': 16,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-21.20692635, -75.402565  ]), array([28, 20, 32])),\n",
       "  'action': array([[ -0.8413882,  -0.6130182],\n",
       "         [-13.491168 ,  -7.647228 ],\n",
       "         [-15.312434 , -14.756844 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  8.43806267, -52.38547516]), array([12,  1, 30])),\n",
       "  'info': {'type': array([12,  1, 30])}},\n",
       " {'iter': 0,\n",
       "  'episode': 17,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.4350802, 2.3813708],\n",
       "         [0.9498735, 4.520049 ],\n",
       "         [1.4449034, 2.2562761]], dtype=float32),\n",
       "  'reward': 0.6504290114823088,\n",
       "  'newState': (array([97.17014289, 90.84230423]), array([41, 24, 18])),\n",
       "  'info': {'type': array([41, 24, 18])}},\n",
       " {'iter': 0,\n",
       "  'episode': 17,\n",
       "  'step': 1,\n",
       "  'oldState': (array([97.17014289, 90.84230423]), array([41, 24, 18])),\n",
       "  'action': array([[39.014065 , 30.539904 ],\n",
       "         [47.922234 , 12.258195 ],\n",
       "         [88.474915 , 10.4670105]], dtype=float32),\n",
       "  'reward': 3.5309768492521,\n",
       "  'newState': (array([-78.24106622,  37.57719421]), array([33,  2, 44])),\n",
       "  'info': {'type': array([33,  2, 44])}},\n",
       " {'iter': 0,\n",
       "  'episode': 17,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-78.24106622,  37.57719421]), array([33,  2, 44])),\n",
       "  'action': array([[10.749351 , 13.201168 ],\n",
       "         [ 1.6675509, 17.778368 ],\n",
       "         [34.4103   , 11.599808 ]], dtype=float32),\n",
       "  'reward': 3.1974145678381287,\n",
       "  'newState': (array([-125.06826806,   -5.00215149]), array([28, 39, 34])),\n",
       "  'info': {'type': array([28, 39, 34])}},\n",
       " {'iter': 0,\n",
       "  'episode': 18,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.519804  , -0.7849289 ],\n",
       "         [-0.6245856 , -0.2193976 ],\n",
       "         [-0.08897199, -2.4360416 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([103.23336172, 103.44036818]), array([10, 32, 41])),\n",
       "  'info': {'type': array([10, 32, 41])}},\n",
       " {'iter': 0,\n",
       "  'episode': 18,\n",
       "  'step': 1,\n",
       "  'oldState': (array([103.23336172, 103.44036818]), array([10, 32, 41])),\n",
       "  'action': array([[65.08193 , 80.253395],\n",
       "         [33.17931 , 58.493866],\n",
       "         [34.341133, 67.73831 ]], dtype=float32),\n",
       "  'reward': 4.356840685896166,\n",
       "  'newState': (array([ -29.36902475, -103.04519701]), array([18, 22,  6])),\n",
       "  'info': {'type': array([18, 22,  6])}},\n",
       " {'iter': 0,\n",
       "  'episode': 18,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -29.36902475, -103.04519701]), array([18, 22,  6])),\n",
       "  'action': array([[-16.139143, -20.47519 ],\n",
       "         [-14.121626, -18.065825],\n",
       "         [-17.11578 , -28.032673]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 18.00752401, -36.47151232]), array([ 2,  7, 39])),\n",
       "  'info': {'type': array([ 2,  7, 39])}},\n",
       " {'iter': 0,\n",
       "  'episode': 19,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[17.649174 ,  0.8739534],\n",
       "         [ 9.421413 , 17.582556 ],\n",
       "         [ 2.3857856, 10.075006 ]], dtype=float32),\n",
       "  'reward': 2.8475319591188963,\n",
       "  'newState': (array([70.54362679, 71.46848679]), array([48, 15,  5])),\n",
       "  'info': {'type': array([48, 15,  5])}},\n",
       " {'iter': 0,\n",
       "  'episode': 19,\n",
       "  'step': 1,\n",
       "  'oldState': (array([70.54362679, 71.46848679]), array([48, 15,  5])),\n",
       "  'action': array([[44.497387, 57.30748 ],\n",
       "         [48.560673, 25.68369 ],\n",
       "         [43.456062, 39.138485]], dtype=float32),\n",
       "  'reward': 3.719679744367993,\n",
       "  'newState': (array([-65.97050285, -50.66116714]), array([17, 42, 20])),\n",
       "  'info': {'type': array([17, 42, 20])}},\n",
       " {'iter': 0,\n",
       "  'episode': 19,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-65.97050285, -50.66116714]), array([17, 42, 20])),\n",
       "  'action': array([[-38.4311  , -36.866104],\n",
       "         [-36.165688, -22.980005],\n",
       "         [ -9.065685, -42.937157]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([17.69197273, 52.12209702]), array([48, 22, 37])),\n",
       "  'info': {'type': array([48, 22, 37])}},\n",
       " {'iter': 0,\n",
       "  'episode': 20,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 0.43765274, 20.71464   ],\n",
       "         [ 3.4064422 , 25.455004  ],\n",
       "         [50.758465  , 27.526882  ]], dtype=float32),\n",
       "  'reward': 1.8359482968328784,\n",
       "  'newState': (array([45.39744186, 26.30347443]), array([13, 49, 33])),\n",
       "  'info': {'type': array([13, 49, 33])}},\n",
       " {'iter': 0,\n",
       "  'episode': 20,\n",
       "  'step': 1,\n",
       "  'oldState': (array([45.39744186, 26.30347443]), array([13, 49, 33])),\n",
       "  'action': array([[ 9.450506, 42.559937],\n",
       "         [13.683888, 12.363269],\n",
       "         [32.906517, 36.666786]], dtype=float32),\n",
       "  'reward': 3.078097082234287,\n",
       "  'newState': (array([-10.64347076, -65.28652191]), array([20, 10, 32])),\n",
       "  'info': {'type': array([20, 10, 32])}},\n",
       " {'iter': 0,\n",
       "  'episode': 20,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-10.64347076, -65.28652191]), array([20, 10, 32])),\n",
       "  'action': array([[-7.867635 , -1.1150706],\n",
       "         [-4.2021117, -5.4317727],\n",
       "         [-4.3178444, -8.48878  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  5.74411964, -50.25089836]), array([25, 21, 39])),\n",
       "  'info': {'type': array([25, 21, 39])}},\n",
       " {'iter': 0,\n",
       "  'episode': 21,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[2.7930152, 0.81078  ],\n",
       "         [1.417026 , 3.7834423],\n",
       "         [4.2064905, 5.100496 ]], dtype=float32),\n",
       "  'reward': 1.2751556963712152,\n",
       "  'newState': (array([91.58346844, 90.30528259]), array([32, 19, 25])),\n",
       "  'info': {'type': array([32, 19, 25])}},\n",
       " {'iter': 0,\n",
       "  'episode': 21,\n",
       "  'step': 1,\n",
       "  'oldState': (array([91.58346844, 90.30528259]), array([32, 19, 25])),\n",
       "  'action': array([[47.521217 , 85.35951  ],\n",
       "         [14.20054  ,  2.0842888],\n",
       "         [85.706474 ,  7.557538 ]], dtype=float32),\n",
       "  'reward': 3.301284548701187,\n",
       "  'newState': (array([-55.84475422,  -4.69606018]), array([49, 14, 13])),\n",
       "  'info': {'type': array([49, 14, 13])}},\n",
       " {'iter': 0,\n",
       "  'episode': 21,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-55.84475422,  -4.69606018]), array([49, 14, 13])),\n",
       "  'action': array([[-4.263601  , -1.57185   ],\n",
       "         [-3.7467794 , -1.669155  ],\n",
       "         [-0.07652883, -2.7880075 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-47.75784588,   1.3329525 ]), array([20, 43,  6])),\n",
       "  'info': {'type': array([20, 43,  6])}},\n",
       " {'iter': 0,\n",
       "  'episode': 22,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.1491288 , 0.8158401 ],\n",
       "         [0.00269861, 0.20832558],\n",
       "         [0.6192065 , 0.5160925 ]], dtype=float32),\n",
       "  'reward': -0.8492861184952241,\n",
       "  'newState': (array([98.228966  , 98.45974183]), array([13, 15, 24])),\n",
       "  'info': {'type': array([13, 15, 24])}},\n",
       " {'iter': 0,\n",
       "  'episode': 22,\n",
       "  'step': 1,\n",
       "  'oldState': (array([98.228966  , 98.45974183]), array([13, 15, 24])),\n",
       "  'action': array([[73.7661  , 33.92226 ],\n",
       "         [42.98608 , 20.908682],\n",
       "         [38.529266, 76.8037  ]], dtype=float32),\n",
       "  'reward': 4.143498410384282,\n",
       "  'newState': (array([-57.05248237, -33.17490172]), array([9, 2, 7])),\n",
       "  'info': {'type': array([9, 2, 7])}},\n",
       " {'iter': 0,\n",
       "  'episode': 22,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-57.05248237, -33.17490172]), array([9, 2, 7])),\n",
       "  'action': array([[-24.758488 , -19.86347  ],\n",
       "         [ -4.238302 ,  -5.0854225],\n",
       "         [-13.937704 ,  -0.8189726]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-14.11798835,  -7.4070375 ]), array([ 5, 36, 37])),\n",
       "  'info': {'type': array([ 5, 36, 37])}},\n",
       " {'iter': 0,\n",
       "  'episode': 23,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-6.494395 , -2.8582242],\n",
       "         [-5.756515 , -0.7406833],\n",
       "         [-0.9717939, -0.6117863]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([113.22270393, 104.21069384]), array([21, 40, 13])),\n",
       "  'info': {'type': array([21, 40, 13])}},\n",
       " {'iter': 0,\n",
       "  'episode': 23,\n",
       "  'step': 1,\n",
       "  'oldState': (array([113.22270393, 104.21069384]), array([21, 40, 13])),\n",
       "  'action': array([[31.4138  , 85.86298 ],\n",
       "         [75.079704, 71.47377 ],\n",
       "         [34.984272, 13.253504]], dtype=float32),\n",
       "  'reward': 3.9669630482777407,\n",
       "  'newState': (array([-28.25506401, -66.37957716]), array([27, 49, 49])),\n",
       "  'info': {'type': array([27, 49, 49])}},\n",
       " {'iter': 0,\n",
       "  'episode': 23,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-28.25506401, -66.37957716]), array([27, 49, 49])),\n",
       "  'action': array([[-26.134901  , -27.097893  ],\n",
       "         [ -9.79439   , -14.508231  ],\n",
       "         [-16.937721  ,  -0.27138272]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 24.61194801, -24.5020709 ]), array([47, 13, 40])),\n",
       "  'info': {'type': array([47, 13, 40])}},\n",
       " {'iter': 0,\n",
       "  'episode': 24,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 2.8069994,  7.503032 ],\n",
       "         [ 9.709256 , 16.499245 ],\n",
       "         [18.886936 ,  4.897367 ]], dtype=float32),\n",
       "  'reward': 2.18515317015572,\n",
       "  'newState': (array([68.59680939, 71.10035515]), array([14, 45, 23])),\n",
       "  'info': {'type': array([14, 45, 23])}},\n",
       " {'iter': 0,\n",
       "  'episode': 24,\n",
       "  'step': 1,\n",
       "  'oldState': (array([68.59680939, 71.10035515]), array([14, 45, 23])),\n",
       "  'action': array([[35.599384 ,  5.7118816],\n",
       "         [43.60234  , 30.109499 ],\n",
       "         [14.749531 , 66.27255  ]], dtype=float32),\n",
       "  'reward': 3.7110857156628896,\n",
       "  'newState': (array([-25.35443878, -30.99357796]), array([16, 28, 42])),\n",
       "  'info': {'type': array([16, 28, 42])}},\n",
       " {'iter': 0,\n",
       "  'episode': 24,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-25.35443878, -30.99357796]), array([16, 28, 42])),\n",
       "  'action': array([[ -0.23414823, -10.35838   ],\n",
       "         [ -3.8199472 , -12.962183  ],\n",
       "         [ -2.128663  , -24.874367  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-19.17168045,  17.20135307]), array([45,  3,  2])),\n",
       "  'info': {'type': array([45,  3,  2])}},\n",
       " {'iter': 0,\n",
       "  'episode': 25,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 3.128464  , 10.299497  ],\n",
       "         [ 9.571423  ,  0.11487232],\n",
       "         [15.423733  , 10.271051  ]], dtype=float32),\n",
       "  'reward': -0.6436280519705418,\n",
       "  'newState': (array([71.87638092, 79.31457901]), array([14, 46,  0])),\n",
       "  'info': {'type': array([14, 46,  0])}},\n",
       " {'iter': 0,\n",
       "  'episode': 25,\n",
       "  'step': 1,\n",
       "  'oldState': (array([71.87638092, 79.31457901]), array([14, 46,  0])),\n",
       "  'action': array([[ 1.3218992, 58.195946 ],\n",
       "         [24.664845 , 16.103119 ],\n",
       "         [18.886206 , 60.785427 ]], dtype=float32),\n",
       "  'reward': 2.195692823153136,\n",
       "  'newState': (array([ 27.00343323, -55.76990891]), array([29, 11, 35])),\n",
       "  'info': {'type': array([29, 11, 35])}},\n",
       " {'iter': 0,\n",
       "  'episode': 25,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 27.00343323, -55.76990891]), array([29, 11, 35])),\n",
       "  'action': array([[12.804771 ,  5.9382057],\n",
       "         [21.604609 , 21.094507 ],\n",
       "         [24.47986  ,  6.675923 ]], dtype=float32),\n",
       "  'reward': 3.0379847155486726,\n",
       "  'newState': (array([-31.88580322, -89.47854614]), array([29, 33,  2])),\n",
       "  'info': {'type': array([29, 33,  2])}},\n",
       " {'iter': 0,\n",
       "  'episode': 26,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-13.076909 , -25.633738 ],\n",
       "         [-12.760157 ,  -7.178741 ],\n",
       "         [-11.081455 , -12.1938305]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([136.91852188, 145.00630951]), array([20, 19, 48])),\n",
       "  'info': {'type': array([20, 19, 48])}},\n",
       " {'iter': 0,\n",
       "  'episode': 26,\n",
       "  'step': 1,\n",
       "  'oldState': (array([136.91852188, 145.00630951]), array([20, 19, 48])),\n",
       "  'action': array([[133.11514 , 109.38514 ],\n",
       "         [ 83.19433 ,  97.74935 ],\n",
       "         [ 14.636297, 118.15047 ]], dtype=float32),\n",
       "  'reward': 4.82241096099597,\n",
       "  'newState': (array([ -94.02724838, -180.27866364]), array([32, 28, 18])),\n",
       "  'info': {'type': array([32, 28, 18])}},\n",
       " {'iter': 0,\n",
       "  'episode': 26,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -94.02724838, -180.27866364]), array([32, 28, 18])),\n",
       "  'action': array([[ -5.2409925, -77.003586 ],\n",
       "         [-79.2984   , -80.517235 ],\n",
       "         [ -7.3222632, -19.594215 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-2.16559219, -3.16364288]), array([31, 28, 30])),\n",
       "  'info': {'type': array([31, 28, 30])}},\n",
       " {'iter': 0,\n",
       "  'episode': 27,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.02225952, -1.6289766 ],\n",
       "         [-0.79388523, -0.7639616 ],\n",
       "         [-0.82375103, -1.1613829 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([101.6398958 , 103.55432105]), array([10,  8, 45])),\n",
       "  'info': {'type': array([10,  8, 45])}},\n",
       " {'iter': 0,\n",
       "  'episode': 27,\n",
       "  'step': 1,\n",
       "  'oldState': (array([101.6398958 , 103.55432105]), array([10,  8, 45])),\n",
       "  'action': array([[28.777826, 66.458725],\n",
       "         [90.41546 , 69.09304 ],\n",
       "         [18.333511, 27.140072]], dtype=float32),\n",
       "  'reward': 3.7976286408756676,\n",
       "  'newState': (array([-35.88689864, -59.13751245]), array([35, 32,  8])),\n",
       "  'info': {'type': array([35, 32,  8])}},\n",
       " {'iter': 0,\n",
       "  'episode': 27,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-35.88689864, -59.13751245]), array([35, 32,  8])),\n",
       "  'action': array([[-15.089553 , -10.196504 ],\n",
       "         [ -3.9488719, -34.209583 ],\n",
       "         [-29.537247 , -11.094844 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([12.68877351, -3.63658166]), array([20, 13, 15])),\n",
       "  'info': {'type': array([20, 13, 15])}},\n",
       " {'iter': 0,\n",
       "  'episode': 28,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[4.8465595, 2.3481889],\n",
       "         [8.963231 , 5.8454866],\n",
       "         [0.7229051, 9.631537 ]], dtype=float32),\n",
       "  'reward': 1.7323771488340594,\n",
       "  'newState': (array([85.46730423, 82.17478561]), array([41,  0, 44])),\n",
       "  'info': {'type': array([41,  0, 44])}},\n",
       " {'iter': 0,\n",
       "  'episode': 28,\n",
       "  'step': 1,\n",
       "  'oldState': (array([85.46730423, 82.17478561]), array([41,  0, 44])),\n",
       "  'action': array([[ 6.0448904, 50.165016 ],\n",
       "         [84.43263  , 68.38922  ],\n",
       "         [ 4.0331435, 39.888775 ]], dtype=float32),\n",
       "  'reward': 2.8258110638667486,\n",
       "  'newState': (array([ -9.04336166, -76.26822281]), array([19, 24, 49])),\n",
       "  'info': {'type': array([19, 24, 49])}},\n",
       " {'iter': 0,\n",
       "  'episode': 28,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -9.04336166, -76.26822281]), array([19, 24, 49])),\n",
       "  'action': array([[-7.8494163 , -6.79346   ],\n",
       "         [-0.6289748 , -0.48100057],\n",
       "         [-5.7145653 , -5.277163  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  5.14959431, -63.71659946]), array([42, 20, 44])),\n",
       "  'info': {'type': array([42, 20, 44])}},\n",
       " {'iter': 0,\n",
       "  'episode': 29,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.15479508, 2.3742952 ],\n",
       "         [4.612398  , 5.1344833 ],\n",
       "         [0.96995914, 2.3955514 ]], dtype=float32),\n",
       "  'reward': 0.3448832306656461,\n",
       "  'newState': (array([94.26284742, 90.09566975]), array([15, 30, 27])),\n",
       "  'info': {'type': array([15, 30, 27])}},\n",
       " {'iter': 0,\n",
       "  'episode': 29,\n",
       "  'step': 1,\n",
       "  'oldState': (array([94.26284742, 90.09566975]), array([15, 30, 27])),\n",
       "  'action': array([[84.627785, 93.90267 ],\n",
       "         [19.46201 , 25.205896],\n",
       "         [ 8.028064, 82.69823 ]], dtype=float32),\n",
       "  'reward': 3.9596965544419995,\n",
       "  'newState': (array([ -17.85501146, -111.71112347]), array([14, 19, 26])),\n",
       "  'info': {'type': array([14, 19, 26])}},\n",
       " {'iter': 0,\n",
       "  'episode': 29,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -17.85501146, -111.71112347]), array([14, 19, 26])),\n",
       "  'action': array([[ -0.10975404, -17.701723  ],\n",
       "         [ -1.843635  ,  -4.3153415 ],\n",
       "         [-11.461486  , -12.4327345 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ -4.44013643, -77.26132488]), array([43, 22,  7])),\n",
       "  'info': {'type': array([43, 22,  7])}},\n",
       " {'iter': 0,\n",
       "  'episode': 30,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-3.3975782, -3.5690844],\n",
       "         [-4.333438 , -1.8808951],\n",
       "         [-1.1312635, -3.5830917]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([108.86227989, 109.03307152]), array([35, 47, 46])),\n",
       "  'info': {'type': array([35, 47, 46])}},\n",
       " {'iter': 0,\n",
       "  'episode': 30,\n",
       "  'step': 1,\n",
       "  'oldState': (array([108.86227989, 109.03307152]), array([35, 47, 46])),\n",
       "  'action': array([[54.37468  ,  1.3215845],\n",
       "         [51.54278  , 44.442604 ],\n",
       "         [27.70838  , 62.53953  ]], dtype=float32),\n",
       "  'reward': 4.10391846989574,\n",
       "  'newState': (array([-24.76355934,   0.72935295]), array([34, 36, 36])),\n",
       "  'info': {'type': array([34, 36, 36])}},\n",
       " {'iter': 0,\n",
       "  'episode': 30,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-24.76355934,   0.72935295]), array([34, 36, 36])),\n",
       "  'action': array([[0.6092378 , 0.03467175],\n",
       "         [0.22153237, 0.02221025],\n",
       "         [0.09231188, 0.09533192]], dtype=float32),\n",
       "  'reward': -2.0202206093147566,\n",
       "  'newState': (array([-25.68664134,   0.57713902]), array([32, 19,  3])),\n",
       "  'info': {'type': array([32, 19,  3])}},\n",
       " {'iter': 0,\n",
       "  'episode': 31,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.0622291 , 0.12555577],\n",
       "         [0.31806874, 0.07313482],\n",
       "         [0.00336696, 0.32631442]], dtype=float32),\n",
       "  'reward': -2.5831054706523062,\n",
       "  'newState': (array([99.61633521, 99.47499502]), array([24, 19, 37])),\n",
       "  'info': {'type': array([24, 19, 37])}},\n",
       " {'iter': 0,\n",
       "  'episode': 31,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.61633521, 99.47499502]), array([24, 19, 37])),\n",
       "  'action': array([[53.289467, 52.772923],\n",
       "         [38.8854  , 18.921148],\n",
       "         [67.88022 , 52.11872 ]], dtype=float32),\n",
       "  'reward': 4.105249011611957,\n",
       "  'newState': (array([-60.43874902, -24.3377949 ]), array([30, 38, 47])),\n",
       "  'info': {'type': array([30, 38, 47])}},\n",
       " {'iter': 0,\n",
       "  'episode': 31,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-60.43874902, -24.3377949 ]), array([30, 38, 47])),\n",
       "  'action': array([[ -3.8930497, -20.240665 ],\n",
       "         [ -6.430821 , -10.182861 ],\n",
       "         [-19.814718 ,  -7.704704 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-30.30016106,  13.79043615]), array([39,  5, 15])),\n",
       "  'info': {'type': array([39,  5, 15])}},\n",
       " {'iter': 0,\n",
       "  'episode': 32,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 9.022872 ,  8.254065 ],\n",
       "         [ 6.9643455, 13.296823 ],\n",
       "         [13.2313595,  2.093283 ]], dtype=float32),\n",
       "  'reward': 2.455920434687083,\n",
       "  'newState': (array([70.78142357, 76.35582924]), array([49, 23, 32])),\n",
       "  'info': {'type': array([49, 23, 32])}},\n",
       " {'iter': 0,\n",
       "  'episode': 32,\n",
       "  'step': 1,\n",
       "  'oldState': (array([70.78142357, 76.35582924]), array([49, 23, 32])),\n",
       "  'action': array([[14.053096, 19.642971],\n",
       "         [68.71586 , 47.772655],\n",
       "         [34.81274 , 62.314407]], dtype=float32),\n",
       "  'reward': 3.5082729905466277,\n",
       "  'newState': (array([-46.80027199, -53.37421227]), array([42, 10,  2])),\n",
       "  'info': {'type': array([42, 10,  2])}},\n",
       " {'iter': 0,\n",
       "  'episode': 32,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-46.80027199, -53.37421227]), array([42, 10,  2])),\n",
       "  'action': array([[-23.122944 , -22.44231  ],\n",
       "         [-10.8123255, -27.09392  ],\n",
       "         [-23.112871 , -32.30846  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([10.24786949, 28.47048378]), array([24, 34, 30])),\n",
       "  'info': {'type': array([24, 34, 30])}},\n",
       " {'iter': 0,\n",
       "  'episode': 33,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[11.212001,  8.930368],\n",
       "         [10.288723, 23.712696],\n",
       "         [10.270446, 26.059258]], dtype=float32),\n",
       "  'reward': 2.9209786585860593,\n",
       "  'newState': (array([68.22882843, 41.29767609]), array([17,  4,  0])),\n",
       "  'info': {'type': array([17,  4,  0])}},\n",
       " {'iter': 0,\n",
       "  'episode': 33,\n",
       "  'step': 1,\n",
       "  'oldState': (array([68.22882843, 41.29767609]), array([17,  4,  0])),\n",
       "  'action': array([[ 1.2950245, 38.35271  ],\n",
       "         [34.757317 ,  9.56427  ],\n",
       "         [41.888466 , 17.790209 ]], dtype=float32),\n",
       "  'reward': 0.6393876548076222,\n",
       "  'newState': (array([ -9.71198273, -24.40951538]), array([14, 17, 39])),\n",
       "  'info': {'type': array([14, 17, 39])}},\n",
       " {'iter': 0,\n",
       "  'episode': 33,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -9.71198273, -24.40951538]), array([14, 17, 39])),\n",
       "  'action': array([[-4.807072  , -0.12992701],\n",
       "         [-5.577669  , -9.115666  ],\n",
       "         [-7.646267  , -4.281162  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  8.31902504, -10.882761  ]), array([35, 17, 28])),\n",
       "  'info': {'type': array([35, 17, 28])}},\n",
       " {'iter': 0,\n",
       "  'episode': 34,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.1870089, 0.4404913],\n",
       "         [8.284102 , 8.083326 ],\n",
       "         [2.0231571, 7.962714 ]], dtype=float32),\n",
       "  'reward': 1.7661314074624037,\n",
       "  'newState': (array([86.50573158, 83.51346779]), array([22, 38, 41])),\n",
       "  'info': {'type': array([22, 38, 41])}},\n",
       " {'iter': 0,\n",
       "  'episode': 34,\n",
       "  'step': 1,\n",
       "  'oldState': (array([86.50573158, 83.51346779]), array([22, 38, 41])),\n",
       "  'action': array([[17.07936 , 26.537588],\n",
       "         [79.25226 , 69.51746 ],\n",
       "         [28.869497, 73.583336]], dtype=float32),\n",
       "  'reward': 4.093253684275452,\n",
       "  'newState': (array([-38.69538689, -86.12492943]), array([10, 13,  6])),\n",
       "  'info': {'type': array([10, 13,  6])}},\n",
       " {'iter': 0,\n",
       "  'episode': 34,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-38.69538689, -86.12492943]), array([10, 13,  6])),\n",
       "  'action': array([[-30.67898 , -30.093552],\n",
       "         [-10.56496 , -11.955953],\n",
       "         [-37.30712 , -24.50356 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 39.85566902, -19.57186699]), array([25, 38, 48])),\n",
       "  'info': {'type': array([25, 38, 48])}},\n",
       " {'iter': 0,\n",
       "  'episode': 35,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[17.707724, 32.655495],\n",
       "         [36.137398, 36.753876],\n",
       "         [17.217392, 36.332603]], dtype=float32),\n",
       "  'reward': 3.362973524242563,\n",
       "  'newState': (array([28.93748474, -5.74197388]), array([48, 44, 41])),\n",
       "  'info': {'type': array([48, 44, 41])}},\n",
       " {'iter': 0,\n",
       "  'episode': 35,\n",
       "  'step': 1,\n",
       "  'oldState': (array([28.93748474, -5.74197388]), array([48, 44, 41])),\n",
       "  'action': array([[12.174909, 11.311013],\n",
       "         [ 7.503555, 10.086989],\n",
       "         [24.359478, 24.313961]], dtype=float32),\n",
       "  'reward': 2.8643264581498666,\n",
       "  'newState': (array([-15.10045624, -51.45393753]), array([ 0, 22, 16])),\n",
       "  'info': {'type': array([ 0, 22, 16])}},\n",
       " {'iter': 0,\n",
       "  'episode': 35,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-15.10045624, -51.45393753]), array([ 0, 22, 16])),\n",
       "  'action': array([[-10.133256 ,  -4.920972 ],\n",
       "         [ -4.0094223, -12.188341 ],\n",
       "         [ -6.9248896,  -3.2104652]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  5.96711159, -31.13415909]), array([19,  9, 48])),\n",
       "  'info': {'type': array([19,  9, 48])}},\n",
       " {'iter': 0,\n",
       "  'episode': 36,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.15423432, 1.6009026 ],\n",
       "         [4.8071394 , 3.4651732 ],\n",
       "         [1.554717  , 2.367829  ]], dtype=float32),\n",
       "  'reward': 0.12539569495158862,\n",
       "  'newState': (array([93.48390913, 92.56609535]), array([28, 47, 10])),\n",
       "  'info': {'type': array([28, 47, 10])}},\n",
       " {'iter': 0,\n",
       "  'episode': 36,\n",
       "  'step': 1,\n",
       "  'oldState': (array([93.48390913, 92.56609535]), array([28, 47, 10])),\n",
       "  'action': array([[61.689285, 13.662001],\n",
       "         [27.028883, 58.249584],\n",
       "         [ 7.438587, 93.244095]], dtype=float32),\n",
       "  'reward': 4.148017201729952,\n",
       "  'newState': (array([ -2.67284441, -72.58957481]), array([ 4, 23, 14])),\n",
       "  'info': {'type': array([ 4, 23, 14])}},\n",
       " {'iter': 0,\n",
       "  'episode': 36,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -2.67284441, -72.58957481]), array([ 4, 23, 14])),\n",
       "  'action': array([[-0.4187745 , -1.1209811 ],\n",
       "         [-0.18144074, -1.2817146 ],\n",
       "         [-1.4487096 , -0.85069805]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ -0.62391949, -69.33618116]), array([21, 46,  3])),\n",
       "  'info': {'type': array([21, 46,  3])}},\n",
       " {'iter': 0,\n",
       "  'episode': 37,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.07926614, -0.18516152],\n",
       "         [-0.38874137, -0.03566821],\n",
       "         [-0.48259404, -0.38351122]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([100.95060158, 100.60434091]), array([24, 16, 46])),\n",
       "  'info': {'type': array([24, 16, 46])}},\n",
       " {'iter': 0,\n",
       "  'episode': 37,\n",
       "  'step': 1,\n",
       "  'oldState': (array([100.95060158, 100.60434091]), array([24, 16, 46])),\n",
       "  'action': array([[ 8.54775 , 16.041231],\n",
       "         [ 5.385228, 23.076206],\n",
       "         [ 7.931257, 68.390526]], dtype=float32),\n",
       "  'reward': 3.5014529532965804,\n",
       "  'newState': (array([79.08636665, -6.90362418]), array([15,  7, 14])),\n",
       "  'info': {'type': array([15,  7, 14])}},\n",
       " {'iter': 0,\n",
       "  'episode': 37,\n",
       "  'step': 2,\n",
       "  'oldState': (array([79.08636665, -6.90362418]), array([15,  7, 14])),\n",
       "  'action': array([[27.219091 ,  5.800029 ],\n",
       "         [48.592464 ,  2.7782354],\n",
       "         [13.272868 , 57.29741  ]], dtype=float32),\n",
       "  'reward': 3.230667165018952,\n",
       "  'newState': (array([ -9.9980526 , -72.77929556]), array([13, 15, 25])),\n",
       "  'info': {'type': array([13, 15, 25])}},\n",
       " {'iter': 0,\n",
       "  'episode': 38,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.7911712 , -6.4241643 ],\n",
       "         [-4.595136  , -0.65375614],\n",
       "         [-0.16957355, -5.1802073 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([106.55588055, 112.25812721]), array([20, 21, 46])),\n",
       "  'info': {'type': array([20, 21, 46])}},\n",
       " {'iter': 0,\n",
       "  'episode': 38,\n",
       "  'step': 1,\n",
       "  'oldState': (array([106.55588055, 112.25812721]), array([20, 21, 46])),\n",
       "  'action': array([[59.665363 , 20.599237 ],\n",
       "         [ 2.8236175, 36.50847  ],\n",
       "         [23.640715 ,  6.6614394]], dtype=float32),\n",
       "  'reward': 3.6119485929234423,\n",
       "  'newState': (array([20.42618847, 48.48898506]), array([29, 44, 37])),\n",
       "  'info': {'type': array([29, 44, 37])}},\n",
       " {'iter': 0,\n",
       "  'episode': 38,\n",
       "  'step': 2,\n",
       "  'oldState': (array([20.42618847, 48.48898506]), array([29, 44, 37])),\n",
       "  'action': array([[ 4.467941 , 41.13669  ],\n",
       "         [21.67332  ,  4.3307977],\n",
       "         [26.776241 ,  6.409445 ]], dtype=float32),\n",
       "  'reward': 2.158930617086366,\n",
       "  'newState': (array([-32.49131489,  -3.38794518]), array([22, 27, 12])),\n",
       "  'info': {'type': array([22, 27, 12])}},\n",
       " {'iter': 0,\n",
       "  'episode': 39,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.614485 , -2.6385722],\n",
       "         [-0.6058225, -0.4946018],\n",
       "         [-0.6023517, -2.5707908]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([103.82265925, 105.70396471]), array([12, 26, 12])),\n",
       "  'info': {'type': array([12, 26, 12])}},\n",
       " {'iter': 0,\n",
       "  'episode': 39,\n",
       "  'step': 1,\n",
       "  'oldState': (array([103.82265925, 105.70396471]), array([12, 26, 12])),\n",
       "  'action': array([[ 9.133946, 70.822716],\n",
       "         [20.671766, 24.084478],\n",
       "         [96.861725, 45.31512 ]], dtype=float32),\n",
       "  'reward': 3.3749918282177367,\n",
       "  'newState': (array([-22.84477544, -34.51835585]), array([ 7, 23, 39])),\n",
       "  'info': {'type': array([ 7, 23, 39])}},\n",
       " {'iter': 0,\n",
       "  'episode': 39,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-22.84477544, -34.51835585]), array([ 7, 23, 39])),\n",
       "  'action': array([[-17.516768, -17.290815],\n",
       "         [-16.859577, -17.705112],\n",
       "         [-17.777184,  -4.064132]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([29.30875087,  4.54170275]), array([43, 12, 38])),\n",
       "  'info': {'type': array([43, 12, 38])}},\n",
       " {'iter': 0,\n",
       "  'episode': 40,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[10.083701, 15.186214],\n",
       "         [26.4297  , 24.666248],\n",
       "         [ 6.24046 , 18.772768]], dtype=float32),\n",
       "  'reward': 2.8829585022033446,\n",
       "  'newState': (array([57.24613953, 41.37477112]), array([27, 48,  5])),\n",
       "  'info': {'type': array([27, 48,  5])}},\n",
       " {'iter': 0,\n",
       "  'episode': 40,\n",
       "  'step': 1,\n",
       "  'oldState': (array([57.24613953, 41.37477112]), array([27, 48,  5])),\n",
       "  'action': array([[ 7.1161385, 53.18748  ],\n",
       "         [39.376377 , 53.025963 ],\n",
       "         [38.92232  , 34.539783 ]], dtype=float32),\n",
       "  'reward': 3.3133153648457134,\n",
       "  'newState': (array([-28.16870117, -99.37844849]), array([34, 33, 43])),\n",
       "  'info': {'type': array([34, 33, 43])}},\n",
       " {'iter': 0,\n",
       "  'episode': 40,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-28.16870117, -99.37844849]), array([34, 33, 43])),\n",
       "  'action': array([[-21.708    , -27.976599 ],\n",
       "         [-26.741892 , -13.92679  ],\n",
       "         [-11.4881935,  -1.676864 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 31.76938248, -55.79819489]), array([26,  5,  9])),\n",
       "  'info': {'type': array([26,  5,  9])}},\n",
       " {'iter': 0,\n",
       "  'episode': 41,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[25.891987, 24.128891],\n",
       "         [23.75474 , 29.236643],\n",
       "         [19.427248, 16.331053]], dtype=float32),\n",
       "  'reward': 3.3436411231809235,\n",
       "  'newState': (array([30.92602539, 30.30341339]), array([25, 27, 43])),\n",
       "  'info': {'type': array([25, 27, 43])}},\n",
       " {'iter': 0,\n",
       "  'episode': 41,\n",
       "  'step': 1,\n",
       "  'oldState': (array([30.92602539, 30.30341339]), array([25, 27, 43])),\n",
       "  'action': array([[24.886858 , 23.528582 ],\n",
       "         [24.681677 ,  0.8003827],\n",
       "         [ 7.193643 ,  7.499604 ]], dtype=float32),\n",
       "  'reward': 1.9989917687163816,\n",
       "  'newState': (array([-25.83615112,  -1.52515411]), array([ 1, 18, 30])),\n",
       "  'info': {'type': array([ 1, 18, 30])}},\n",
       " {'iter': 0,\n",
       "  'episode': 41,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-25.83615112,  -1.52515411]), array([ 1, 18, 30])),\n",
       "  'action': array([[-0.73384523, -0.08890724],\n",
       "         [-1.1500916 , -0.19217643],\n",
       "         [-0.854827  , -0.76614934]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-23.09738731,  -0.47792113]), array([32, 26, 20])),\n",
       "  'info': {'type': array([32, 26, 20])}},\n",
       " {'iter': 0,\n",
       "  'episode': 42,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.10390008, -0.31288323],\n",
       "         [-0.36816704, -0.13500734],\n",
       "         [-0.08531099, -0.33422467]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([100.55737811, 100.78211522]), array([30, 39,  0])),\n",
       "  'info': {'type': array([30, 39,  0])}},\n",
       " {'iter': 0,\n",
       "  'episode': 42,\n",
       "  'step': 1,\n",
       "  'oldState': (array([100.55737811, 100.78211522]), array([30, 39,  0])),\n",
       "  'action': array([[28.296669, 21.316969],\n",
       "         [65.6674  , 78.93206 ],\n",
       "         [25.373959, 16.109682]], dtype=float32),\n",
       "  'reward': 3.922568619972965,\n",
       "  'newState': (array([-18.78064984, -15.57659602]), array([22, 34,  3])),\n",
       "  'info': {'type': array([22, 34,  3])}},\n",
       " {'iter': 0,\n",
       "  'episode': 42,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-18.78064984, -15.57659602]), array([22, 34,  3])),\n",
       "  'action': array([[ -6.8823915 , -11.249803  ],\n",
       "         [ -0.45435172, -10.339191  ],\n",
       "         [ -9.2346525 ,  -6.2632475 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-2.20925397, 12.27564549]), array([ 6, 12, 39])),\n",
       "  'info': {'type': array([ 6, 12, 39])}},\n",
       " {'iter': 0,\n",
       "  'episode': 43,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 2.571513  ,  9.781735  ],\n",
       "         [ 0.07394576,  9.84405   ],\n",
       "         [10.91182   ,  9.265032  ]], dtype=float32),\n",
       "  'reward': 1.8449053103706416,\n",
       "  'newState': (array([86.44272041, 71.10918236]), array([38, 19, 47])),\n",
       "  'info': {'type': array([38, 19, 47])}},\n",
       " {'iter': 0,\n",
       "  'episode': 43,\n",
       "  'step': 1,\n",
       "  'oldState': (array([86.44272041, 71.10918236]), array([38, 19, 47])),\n",
       "  'action': array([[23.110067, 24.099693],\n",
       "         [11.139639, 31.299192],\n",
       "         [54.22055 , 17.292027]], dtype=float32),\n",
       "  'reward': 3.7061778593142014,\n",
       "  'newState': (array([-2.02754021, -1.58173561]), array([48,  6, 13])),\n",
       "  'info': {'type': array([48,  6, 13])}},\n",
       " {'iter': 0,\n",
       "  'episode': 43,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-2.02754021, -1.58173561]), array([48,  6, 13])),\n",
       "  'action': array([[-0.20942551, -0.20578027],\n",
       "         [-1.042427  , -0.61229104],\n",
       "         [-0.10371809, -1.0619162 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-0.67196965,  0.29825187]), array([36, 23, 22])),\n",
       "  'info': {'type': array([36, 23, 22])}},\n",
       " {'iter': 0,\n",
       "  'episode': 44,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.08648021, 0.2885964 ],\n",
       "         [0.22199973, 0.23916005],\n",
       "         [0.02629333, 0.04740146]], dtype=float32),\n",
       "  'reward': -1.86920696264129,\n",
       "  'newState': (array([99.66522673, 99.42484212]), array([ 2, 28, 42])),\n",
       "  'info': {'type': array([ 2, 28, 42])}},\n",
       " {'iter': 0,\n",
       "  'episode': 44,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.66522673, 99.42484212]), array([ 2, 28, 42])),\n",
       "  'action': array([[59.93791 , 28.874834],\n",
       "         [83.794785, 28.766855],\n",
       "         [60.82704 , 42.71434 ]], dtype=float32),\n",
       "  'reward': 4.126717826978032,\n",
       "  'newState': (array([-104.89451143,   -0.93119121]), array([31,  9, 41])),\n",
       "  'info': {'type': array([31,  9, 41])}},\n",
       " {'iter': 0,\n",
       "  'episode': 44,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-104.89451143,   -0.93119121]), array([31,  9, 41])),\n",
       "  'action': array([[-0.33911926, -0.37602052],\n",
       "         [-0.82586265, -0.41078138],\n",
       "         [-0.55876684, -0.6109332 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-103.17076275,    0.46654391]), array([24, 45, 29])),\n",
       "  'info': {'type': array([24, 45, 29])}},\n",
       " {'iter': 0,\n",
       "  'episode': 45,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.03860718, 0.22869278],\n",
       "         [0.38588274, 0.35343572],\n",
       "         [0.13641141, 0.06245226]], dtype=float32),\n",
       "  'reward': -1.87503329495112,\n",
       "  'newState': (array([99.43909866, 99.35541922]), array([12, 18, 42])),\n",
       "  'info': {'type': array([12, 18, 42])}},\n",
       " {'iter': 0,\n",
       "  'episode': 45,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.43909866, 99.35541922]), array([12, 18, 42])),\n",
       "  'action': array([[31.964275  , 28.853783  ],\n",
       "         [ 0.35456783, 65.68637   ],\n",
       "         [ 9.491913  , 90.79283   ]], dtype=float32),\n",
       "  'reward': 4.3116672684104,\n",
       "  'newState': (array([ 57.62834197, -85.97755808]), array([11, 41, 36])),\n",
       "  'info': {'type': array([11, 41, 36])}},\n",
       " {'iter': 0,\n",
       "  'episode': 45,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 57.62834197, -85.97755808]), array([11, 41, 36])),\n",
       "  'action': array([[27.810438 ,  0.9730828],\n",
       "         [52.564785 ,  3.0648246],\n",
       "         [17.771738 , 28.8558   ]], dtype=float32),\n",
       "  'reward': 2.5092956488789966,\n",
       "  'newState': (array([ -40.51861542, -118.87126535]), array([48, 16, 30])),\n",
       "  'info': {'type': array([48, 16, 30])}},\n",
       " {'iter': 0,\n",
       "  'episode': 46,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -7.4295263,  -4.650995 ],\n",
       "         [-32.860397 , -36.07513  ],\n",
       "         [ -7.5070224,  -8.718847 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([147.79694748, 149.44496918]), array([42, 20, 35])),\n",
       "  'info': {'type': array([42, 20, 35])}},\n",
       " {'iter': 0,\n",
       "  'episode': 46,\n",
       "  'step': 1,\n",
       "  'oldState': (array([147.79694748, 149.44496918]), array([42, 20, 35])),\n",
       "  'action': array([[ 60.290997,  41.83957 ],\n",
       "         [134.5444  ,  13.363641],\n",
       "         [  4.611058, 136.53322 ]], dtype=float32),\n",
       "  'reward': 4.095451762112666,\n",
       "  'newState': (array([-51.64950943, -42.2914505 ]), array([41, 17,  2])),\n",
       "  'info': {'type': array([41, 17,  2])}},\n",
       " {'iter': 0,\n",
       "  'episode': 46,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-51.64950943, -42.2914505 ]), array([41, 17,  2])),\n",
       "  'action': array([[ -9.93564   , -19.305342  ],\n",
       "         [ -0.35159472, -17.083487  ],\n",
       "         [-30.72079   ,  -1.5391613 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-10.64148331,  -4.36346054]), array([21, 29, 36])),\n",
       "  'info': {'type': array([21, 29, 36])}},\n",
       " {'iter': 0,\n",
       "  'episode': 47,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.27992055, -3.557938  ],\n",
       "         [-1.6347861 , -2.3366985 ],\n",
       "         [-0.6635756 , -1.1244268 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([102.57828236, 107.01906347]), array([45, 46, 16])),\n",
       "  'info': {'type': array([45, 46, 16])}},\n",
       " {'iter': 0,\n",
       "  'episode': 47,\n",
       "  'step': 1,\n",
       "  'oldState': (array([102.57828236, 107.01906347]), array([45, 46, 16])),\n",
       "  'action': array([[13.61901 , 42.77059 ],\n",
       "         [33.68067 , 76.000015],\n",
       "         [20.469646, 66.13085 ]], dtype=float32),\n",
       "  'reward': 3.6272021437230215,\n",
       "  'newState': (array([ 34.80894947, -77.88239527]), array([27,  8, 28])),\n",
       "  'info': {'type': array([27,  8, 28])}},\n",
       " {'iter': 0,\n",
       "  'episode': 47,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 34.80894947, -77.88239527]), array([27,  8, 28])),\n",
       "  'action': array([[26.799   , 27.622728],\n",
       "         [10.753449, 22.061121],\n",
       "         [25.633171, 12.429111]], dtype=float32),\n",
       "  'reward': 3.4195975318473235,\n",
       "  'newState': (array([ -28.37666988, -139.99535608]), array([ 2, 35, 13])),\n",
       "  'info': {'type': array([ 2, 35, 13])}},\n",
       " {'iter': 0,\n",
       "  'episode': 48,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-18.431335,  -7.823238],\n",
       "         [-16.25721 , -14.152318],\n",
       "         [-12.658893, -27.45206 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([147.34743881, 149.42761612]), array([41, 36, 36])),\n",
       "  'info': {'type': array([41, 36, 36])}},\n",
       " {'iter': 0,\n",
       "  'episode': 48,\n",
       "  'step': 1,\n",
       "  'oldState': (array([147.34743881, 149.42761612]), array([41, 36, 36])),\n",
       "  'action': array([[130.55405 ,  50.811462],\n",
       "         [123.391716,  13.587728],\n",
       "         [ 84.46484 , 134.01207 ]], dtype=float32),\n",
       "  'reward': 4.314989234560274,\n",
       "  'newState': (array([-191.0631752 ,  -48.98363876]), array([40, 18, 33])),\n",
       "  'info': {'type': array([40, 18, 33])}},\n",
       " {'iter': 0,\n",
       "  'episode': 48,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-191.0631752 ,  -48.98363876]), array([40, 18, 33])),\n",
       "  'action': array([[ -7.7256274, -11.996016 ],\n",
       "         [-45.747086 ,  -4.8402815],\n",
       "         [ -9.089076 , -16.180943 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-128.50138474,  -15.96640015]), array([38, 46, 40])),\n",
       "  'info': {'type': array([38, 46, 40])}},\n",
       " {'iter': 0,\n",
       "  'episode': 49,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -0.4461644,  -5.4385123],\n",
       "         [-11.987456 , -14.041839 ],\n",
       "         [ -3.2429485,  -8.704882 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([115.67656898, 128.18523216]), array([25, 39, 48])),\n",
       "  'info': {'type': array([25, 39, 48])}},\n",
       " {'iter': 0,\n",
       "  'episode': 49,\n",
       "  'step': 1,\n",
       "  'oldState': (array([115.67656898, 128.18523216]), array([25, 39, 48])),\n",
       "  'action': array([[ 45.916588,  70.001564],\n",
       "         [ 33.827225, 115.44073 ],\n",
       "         [126.19834 ,  70.06751 ]], dtype=float32),\n",
       "  'reward': 4.770417491170725,\n",
       "  'newState': (array([ -90.26558495, -127.32456398]), array([37,  2, 34])),\n",
       "  'info': {'type': array([37,  2, 34])}},\n",
       " {'iter': 0,\n",
       "  'episode': 49,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -90.26558495, -127.32456398]), array([37,  2, 34])),\n",
       "  'action': array([[-86.47619  ,  -1.6063727],\n",
       "         [-72.35571  , -55.588257 ],\n",
       "         [-61.364746 , -42.04202  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([129.93107033, -28.08791542]), array([28, 14, 11])),\n",
       "  'info': {'type': array([28, 14, 11])}},\n",
       " {'iter': 0,\n",
       "  'episode': 50,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[124.90738 ,  74.805595],\n",
       "         [109.55519 ,  44.75696 ],\n",
       "         [ 26.711308,  35.18649 ]], dtype=float32),\n",
       "  'reward': 4.191740409497744,\n",
       "  'newState': (array([-161.17388916,  -54.74905396]), array([42, 26, 40])),\n",
       "  'info': {'type': array([42, 26, 40])}},\n",
       " {'iter': 0,\n",
       "  'episode': 50,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-161.17388916,  -54.74905396]), array([42, 26, 40])),\n",
       "  'action': array([[-24.101698, -24.330076],\n",
       "         [-21.526836, -53.391796],\n",
       "         [-53.57317 , -23.282503]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-61.97218323,  46.25531769]), array([21, 16, 28])),\n",
       "  'info': {'type': array([21, 16, 28])}},\n",
       " {'iter': 0,\n",
       "  'episode': 50,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-61.97218323,  46.25531769]), array([21, 16, 28])),\n",
       "  'action': array([[ 0.70971805, 41.6424    ],\n",
       "         [17.17056   , 41.93233   ],\n",
       "         [ 8.462502  , 14.955918  ]], dtype=float32),\n",
       "  'reward': 2.167306426216805,\n",
       "  'newState': (array([-88.31496429, -52.27532959]), array([37, 41, 45])),\n",
       "  'info': {'type': array([37, 41, 45])}},\n",
       " {'iter': 1,\n",
       "  'episode': 1,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-31.886051, -30.587078],\n",
       "         [ -8.533564, -44.06531 ],\n",
       "         [-51.11434 , -50.616165]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([191.53395844, 225.26855469]), array([40, 42, 11])),\n",
       "  'info': {'type': array([40, 42, 11])}},\n",
       " {'iter': 1,\n",
       "  'episode': 1,\n",
       "  'step': 1,\n",
       "  'oldState': (array([191.53395844, 225.26855469]), array([40, 42, 11])),\n",
       "  'action': array([[212.40424, 116.01629],\n",
       "         [189.76054,  87.39872],\n",
       "         [142.80005, 157.84973]], dtype=float32),\n",
       "  'reward': 4.9985509964737345,\n",
       "  'newState': (array([-353.43088531, -135.9961853 ]), array([22,  6, 32])),\n",
       "  'info': {'type': array([22,  6, 32])}},\n",
       " {'iter': 1,\n",
       "  'episode': 1,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-353.43088531, -135.9961853 ]), array([22,  6, 32])),\n",
       "  'action': array([[-134.3566  ,  -44.94379 ],\n",
       "         [-116.01572 ,  -51.79472 ],\n",
       "         [ -27.495518,  -93.69531 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-75.56305695,  54.43763733]), array([14, 36, 23])),\n",
       "  'info': {'type': array([14, 36, 23])}},\n",
       " {'iter': 1,\n",
       "  'episode': 2,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[45.057716 , 13.188619 ],\n",
       "         [ 3.0221512, 19.378931 ],\n",
       "         [ 8.354916 , 54.42583  ]], dtype=float32),\n",
       "  'reward': 3.339970112019928,\n",
       "  'newState': (array([43.56521606, 13.00662231]), array([11, 35, 32])),\n",
       "  'info': {'type': array([11, 35, 32])}},\n",
       " {'iter': 1,\n",
       "  'episode': 2,\n",
       "  'step': 1,\n",
       "  'oldState': (array([43.56521606, 13.00662231]), array([11, 35, 32])),\n",
       "  'action': array([[33.192875, 38.96204 ],\n",
       "         [ 9.511455, 21.679726],\n",
       "         [20.03959 , 10.363688]], dtype=float32),\n",
       "  'reward': 3.2751861039139407,\n",
       "  'newState': (array([-19.17870331, -57.9988327 ]), array([46, 27, 49])),\n",
       "  'info': {'type': array([46, 27, 49])}},\n",
       " {'iter': 1,\n",
       "  'episode': 2,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-19.17870331, -57.9988327 ]), array([46, 27, 49])),\n",
       "  'action': array([[-13.855262 ,  -9.794933 ],\n",
       "         [-12.326403 ,  -2.873624 ],\n",
       "         [ -3.9947891, -16.948862 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 10.99774933, -28.38141251]), array([38,  0, 22])),\n",
       "  'info': {'type': array([38,  0, 22])}},\n",
       " {'iter': 1,\n",
       "  'episode': 3,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 6.660679 ,  9.156675 ],\n",
       "         [ 9.534259 ,  1.6269646],\n",
       "         [10.639873 ,  4.0444665]], dtype=float32),\n",
       "  'reward': 1.1287098862041525,\n",
       "  'newState': (array([73.16518784, 85.17189407]), array([33,  6, 36])),\n",
       "  'info': {'type': array([33,  6, 36])}},\n",
       " {'iter': 1,\n",
       "  'episode': 3,\n",
       "  'step': 1,\n",
       "  'oldState': (array([73.16518784, 85.17189407]), array([33,  6, 36])),\n",
       "  'action': array([[15.391742, 63.405594],\n",
       "         [13.839342, 21.452143],\n",
       "         [21.051142, 38.330853]], dtype=float32),\n",
       "  'reward': 3.408467359212271,\n",
       "  'newState': (array([ 22.88296127, -38.0166893 ]), array([18, 27, 28])),\n",
       "  'info': {'type': array([18, 27, 28])}},\n",
       " {'iter': 1,\n",
       "  'episode': 3,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 22.88296127, -38.0166893 ]), array([18, 27, 28])),\n",
       "  'action': array([[ 9.71696 , 12.838734],\n",
       "         [ 1.288089, 18.814337],\n",
       "         [ 9.303144, 16.713207]], dtype=float32),\n",
       "  'reward': 2.896010072309052,\n",
       "  'newState': (array([  2.57476807, -86.3829689 ]), array([37, 38, 30])),\n",
       "  'info': {'type': array([37, 38, 30])}},\n",
       " {'iter': 1,\n",
       "  'episode': 4,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.99598545, 0.88729316],\n",
       "         [1.0004202 , 0.23883137],\n",
       "         [1.2274175 , 1.308561  ]], dtype=float32),\n",
       "  'reward': -0.7735381087901843,\n",
       "  'newState': (array([96.77617693, 97.56531453]), array([46,  7, 21])),\n",
       "  'info': {'type': array([46,  7, 21])}},\n",
       " {'iter': 1,\n",
       "  'episode': 4,\n",
       "  'step': 1,\n",
       "  'oldState': (array([96.77617693, 97.56531453]), array([46,  7, 21])),\n",
       "  'action': array([[75.43515 , 96.602135],\n",
       "         [45.19587 , 54.976326],\n",
       "         [47.258514, 63.000927]], dtype=float32),\n",
       "  'reward': 4.401060158287806,\n",
       "  'newState': (array([ -71.11334944, -117.01407695]), array([16, 39, 29])),\n",
       "  'info': {'type': array([16, 39, 29])}},\n",
       " {'iter': 1,\n",
       "  'episode': 4,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -71.11334944, -117.01407695]), array([16, 39, 29])),\n",
       "  'action': array([[-15.5792  , -17.34945 ],\n",
       "         [-20.99839 , -51.279797],\n",
       "         [-48.743725,  -6.104725]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 14.20797014, -42.28011394]), array([11, 14, 40])),\n",
       "  'info': {'type': array([11, 14, 40])}},\n",
       " {'iter': 1,\n",
       "  'episode': 5,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.2829213, 1.3917361],\n",
       "         [8.608234 , 9.767826 ],\n",
       "         [4.041993 , 1.3364329]], dtype=float32),\n",
       "  'reward': 1.849042141398717,\n",
       "  'newState': (array([84.06685162, 87.50400543]), array([30,  8, 40])),\n",
       "  'info': {'type': array([30,  8, 40])}},\n",
       " {'iter': 1,\n",
       "  'episode': 5,\n",
       "  'step': 1,\n",
       "  'oldState': (array([84.06685162, 87.50400543]), array([30,  8, 40])),\n",
       "  'action': array([[51.546272  , 17.591963  ],\n",
       "         [46.515915  , 10.986764  ],\n",
       "         [41.93121   ,  0.92158693]], dtype=float32),\n",
       "  'reward': 3.6892149133038767,\n",
       "  'newState': (array([-55.92654133,  58.00369072]), array([48, 30, 23])),\n",
       "  'info': {'type': array([48, 30, 23])}},\n",
       " {'iter': 1,\n",
       "  'episode': 5,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-55.92654133,  58.00369072]), array([48, 30, 23])),\n",
       "  'action': array([[ 4.888196, 30.163788],\n",
       "         [23.326206, 34.286182],\n",
       "         [29.727617, 23.84044 ]], dtype=float32),\n",
       "  'reward': 2.7106109911006673,\n",
       "  'newState': (array([-113.86855793,  -30.28671455]), array([ 2, 28,  0])),\n",
       "  'info': {'type': array([ 2, 28,  0])}},\n",
       " {'iter': 1,\n",
       "  'episode': 6,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-16.825195, -22.568813],\n",
       "         [-11.202068,  -6.827791],\n",
       "         [-24.37031 , -24.174099]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([152.39757538, 153.5707016 ]), array([39, 12, 17])),\n",
       "  'info': {'type': array([39, 12, 17])}},\n",
       " {'iter': 1,\n",
       "  'episode': 6,\n",
       "  'step': 1,\n",
       "  'oldState': (array([152.39757538, 153.5707016 ]), array([39, 12, 17])),\n",
       "  'action': array([[ 89.83486 , 127.91619 ],\n",
       "         [ 58.97428 ,  64.41107 ],\n",
       "         [132.78528 ,  72.357285]], dtype=float32),\n",
       "  'reward': 4.645696556058289,\n",
       "  'newState': (array([-129.19684601, -111.11386871]), array([33, 10, 28])),\n",
       "  'info': {'type': array([33, 10, 28])}},\n",
       " {'iter': 1,\n",
       "  'episode': 6,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-129.19684601, -111.11386871]), array([33, 10, 28])),\n",
       "  'action': array([[-40.322704 , -69.90308  ],\n",
       "         [-52.601162 , -19.330633 ],\n",
       "         [ -7.6469007, -36.337337 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-28.62607574,  14.45719147]), array([41, 11,  5])),\n",
       "  'info': {'type': array([41, 11,  5])}},\n",
       " {'iter': 1,\n",
       "  'episode': 7,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 3.3809788,  5.934368 ],\n",
       "         [ 5.21142  ,  3.4690008],\n",
       "         [ 9.434481 , 12.116803 ]], dtype=float32),\n",
       "  'reward': 1.3446112254148754,\n",
       "  'newState': (array([81.97312164, 78.47982788]), array([17,  5, 42])),\n",
       "  'info': {'type': array([17,  5, 42])}},\n",
       " {'iter': 1,\n",
       "  'episode': 7,\n",
       "  'step': 1,\n",
       "  'oldState': (array([81.97312164, 78.47982788]), array([17,  5, 42])),\n",
       "  'action': array([[32.107323, 41.72506 ],\n",
       "         [14.893598, 48.33018 ],\n",
       "         [ 8.415165, 32.63817 ]], dtype=float32),\n",
       "  'reward': 3.6623333858006397,\n",
       "  'newState': (array([ 26.55703735, -44.21357727]), array([22, 14, 23])),\n",
       "  'info': {'type': array([22, 14, 23])}},\n",
       " {'iter': 1,\n",
       "  'episode': 7,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 26.55703735, -44.21357727]), array([22, 14, 23])),\n",
       "  'action': array([[1.0172962e-02, 8.1665735e+00],\n",
       "         [2.4165339e+01, 2.4126220e+00],\n",
       "         [2.1941755e+01, 2.3739014e+01]], dtype=float32),\n",
       "  'reward': -0.01199835200096002,\n",
       "  'newState': (array([-19.56023026, -78.53178406]), array([17, 10,  8])),\n",
       "  'info': {'type': array([17, 10,  8])}},\n",
       " {'iter': 1,\n",
       "  'episode': 8,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -5.532593 ,  -1.058473 ],\n",
       "         [ -8.632442 ,  -5.164731 ],\n",
       "         [-13.534842 ,  -1.1380404]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([127.69987679, 107.36124468]), array([48, 19, 12])),\n",
       "  'info': {'type': array([48, 19, 12])}},\n",
       " {'iter': 1,\n",
       "  'episode': 8,\n",
       "  'step': 1,\n",
       "  'oldState': (array([127.69987679, 107.36124468]), array([48, 19, 12])),\n",
       "  'action': array([[58.365944, 86.06911 ],\n",
       "         [91.83736 , 52.90794 ],\n",
       "         [87.08758 ,  7.267642]], dtype=float32),\n",
       "  'reward': 4.116081991921083,\n",
       "  'newState': (array([-109.59101677,  -38.88344526]), array([25, 13, 16])),\n",
       "  'info': {'type': array([25, 13, 16])}},\n",
       " {'iter': 1,\n",
       "  'episode': 8,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-109.59101677,  -38.88344526]), array([25, 13, 16])),\n",
       "  'action': array([[-33.80208  ,  -0.6688322],\n",
       "         [ -4.4936037, -24.897596 ],\n",
       "         [-16.025856 , -13.8876705]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-55.26947975,   0.5706563 ]), array([ 4, 24, 27])),\n",
       "  'info': {'type': array([ 4, 24, 27])}},\n",
       " {'iter': 1,\n",
       "  'episode': 9,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.0931442 , 0.42685613],\n",
       "         [0.16025986, 0.5293443 ],\n",
       "         [0.14201559, 0.48663747]], dtype=float32),\n",
       "  'reward': -1.2537668444699706,\n",
       "  'newState': (array([99.60458034, 98.55716205]), array([ 4,  3, 12])),\n",
       "  'info': {'type': array([ 4,  3, 12])}},\n",
       " {'iter': 1,\n",
       "  'episode': 9,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.60458034, 98.55716205]), array([ 4,  3, 12])),\n",
       "  'action': array([[58.408623 , 86.96642  ],\n",
       "         [55.581757 , 98.02144  ],\n",
       "         [65.5623   ,  2.4258296]], dtype=float32),\n",
       "  'reward': 4.245126871710237,\n",
       "  'newState': (array([-79.948093  , -88.85651898]), array([ 2, 12, 32])),\n",
       "  'info': {'type': array([ 2, 12, 32])}},\n",
       " {'iter': 1,\n",
       "  'episode': 9,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-79.948093  , -88.85651898]), array([ 2, 12, 32])),\n",
       "  'action': array([[ -6.843287, -67.284996],\n",
       "         [-20.180496, -16.300991],\n",
       "         [-45.69221 , -49.8191  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-7.23209721, 44.54857135]), array([32, 15, 36])),\n",
       "  'info': {'type': array([32, 15, 36])}},\n",
       " {'iter': 1,\n",
       "  'episode': 10,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[15.317313 ,  3.1448028],\n",
       "         [ 9.271514 , 18.042559 ],\n",
       "         [35.966557 , 20.892214 ]], dtype=float32),\n",
       "  'reward': 2.9026935627966015,\n",
       "  'newState': (array([39.44461823, 57.92042542]), array([10, 12, 18])),\n",
       "  'info': {'type': array([10, 12, 18])}},\n",
       " {'iter': 1,\n",
       "  'episode': 10,\n",
       "  'step': 1,\n",
       "  'oldState': (array([39.44461823, 57.92042542]), array([10, 12, 18])),\n",
       "  'action': array([[55.87566 , 13.635018],\n",
       "         [32.367455, 55.512493],\n",
       "         [12.332668, 20.953457]], dtype=float32),\n",
       "  'reward': 3.7880779371032305,\n",
       "  'newState': (array([-61.13117218, -32.18054199]), array([30,  5, 16])),\n",
       "  'info': {'type': array([30,  5, 16])}},\n",
       " {'iter': 1,\n",
       "  'episode': 10,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-61.13117218, -32.18054199]), array([30,  5, 16])),\n",
       "  'action': array([[-17.465124 , -24.145021 ],\n",
       "         [-24.543722 ,  -5.4332757],\n",
       "         [ -7.9793434,  -9.50579  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-11.14298248,   6.90354538]), array([31, 32, 43])),\n",
       "  'info': {'type': array([31, 32, 43])}},\n",
       " {'iter': 1,\n",
       "  'episode': 11,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[6.5138717 , 1.9312632 ],\n",
       "         [6.128424  , 2.2999806 ],\n",
       "         [5.5060654 , 0.83146304]], dtype=float32),\n",
       "  'reward': 1.270237329026559,\n",
       "  'newState': (array([81.85163879, 94.93729305]), array([44, 31, 43])),\n",
       "  'info': {'type': array([44, 31, 43])}},\n",
       " {'iter': 1,\n",
       "  'episode': 11,\n",
       "  'step': 1,\n",
       "  'oldState': (array([81.85163879, 94.93729305]), array([44, 31, 43])),\n",
       "  'action': array([[ 6.1007495, 39.929607 ],\n",
       "         [26.532522 , 10.343954 ],\n",
       "         [82.913994 , 72.75429  ]], dtype=float32),\n",
       "  'reward': 3.1275496255073163,\n",
       "  'newState': (array([-33.69562531, -28.09055424]), array([35, 44, 24])),\n",
       "  'info': {'type': array([35, 44, 24])}},\n",
       " {'iter': 1,\n",
       "  'episode': 11,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-33.69562531, -28.09055424]), array([35, 44, 24])),\n",
       "  'action': array([[-11.112292, -17.790922],\n",
       "         [ -5.37972 , -27.57115 ],\n",
       "         [-18.15655 , -23.798098]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 0.95293427, 41.06961727]), array([15, 21, 19])),\n",
       "  'info': {'type': array([15, 21, 19])}},\n",
       " {'iter': 1,\n",
       "  'episode': 12,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[25.812508 , 30.225372 ],\n",
       "         [ 6.6281247, 25.461264 ],\n",
       "         [27.275167 , 32.702007 ]], dtype=float32),\n",
       "  'reward': 3.293725182294343,\n",
       "  'newState': (array([40.28420258, 11.61135864]), array([13, 33,  4])),\n",
       "  'info': {'type': array([13, 33,  4])}},\n",
       " {'iter': 1,\n",
       "  'episode': 12,\n",
       "  'step': 1,\n",
       "  'oldState': (array([40.28420258, 11.61135864]), array([13, 33,  4])),\n",
       "  'action': array([[23.790947 ,  2.6290948],\n",
       "         [38.968636 , 18.233015 ],\n",
       "         [ 1.1843517,  0.6768938]], dtype=float32),\n",
       "  'reward': 2.789853419324532,\n",
       "  'newState': (array([-23.65973282,  -9.92764473]), array([39,  3, 34])),\n",
       "  'info': {'type': array([39,  3, 34])}},\n",
       " {'iter': 1,\n",
       "  'episode': 12,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-23.65973282,  -9.92764473]), array([39,  3, 34])),\n",
       "  'action': array([[-1.4716638, -8.179044 ],\n",
       "         [-1.1955359, -5.8945174],\n",
       "         [-8.900686 , -8.950339 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-12.09184647,  13.09625435]), array([34, 42, 14])),\n",
       "  'info': {'type': array([34, 42, 14])}},\n",
       " {'iter': 1,\n",
       "  'episode': 13,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 5.30217  , 11.044403 ],\n",
       "         [ 7.5488524,  1.347886 ],\n",
       "         [10.959433 ,  8.126746 ]], dtype=float32),\n",
       "  'reward': 0.9532301459600445,\n",
       "  'newState': (array([76.18954468, 79.48096466]), array([18, 38, 38])),\n",
       "  'info': {'type': array([18, 38, 38])}},\n",
       " {'iter': 1,\n",
       "  'episode': 13,\n",
       "  'step': 1,\n",
       "  'oldState': (array([76.18954468, 79.48096466]), array([18, 38, 38])),\n",
       "  'action': array([[64.685974, 35.946186],\n",
       "         [71.245705, 39.01247 ],\n",
       "         [64.86654 , 27.291372]], dtype=float32),\n",
       "  'reward': 4.108217281484344,\n",
       "  'newState': (array([-124.6086731 ,  -22.76906586]), array([48, 17,  5])),\n",
       "  'info': {'type': array([48, 17,  5])}},\n",
       " {'iter': 1,\n",
       "  'episode': 13,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-124.6086731 ,  -22.76906586]), array([48, 17,  5])),\n",
       "  'action': array([[-18.488699 ,  -3.0071955],\n",
       "         [-19.415075 ,  -6.8962116],\n",
       "         [ -3.7753966, -13.52937  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-82.92950058,   0.66371155]), array([38, 27,  8])),\n",
       "  'info': {'type': array([38, 27,  8])}},\n",
       " {'iter': 1,\n",
       "  'episode': 14,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.04746996, 0.33624244],\n",
       "         [0.3072912 , 0.29659474],\n",
       "         [0.41517684, 0.210646  ]], dtype=float32),\n",
       "  'reward': -1.8326727239724099,\n",
       "  'newState': (array([99.23006201, 99.15651679]), array([40,  5,  5])),\n",
       "  'info': {'type': array([40,  5,  5])}},\n",
       " {'iter': 1,\n",
       "  'episode': 14,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.23006201, 99.15651679]), array([40,  5,  5])),\n",
       "  'action': array([[15.5182085, 96.81321  ],\n",
       "         [ 3.7542126, 12.865245 ],\n",
       "         [23.4823   , 81.71084  ]], dtype=float32),\n",
       "  'reward': 2.9146440163263097,\n",
       "  'newState': (array([ 56.47533941, -92.23276544]), array([ 7, 14, 37])),\n",
       "  'info': {'type': array([ 7, 14, 37])}},\n",
       " {'iter': 1,\n",
       "  'episode': 14,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 56.47533941, -92.23276544]), array([ 7, 14, 37])),\n",
       "  'action': array([[ 2.9256377, 22.898066 ],\n",
       "         [23.093138 , 11.719415 ],\n",
       "         [23.043236 , 19.190187 ]], dtype=float32),\n",
       "  'reward': 3.1115669739797136,\n",
       "  'newState': (array([   7.41332769, -146.04043603]), array([41, 14, 33])),\n",
       "  'info': {'type': array([41, 14, 33])}},\n",
       " {'iter': 1,\n",
       "  'episode': 15,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.94958925, 5.5404587 ],\n",
       "         [0.7955904 , 1.6309122 ],\n",
       "         [5.350609  , 0.05794473]], dtype=float32),\n",
       "  'reward': 0.3658654328759956,\n",
       "  'newState': (array([92.90421152, 92.77068424]), array([27, 13, 30])),\n",
       "  'info': {'type': array([27, 13, 30])}},\n",
       " {'iter': 1,\n",
       "  'episode': 15,\n",
       "  'step': 1,\n",
       "  'oldState': (array([92.90421152, 92.77068424]), array([27, 13, 30])),\n",
       "  'action': array([[26.620281 , 50.529922 ],\n",
       "         [62.74352  ,  5.1042957],\n",
       "         [74.34393  , 20.880201 ]], dtype=float32),\n",
       "  'reward': 3.5211893739137685,\n",
       "  'newState': (array([-70.80352163,  16.25626469]), array([43, 46,  9])),\n",
       "  'info': {'type': array([43, 46,  9])}},\n",
       " {'iter': 1,\n",
       "  'episode': 15,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-70.80352163,  16.25626469]), array([43, 46,  9])),\n",
       "  'action': array([[12.142821 ,  8.590656 ],\n",
       "         [ 3.0304127, 15.896895 ],\n",
       "         [ 8.6067505,  1.0419618]], dtype=float32),\n",
       "  'reward': 2.6020699716318036,\n",
       "  'newState': (array([-94.58350515,  -9.27324963]), array([3, 3, 3])),\n",
       "  'info': {'type': array([3, 3, 3])}},\n",
       " {'iter': 1,\n",
       "  'episode': 16,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-8.380713 , -3.3504467],\n",
       "         [-1.9765927, -6.526311 ],\n",
       "         [-1.0107313, -4.668284 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([111.36803818, 114.54504204]), array([33, 35, 16])),\n",
       "  'info': {'type': array([33, 35, 16])}},\n",
       " {'iter': 1,\n",
       "  'episode': 16,\n",
       "  'step': 1,\n",
       "  'oldState': (array([111.36803818, 114.54504204]), array([33, 35, 16])),\n",
       "  'action': array([[57.838097, 47.47572 ],\n",
       "         [11.353177, 72.02253 ],\n",
       "         [11.27121 , 32.310184]], dtype=float32),\n",
       "  'reward': 4.095127649639342,\n",
       "  'newState': (array([ 30.90555191, -37.26338387]), array([28, 37,  0])),\n",
       "  'info': {'type': array([28, 37,  0])}},\n",
       " {'iter': 1,\n",
       "  'episode': 16,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 30.90555191, -37.26338387]), array([28, 37,  0])),\n",
       "  'action': array([[ 2.7667608,  9.968283 ],\n",
       "         [13.357388 ,  2.9397113],\n",
       "         [12.796821 , 17.806393 ]], dtype=float32),\n",
       "  'reward': 1.0521920722085418,\n",
       "  'newState': (array([  1.98458099, -67.97776985]), array([37, 29, 18])),\n",
       "  'info': {'type': array([37, 29, 18])}},\n",
       " {'iter': 1,\n",
       "  'episode': 17,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.2068115 , 0.44330418],\n",
       "         [0.5905435 , 0.34741604],\n",
       "         [0.3917587 , 1.2523341 ]], dtype=float32),\n",
       "  'reward': -0.5135150610763447,\n",
       "  'newState': (array([97.81088614, 97.95694566]), array([14, 39,  6])),\n",
       "  'info': {'type': array([14, 39,  6])}},\n",
       " {'iter': 1,\n",
       "  'episode': 17,\n",
       "  'step': 1,\n",
       "  'oldState': (array([97.81088614, 97.95694566]), array([14, 39,  6])),\n",
       "  'action': array([[26.896242, 88.09315 ],\n",
       "         [91.31886 , 62.153286],\n",
       "         [26.708086, 64.97171 ]], dtype=float32),\n",
       "  'reward': 3.9703757311728265,\n",
       "  'newState': (array([ -47.11230111, -117.26119399]), array([28, 10, 32])),\n",
       "  'info': {'type': array([28, 10, 32])}},\n",
       " {'iter': 1,\n",
       "  'episode': 17,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -47.11230111, -117.26119399]), array([28, 10, 32])),\n",
       "  'action': array([[-45.48534  , -41.13536  ],\n",
       "         [-29.526842 ,  -4.2424088],\n",
       "         [-19.146948 , -31.810495 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 47.0468328 , -40.07293105]), array([46, 29, 18])),\n",
       "  'info': {'type': array([46, 29, 18])}},\n",
       " {'iter': 1,\n",
       "  'episode': 18,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[16.966656 , 12.075844 ],\n",
       "         [13.1665125, 43.00192  ],\n",
       "         [17.223425 , 12.033096 ]], dtype=float32),\n",
       "  'reward': 3.4019007181682834,\n",
       "  'newState': (array([52.64340973, 32.8891449 ]), array([36, 29, 39])),\n",
       "  'info': {'type': array([36, 29, 39])}},\n",
       " {'iter': 1,\n",
       "  'episode': 18,\n",
       "  'step': 1,\n",
       "  'oldState': (array([52.64340973, 32.8891449 ]), array([36, 29, 39])),\n",
       "  'action': array([[ 1.2860221,  6.6378603],\n",
       "         [ 2.9373143, 21.709421 ],\n",
       "         [30.089115 , 12.111598 ]], dtype=float32),\n",
       "  'reward': 2.348707954520333,\n",
       "  'newState': (array([18.33095932, -7.56973648]), array([28, 29, 39])),\n",
       "  'info': {'type': array([28, 29, 39])}},\n",
       " {'iter': 1,\n",
       "  'episode': 18,\n",
       "  'step': 2,\n",
       "  'oldState': (array([18.33095932, -7.56973648]), array([28, 29, 39])),\n",
       "  'action': array([[ 9.646676 ,  3.057141 ],\n",
       "         [13.061039 ,  0.2500135],\n",
       "         [16.782978 , 15.054049 ]], dtype=float32),\n",
       "  'reward': 1.648216393597233,\n",
       "  'newState': (array([-21.15973282, -25.93093872]), array([26, 27, 42])),\n",
       "  'info': {'type': array([26, 27, 42])}},\n",
       " {'iter': 1,\n",
       "  'episode': 19,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -0.6626489, -12.715098 ],\n",
       "         [-18.670456 ,  -6.1749625],\n",
       "         [-17.38954  , -13.35697  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([136.72264481, 132.24703217]), array([12, 17,  7])),\n",
       "  'info': {'type': array([12, 17,  7])}},\n",
       " {'iter': 1,\n",
       "  'episode': 19,\n",
       "  'step': 1,\n",
       "  'oldState': (array([136.72264481, 132.24703217]), array([12, 17,  7])),\n",
       "  'action': array([[ 54.232006, 119.51277 ],\n",
       "         [112.40643 , 101.113716],\n",
       "         [ 54.474075,  63.67945 ]], dtype=float32),\n",
       "  'reward': 4.438870203527053,\n",
       "  'newState': (array([ -84.3898735 , -152.05890656]), array([27,  7, 19])),\n",
       "  'info': {'type': array([27,  7, 19])}},\n",
       " {'iter': 1,\n",
       "  'episode': 19,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -84.3898735 , -152.05890656]), array([27,  7, 19])),\n",
       "  'action': array([[-61.17498  ,  -5.3193893],\n",
       "         [-23.596233 , -48.26757  ],\n",
       "         [-59.618687 , -79.15121  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 60.00001907, -19.32074738]), array([32, 12, 38])),\n",
       "  'info': {'type': array([32, 12, 38])}},\n",
       " {'iter': 1,\n",
       "  'episode': 20,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[24.025032, 22.250618],\n",
       "         [34.840687, 36.79601 ],\n",
       "         [22.821428, 14.742554]], dtype=float32),\n",
       "  'reward': 3.4525519000658513,\n",
       "  'newState': (array([18.31285095, 26.21081543]), array([32, 30, 22])),\n",
       "  'info': {'type': array([32, 30, 22])}},\n",
       " {'iter': 1,\n",
       "  'episode': 20,\n",
       "  'step': 1,\n",
       "  'oldState': (array([18.31285095, 26.21081543]), array([32, 30, 22])),\n",
       "  'action': array([[20.494707, 20.698957],\n",
       "         [15.770945,  2.785263],\n",
       "         [10.375342, 12.372011]], dtype=float32),\n",
       "  'reward': 2.334684247944434,\n",
       "  'newState': (array([-28.32814407,  -9.64541626]), array([ 5, 27, 31])),\n",
       "  'info': {'type': array([ 5, 27, 31])}},\n",
       " {'iter': 1,\n",
       "  'episode': 20,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-28.32814407,  -9.64541626]), array([ 5, 27, 31])),\n",
       "  'action': array([[-0.7118798, -2.205902 ],\n",
       "         [-1.9303532, -0.6432712],\n",
       "         [-8.81799  , -8.328424 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-16.86792088,   1.53218174]), array([41, 22, 12])),\n",
       "  'info': {'type': array([41, 22, 12])}},\n",
       " {'iter': 1,\n",
       "  'episode': 21,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.49229017, 0.71469617],\n",
       "         [1.3407148 , 1.1170442 ],\n",
       "         [0.59483385, 0.5364243 ]], dtype=float32),\n",
       "  'reward': -0.18471113368763528,\n",
       "  'newState': (array([97.5721612 , 97.63183546]), array([45, 22, 38])),\n",
       "  'info': {'type': array([45, 22, 38])}},\n",
       " {'iter': 1,\n",
       "  'episode': 21,\n",
       "  'step': 1,\n",
       "  'oldState': (array([97.5721612 , 97.63183546]), array([45, 22, 38])),\n",
       "  'action': array([[69.01535 , 49.320255],\n",
       "         [93.2931  , 43.35074 ],\n",
       "         [61.138634, 62.71482 ]], dtype=float32),\n",
       "  'reward': 4.3485303696268875,\n",
       "  'newState': (array([-125.87492132,  -57.75396776]), array([18, 29, 29])),\n",
       "  'info': {'type': array([18, 29, 29])}},\n",
       " {'iter': 1,\n",
       "  'episode': 21,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-125.87492132,  -57.75396776]), array([18, 29, 29])),\n",
       "  'action': array([[-45.651833, -41.840668],\n",
       "         [-42.790047, -25.146036],\n",
       "         [-51.953526, -29.897226]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([14.52047968, 39.12995863]), array([18, 31, 49])),\n",
       "  'info': {'type': array([18, 31, 49])}},\n",
       " {'iter': 1,\n",
       "  'episode': 22,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[28.185434 ,  6.808953 ],\n",
       "         [ 9.359803 ,  3.9419103],\n",
       "         [ 4.6937714, 24.348434 ]], dtype=float32),\n",
       "  'reward': 2.2029861691956096,\n",
       "  'newState': (array([57.76099014, 64.90070343]), array([34, 19, 29])),\n",
       "  'info': {'type': array([34, 19, 29])}},\n",
       " {'iter': 1,\n",
       "  'episode': 22,\n",
       "  'step': 1,\n",
       "  'oldState': (array([57.76099014, 64.90070343]), array([34, 19, 29])),\n",
       "  'action': array([[ 7.9243126, 60.15804  ],\n",
       "         [ 4.2141476,  8.588542 ],\n",
       "         [52.305775 , 14.685149 ]], dtype=float32),\n",
       "  'reward': 2.8435136292733256,\n",
       "  'newState': (array([ -6.68324661, -18.53102875]), array([45, 43, 22])),\n",
       "  'info': {'type': array([45, 43, 22])}},\n",
       " {'iter': 1,\n",
       "  'episode': 22,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -6.68324661, -18.53102875]), array([45, 43, 22])),\n",
       "  'action': array([[-0.6091976, -5.624411 ],\n",
       "         [-4.931127 , -5.769279 ],\n",
       "         [-5.8530927, -3.989938 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 4.71017075, -3.14740086]), array([15,  7, 48])),\n",
       "  'info': {'type': array([15,  7, 48])}},\n",
       " {'iter': 1,\n",
       "  'episode': 23,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.3033853, 2.8527322],\n",
       "         [2.4377525, 1.8171265],\n",
       "         [0.1720968, 1.9139187]], dtype=float32),\n",
       "  'reward': 0.8216026536564796,\n",
       "  'newState': (array([94.08676577, 93.41622257]), array([28, 19, 27])),\n",
       "  'info': {'type': array([28, 19, 27])}},\n",
       " {'iter': 1,\n",
       "  'episode': 23,\n",
       "  'step': 1,\n",
       "  'oldState': (array([94.08676577, 93.41622257]), array([28, 19, 27])),\n",
       "  'action': array([[67.13441 , 73.710266],\n",
       "         [45.5349  , 12.813009],\n",
       "         [43.214542, 61.2912  ]], dtype=float32),\n",
       "  'reward': 3.9429162228141212,\n",
       "  'newState': (array([-61.79708433, -54.39826107]), array([43, 19, 15])),\n",
       "  'info': {'type': array([43, 19, 15])}},\n",
       " {'iter': 1,\n",
       "  'episode': 23,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-61.79708433, -54.39826107]), array([43, 19, 15])),\n",
       "  'action': array([[-50.695435, -50.120594],\n",
       "         [-38.12356 ,  -5.978957],\n",
       "         [-26.001078, -49.885185]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([53.02299166, 51.58648014]), array([ 6, 24, 22])),\n",
       "  'info': {'type': array([ 6, 24, 22])}},\n",
       " {'iter': 1,\n",
       "  'episode': 24,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[41.654484 , 50.84787  ],\n",
       "         [13.7209215,  2.5322278],\n",
       "         [12.420604 , 37.642715 ]], dtype=float32),\n",
       "  'reward': 2.121029964876177,\n",
       "  'newState': (array([32.20399475,  8.97718811]), array([11, 37,  1])),\n",
       "  'info': {'type': array([11, 37,  1])}},\n",
       " {'iter': 1,\n",
       "  'episode': 24,\n",
       "  'step': 1,\n",
       "  'oldState': (array([32.20399475,  8.97718811]), array([11, 37,  1])),\n",
       "  'action': array([[15.629205, 24.299536],\n",
       "         [21.872522, 27.869339],\n",
       "         [31.300018, 16.503986]], dtype=float32),\n",
       "  'reward': 3.2086972833750824,\n",
       "  'newState': (array([-36.5977478 , -59.69567871]), array([29, 15, 34])),\n",
       "  'info': {'type': array([29, 15, 34])}},\n",
       " {'iter': 1,\n",
       "  'episode': 24,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-36.5977478 , -59.69567871]), array([29, 15, 34])),\n",
       "  'action': array([[ -3.0263531, -14.702204 ],\n",
       "         [ -6.131665 , -30.154655 ],\n",
       "         [ -7.7249556, -33.937363 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-19.71477509,  19.09854126]), array([22, 45, 42])),\n",
       "  'info': {'type': array([22, 45, 42])}},\n",
       " {'iter': 1,\n",
       "  'episode': 25,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 7.7842455, 15.915499 ],\n",
       "         [11.658256 , 10.601428 ],\n",
       "         [13.670193 ,  6.93843  ]], dtype=float32),\n",
       "  'reward': 2.289386294453977,\n",
       "  'newState': (array([66.88730621, 66.5446434 ]), array([22, 45, 39])),\n",
       "  'info': {'type': array([22, 45, 39])}},\n",
       " {'iter': 1,\n",
       "  'episode': 25,\n",
       "  'step': 1,\n",
       "  'oldState': (array([66.88730621, 66.5446434 ]), array([22, 45, 39])),\n",
       "  'action': array([[34.405525 , 13.948236 ],\n",
       "         [ 6.5620403, 53.792873 ],\n",
       "         [14.591578 , 33.492165 ]], dtype=float32),\n",
       "  'reward': 3.8511032361294855,\n",
       "  'newState': (array([ 11.32816315, -34.68863297]), array([18, 40, 44])),\n",
       "  'info': {'type': array([18, 40, 44])}},\n",
       " {'iter': 1,\n",
       "  'episode': 25,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 11.32816315, -34.68863297]), array([18, 40, 44])),\n",
       "  'action': array([[8.105989  , 3.334963  ],\n",
       "         [0.70003814, 5.169047  ],\n",
       "         [4.7193923 , 5.78663   ]], dtype=float32),\n",
       "  'reward': 2.028040507233079,\n",
       "  'newState': (array([ -2.19725609, -48.97927284]), array([16, 17, 43])),\n",
       "  'info': {'type': array([16, 17, 43])}},\n",
       " {'iter': 1,\n",
       "  'episode': 26,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.6580024 , -0.00428802],\n",
       "         [-1.4670942 , -0.22201   ],\n",
       "         [-0.41850698, -1.2122098 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([102.54360342, 101.4385078 ]), array([24, 38,  0])),\n",
       "  'info': {'type': array([24, 38,  0])}},\n",
       " {'iter': 1,\n",
       "  'episode': 26,\n",
       "  'step': 1,\n",
       "  'oldState': (array([102.54360342, 101.4385078 ]), array([24, 38,  0])),\n",
       "  'action': array([[ 9.871337, 41.878815],\n",
       "         [81.56699 , 47.353615],\n",
       "         [68.86526 , 77.62615 ]], dtype=float32),\n",
       "  'reward': 3.250672374437413,\n",
       "  'newState': (array([-57.75998545, -65.42007375]), array([48, 33, 18])),\n",
       "  'info': {'type': array([48, 33, 18])}},\n",
       " {'iter': 1,\n",
       "  'episode': 26,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-57.75998545, -65.42007375]), array([48, 33, 18])),\n",
       "  'action': array([[-48.205112 ,  -7.3129997],\n",
       "         [-20.457314 , -48.38179  ],\n",
       "         [-56.752792 , -53.263905 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([67.65523672, 43.53862071]), array([ 7, 14, 36])),\n",
       "  'info': {'type': array([ 7, 14, 36])}},\n",
       " {'iter': 1,\n",
       "  'episode': 27,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[39.46868 , 63.879677],\n",
       "         [ 9.564318,  8.810733],\n",
       "         [26.905209, 35.101673]], dtype=float32),\n",
       "  'reward': 2.835518566237072,\n",
       "  'newState': (array([24.0617981 , -7.79208374]), array([26, 32,  1])),\n",
       "  'info': {'type': array([26, 32,  1])}},\n",
       " {'iter': 1,\n",
       "  'episode': 27,\n",
       "  'step': 1,\n",
       "  'oldState': (array([24.0617981 , -7.79208374]), array([26, 32,  1])),\n",
       "  'action': array([[14.042005 ,  4.491759 ],\n",
       "         [20.418125 ,  2.3746665],\n",
       "         [12.498061 ,  9.637034 ]], dtype=float32),\n",
       "  'reward': 1.685863902499847,\n",
       "  'newState': (array([-22.89639282, -24.29554367]), array([48, 24, 22])),\n",
       "  'info': {'type': array([48, 24, 22])}},\n",
       " {'iter': 1,\n",
       "  'episode': 27,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-22.89639282, -24.29554367]), array([48, 24, 22])),\n",
       "  'action': array([[-11.049485  , -17.555014  ],\n",
       "         [-11.447725  , -15.372083  ],\n",
       "         [-10.665321  ,  -0.61962426]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([10.26613998,  9.25117874]), array([34, 30, 21])),\n",
       "  'info': {'type': array([34, 30, 21])}},\n",
       " {'iter': 1,\n",
       "  'episode': 28,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 5.4455047, 10.261682 ],\n",
       "         [ 3.4941125,  7.238932 ],\n",
       "         [ 3.3960328,  7.9906464]], dtype=float32),\n",
       "  'reward': 1.9038635130449972,\n",
       "  'newState': (array([87.66435051, 74.50873947]), array([ 4,  3, 48])),\n",
       "  'info': {'type': array([ 4,  3, 48])}},\n",
       " {'iter': 1,\n",
       "  'episode': 28,\n",
       "  'step': 1,\n",
       "  'oldState': (array([87.66435051, 74.50873947]), array([ 4,  3, 48])),\n",
       "  'action': array([[43.432663, 64.82975 ],\n",
       "         [62.043293, 86.97158 ],\n",
       "         [78.41147 , 32.058258]], dtype=float32),\n",
       "  'reward': 4.623803345611622,\n",
       "  'newState': (array([ -96.22307014, -109.35084915]), array([18, 33, 11])),\n",
       "  'info': {'type': array([18, 33, 11])}},\n",
       " {'iter': 1,\n",
       "  'episode': 28,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -96.22307014, -109.35084915]), array([18, 33, 11])),\n",
       "  'action': array([[-57.59795 , -54.688374],\n",
       "         [-14.741721,  -9.820925],\n",
       "         [-91.13353 , -53.53857 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([67.25013542,  8.69701767]), array([11, 12,  4])),\n",
       "  'info': {'type': array([11, 12,  4])}},\n",
       " {'iter': 1,\n",
       "  'episode': 29,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 0.7076042,  6.142594 ],\n",
       "         [56.303448 , 29.732492 ],\n",
       "         [36.576504 , 29.679539 ]], dtype=float32),\n",
       "  'reward': 2.0893863336590663,\n",
       "  'newState': (array([ 6.41244507, 34.44537354]), array([45,  0, 25])),\n",
       "  'info': {'type': array([45,  0, 25])}},\n",
       " {'iter': 1,\n",
       "  'episode': 29,\n",
       "  'step': 1,\n",
       "  'oldState': (array([ 6.41244507, 34.44537354]), array([45,  0, 25])),\n",
       "  'action': array([[10.7107725, 27.757954 ],\n",
       "         [ 9.633477 , 26.225729 ],\n",
       "         [17.974802 , 24.12428  ]], dtype=float32),\n",
       "  'reward': 2.860098564072405,\n",
       "  'newState': (array([-31.90660858, -43.66259003]), array([40,  7,  7])),\n",
       "  'info': {'type': array([40,  7,  7])}},\n",
       " {'iter': 1,\n",
       "  'episode': 29,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-31.90660858, -43.66259003]), array([40,  7,  7])),\n",
       "  'action': array([[ -7.0333905 , -27.453587  ],\n",
       "         [-19.669662  ,  -0.7294216 ],\n",
       "         [ -0.28922784,  -4.4857783 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ -4.91432762, -10.99380493]), array([33,  7, 34])),\n",
       "  'info': {'type': array([33,  7, 34])}},\n",
       " {'iter': 1,\n",
       "  'episode': 30,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.7038689, -1.6196551],\n",
       "         [-2.389932 , -3.6248746],\n",
       "         [-1.4071847, -2.9002337]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([105.50098515, 108.14476395]), array([ 4,  5, 39])),\n",
       "  'info': {'type': array([ 4,  5, 39])}},\n",
       " {'iter': 1,\n",
       "  'episode': 30,\n",
       "  'step': 1,\n",
       "  'oldState': (array([105.50098515, 108.14476395]), array([ 4,  5, 39])),\n",
       "  'action': array([[75.728935, 18.572844],\n",
       "         [18.144417, 28.158443],\n",
       "         [77.26664 , 80.63085 ]], dtype=float32),\n",
       "  'reward': 4.82112026874262,\n",
       "  'newState': (array([-65.63899899, -19.21737289]), array([12, 45, 32])),\n",
       "  'info': {'type': array([12, 45, 32])}},\n",
       " {'iter': 1,\n",
       "  'episode': 30,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-65.63899899, -19.21737289]), array([12, 45, 32])),\n",
       "  'action': array([[ -1.9183108, -13.056097 ],\n",
       "         [-17.816158 , -12.76029  ],\n",
       "         [ -5.42077  ,  -1.5966154]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-40.48375988,   8.19562912]), array([21, 28,  7])),\n",
       "  'info': {'type': array([21, 28,  7])}},\n",
       " {'iter': 1,\n",
       "  'episode': 31,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.36195424, 3.5598316 ],\n",
       "         [1.9479593 , 3.1486435 ],\n",
       "         [7.650399  , 0.9089473 ]], dtype=float32),\n",
       "  'reward': 0.425332982817734,\n",
       "  'newState': (array([90.03968716, 92.38257742]), array([28, 47, 25])),\n",
       "  'info': {'type': array([28, 47, 25])}},\n",
       " {'iter': 1,\n",
       "  'episode': 31,\n",
       "  'step': 1,\n",
       "  'oldState': (array([90.03968716, 92.38257742]), array([28, 47, 25])),\n",
       "  'action': array([[80.6174   ,  7.4088907],\n",
       "         [72.03021  , 56.99565  ],\n",
       "         [40.73024  , 13.229201 ]], dtype=float32),\n",
       "  'reward': 4.126376471047696,\n",
       "  'newState': (array([-103.33816624,   14.74883413]), array([41, 33,  1])),\n",
       "  'info': {'type': array([41, 33,  1])}},\n",
       " {'iter': 1,\n",
       "  'episode': 31,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-103.33816624,   14.74883413]), array([41, 33,  1])),\n",
       "  'action': array([[ 6.3141704, 13.9222555],\n",
       "         [ 7.8876224,  9.974602 ],\n",
       "         [14.453933 ,  9.931036 ]], dtype=float32),\n",
       "  'reward': 2.0620000711732955,\n",
       "  'newState': (array([-131.99389172,  -19.07906199]), array([13, 38, 21])),\n",
       "  'info': {'type': array([13, 38, 21])}},\n",
       " {'iter': 1,\n",
       "  'episode': 32,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -4.867081, -10.699197],\n",
       "         [-10.786405,  -7.24202 ],\n",
       "         [-14.972508,  -3.196523]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([130.62599564, 121.13774109]), array([27, 38, 20])),\n",
       "  'info': {'type': array([27, 38, 20])}},\n",
       " {'iter': 1,\n",
       "  'episode': 32,\n",
       "  'step': 1,\n",
       "  'oldState': (array([130.62599564, 121.13774109]), array([27, 38, 20])),\n",
       "  'action': array([[42.424046 , 50.535763 ],\n",
       "         [98.317154 ,  6.9631653],\n",
       "         [ 9.783723 , 40.60291  ]], dtype=float32),\n",
       "  'reward': 2.9803168154208146,\n",
       "  'newState': (array([-19.89892197,  23.03590393]), array([33,  1, 31])),\n",
       "  'info': {'type': array([33,  1, 31])}},\n",
       " {'iter': 1,\n",
       "  'episode': 32,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-19.89892197,  23.03590393]), array([33,  1, 31])),\n",
       "  'action': array([[16.831158 , 16.820478 ],\n",
       "         [ 4.1716065,  1.2869625],\n",
       "         [ 5.123706 , 14.8905735]], dtype=float32),\n",
       "  'reward': 2.866288608600695,\n",
       "  'newState': (array([-46.02539062,  -9.96211243]), array([49, 38, 28])),\n",
       "  'info': {'type': array([49, 38, 28])}},\n",
       " {'iter': 1,\n",
       "  'episode': 33,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.2603861, -1.0463953],\n",
       "         [-3.2841306, -5.7839165],\n",
       "         [-3.867224 , -5.8781962]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([108.4117403 , 112.70850754]), array([11, 35, 31])),\n",
       "  'info': {'type': array([11, 35, 31])}},\n",
       " {'iter': 1,\n",
       "  'episode': 33,\n",
       "  'step': 1,\n",
       "  'oldState': (array([108.4117403 , 112.70850754]), array([11, 35, 31])),\n",
       "  'action': array([[ 73.41215 ,   4.286383],\n",
       "         [109.57782 ,  69.23043 ],\n",
       "         [ 83.14828 ,  72.096306]], dtype=float32),\n",
       "  'reward': 4.57094101715654,\n",
       "  'newState': (array([-157.72650433,  -32.90462112]), array([ 2,  3, 32])),\n",
       "  'info': {'type': array([ 2,  3, 32])}},\n",
       " {'iter': 1,\n",
       "  'episode': 33,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-157.72650433,  -32.90462112]), array([ 2,  3, 32])),\n",
       "  'action': array([[-28.29536 , -24.03428 ],\n",
       "         [-10.94555 , -26.856867],\n",
       "         [ -3.091209, -29.475168]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-115.39438534,   47.46169662]), array([10, 32, 33])),\n",
       "  'info': {'type': array([10, 32, 33])}},\n",
       " {'iter': 1,\n",
       "  'episode': 34,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[44.286926, 46.970306],\n",
       "         [19.988321, 30.776669],\n",
       "         [14.695952, 13.486474]], dtype=float32),\n",
       "  'reward': 3.552994086032568,\n",
       "  'newState': (array([21.02880096,  8.76654816]), array([ 5,  0, 37])),\n",
       "  'info': {'type': array([ 5,  0, 37])}},\n",
       " {'iter': 1,\n",
       "  'episode': 34,\n",
       "  'step': 1,\n",
       "  'oldState': (array([21.02880096,  8.76654816]), array([ 5,  0, 37])),\n",
       "  'action': array([[6.416517  , 6.03328   ],\n",
       "         [7.8074484 , 0.07216553],\n",
       "         [4.224666  , 0.2891893 ]], dtype=float32),\n",
       "  'reward': 1.5490235268098151,\n",
       "  'newState': (array([2.58016968, 2.37191343]), array([46,  8, 43])),\n",
       "  'info': {'type': array([46,  8, 43])}},\n",
       " {'iter': 1,\n",
       "  'episode': 34,\n",
       "  'step': 2,\n",
       "  'oldState': (array([2.58016968, 2.37191343]), array([46,  8, 43])),\n",
       "  'action': array([[0.67868054, 2.227894  ],\n",
       "         [2.3639357 , 0.01087312],\n",
       "         [0.79074365, 0.41118658]], dtype=float32),\n",
       "  'reward': -0.47518116728921417,\n",
       "  'newState': (array([-1.25319028, -0.27804041]), array([44, 24, 16])),\n",
       "  'info': {'type': array([44, 24, 16])}},\n",
       " {'iter': 1,\n",
       "  'episode': 35,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.10527242, -0.01486408],\n",
       "         [-0.1155922 , -0.11340897],\n",
       "         [-0.17504938, -0.16888762]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([100.39591402, 100.29716066]), array([32, 32, 41])),\n",
       "  'info': {'type': array([32, 32, 41])}},\n",
       " {'iter': 1,\n",
       "  'episode': 35,\n",
       "  'step': 1,\n",
       "  'oldState': (array([100.39591402, 100.29716066]), array([32, 32, 41])),\n",
       "  'action': array([[ 4.3691883, 12.052384 ],\n",
       "         [46.677063 , 51.601273 ],\n",
       "         [54.960327 , 29.849253 ]], dtype=float32),\n",
       "  'reward': 3.3851114616480102,\n",
       "  'newState': (array([-5.61066252,  6.79425386]), array([24, 21, 27])),\n",
       "  'info': {'type': array([24, 21, 27])}},\n",
       " {'iter': 1,\n",
       "  'episode': 35,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-5.61066252,  6.79425386]), array([24, 21, 27])),\n",
       "  'action': array([[4.199679  , 0.6770473 ],\n",
       "         [2.2795413 , 3.5791488 ],\n",
       "         [0.02747301, 4.013748  ]], dtype=float32),\n",
       "  'reward': 1.373952575525755,\n",
       "  'newState': (array([-12.11735588,  -1.47569034]), array([46, 35,  4])),\n",
       "  'info': {'type': array([46, 35,  4])}},\n",
       " {'iter': 1,\n",
       "  'episode': 36,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.1750394 , -1.4364622 ],\n",
       "         [-0.03823918, -0.2691075 ],\n",
       "         [-0.81493235, -1.0193149 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([102.02821112, 102.72488451]), array([32, 45, 24])),\n",
       "  'info': {'type': array([32, 45, 24])}},\n",
       " {'iter': 1,\n",
       "  'episode': 36,\n",
       "  'step': 1,\n",
       "  'oldState': (array([102.02821112, 102.72488451]), array([32, 45, 24])),\n",
       "  'action': array([[74.24924 , 96.42367 ],\n",
       "         [65.51002 , 14.083635],\n",
       "         [11.078245, 32.13054 ]], dtype=float32),\n",
       "  'reward': 3.4381023703340396,\n",
       "  'newState': (array([-48.80928278, -39.91296339]), array([38, 42, 25])),\n",
       "  'info': {'type': array([38, 42, 25])}},\n",
       " {'iter': 1,\n",
       "  'episode': 36,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-48.80928278, -39.91296339]), array([38, 42, 25])),\n",
       "  'action': array([[-36.36259 , -22.4656  ],\n",
       "         [ -8.9042  , -33.222878],\n",
       "         [-10.316573, -38.710754]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 6.77408361, 54.48626757]), array([32, 40, 33])),\n",
       "  'info': {'type': array([32, 40, 33])}},\n",
       " {'iter': 1,\n",
       "  'episode': 37,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[50.289413, 33.472702],\n",
       "         [51.829964, 44.574886],\n",
       "         [10.1874  , 25.857685]], dtype=float32),\n",
       "  'reward': 3.8279744533128386,\n",
       "  'newState': (array([-12.30677795,  -3.90527344]), array([ 6,  1, 31])),\n",
       "  'info': {'type': array([ 6,  1, 31])}},\n",
       " {'iter': 1,\n",
       "  'episode': 37,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-12.30677795,  -3.90527344]), array([ 6,  1, 31])),\n",
       "  'action': array([[-1.4195794 , -3.2943742 ],\n",
       "         [-3.074052  , -0.2811189 ],\n",
       "         [-0.43347064, -2.9823542 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-7.37967587,  2.65257359]), array([ 7, 13,  3])),\n",
       "  'info': {'type': array([ 7, 13,  3])}},\n",
       " {'iter': 1,\n",
       "  'episode': 37,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-7.37967587,  2.65257359]), array([ 7, 13,  3])),\n",
       "  'action': array([[0.93435353, 0.03342841],\n",
       "         [1.1698784 , 0.8524144 ],\n",
       "         [0.3548732 , 0.39391458]], dtype=float32),\n",
       "  'reward': -0.1486553758453416,\n",
       "  'newState': (array([-9.83878088,  1.37281609]), array([28, 15, 29])),\n",
       "  'info': {'type': array([28, 15, 29])}},\n",
       " {'iter': 1,\n",
       "  'episode': 38,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.221681  , 0.9938016 ],\n",
       "         [1.2302808 , 1.2348546 ],\n",
       "         [0.86072356, 1.1687052 ]], dtype=float32),\n",
       "  'reward': 0.2370043302186157,\n",
       "  'newState': (array([96.68731475, 96.60263848]), array([ 2, 47, 19])),\n",
       "  'info': {'type': array([ 2, 47, 19])}},\n",
       " {'iter': 1,\n",
       "  'episode': 38,\n",
       "  'step': 1,\n",
       "  'oldState': (array([96.68731475, 96.60263848]), array([ 2, 47, 19])),\n",
       "  'action': array([[16.509588, 54.31322 ],\n",
       "         [52.419018, 27.131235],\n",
       "         [14.081417, 29.566967]], dtype=float32),\n",
       "  'reward': 3.4189304006482484,\n",
       "  'newState': (array([ 13.67728972, -14.40879035]), array([32, 18, 40])),\n",
       "  'info': {'type': array([32, 18, 40])}},\n",
       " {'iter': 1,\n",
       "  'episode': 38,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 13.67728972, -14.40879035]), array([32, 18, 40])),\n",
       "  'action': array([[7.5491414, 2.6070175],\n",
       "         [7.386885 , 7.48062  ],\n",
       "         [3.082464 , 7.163424 ]], dtype=float32),\n",
       "  'reward': 2.155362476128058,\n",
       "  'newState': (array([ -4.34120011, -31.65985084]), array([34, 30, 32])),\n",
       "  'info': {'type': array([34, 30, 32])}},\n",
       " {'iter': 1,\n",
       "  'episode': 39,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.15568589, -2.4600627 ],\n",
       "         [-0.10160578, -0.5571951 ],\n",
       "         [-2.8567646 , -2.0003436 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([103.11405611, 105.01760149]), array([49, 46, 19])),\n",
       "  'info': {'type': array([49, 46, 19])}},\n",
       " {'iter': 1,\n",
       "  'episode': 39,\n",
       "  'step': 1,\n",
       "  'oldState': (array([103.11405611, 105.01760149]), array([49, 46, 19])),\n",
       "  'action': array([[ 74.50677 , 103.953316],\n",
       "         [ 10.875583,  39.881466],\n",
       "         [ 86.852356, 100.956566]], dtype=float32),\n",
       "  'reward': 4.212794935039398,\n",
       "  'newState': (array([ -69.12065458, -139.77374983]), array([41, 20, 40])),\n",
       "  'info': {'type': array([41, 20, 40])}},\n",
       " {'iter': 1,\n",
       "  'episode': 39,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -69.12065458, -139.77374983]), array([41, 20, 40])),\n",
       "  'action': array([[-15.577977, -53.98792 ],\n",
       "         [-27.426355, -37.414463],\n",
       "         [-58.050793, -21.884476]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 31.93447542, -26.48689222]), array([46,  4,  9])),\n",
       "  'info': {'type': array([46,  4,  9])}},\n",
       " {'iter': 1,\n",
       "  'episode': 40,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[18.904026, 11.959782],\n",
       "         [ 9.267339, 14.92737 ],\n",
       "         [13.024069, 17.151823]], dtype=float32),\n",
       "  'reward': 2.8309625723463134,\n",
       "  'newState': (array([58.80456543, 55.96102524]), array([ 0, 26, 21])),\n",
       "  'info': {'type': array([ 0, 26, 21])}},\n",
       " {'iter': 1,\n",
       "  'episode': 40,\n",
       "  'step': 1,\n",
       "  'oldState': (array([58.80456543, 55.96102524]), array([ 0, 26, 21])),\n",
       "  'action': array([[18.90896  , 14.438589 ],\n",
       "         [41.756744 ,  0.3067925],\n",
       "         [ 2.821632 ,  5.4051385]], dtype=float32),\n",
       "  'reward': 0.28795933335959045,\n",
       "  'newState': (array([-4.68276978, 35.81050491]), array([10, 21, 33])),\n",
       "  'info': {'type': array([10, 21, 33])}},\n",
       " {'iter': 1,\n",
       "  'episode': 40,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-4.68276978, 35.81050491]), array([10, 21, 33])),\n",
       "  'action': array([[ 4.872101, 22.765495],\n",
       "         [ 0.785342, 20.57169 ],\n",
       "         [12.440604, 10.040995]], dtype=float32),\n",
       "  'reward': 2.844632667290513,\n",
       "  'newState': (array([-22.78081703, -17.56767654]), array([38, 37, 43])),\n",
       "  'info': {'type': array([38, 37, 43])}},\n",
       " {'iter': 1,\n",
       "  'episode': 41,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -8.223022 ,  -5.545195 ],\n",
       "         [-15.053346 ,  -4.5006638],\n",
       "         [-14.909217 ,  -7.661791 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([138.18558502, 117.70764923]), array([39, 33, 31])),\n",
       "  'info': {'type': array([39, 33, 31])}},\n",
       " {'iter': 1,\n",
       "  'episode': 41,\n",
       "  'step': 1,\n",
       "  'oldState': (array([138.18558502, 117.70764923]), array([39, 33, 31])),\n",
       "  'action': array([[101.95132 , 106.82991 ],\n",
       "         [110.96147 , 104.1462  ],\n",
       "         [ 13.440417,  48.485813]], dtype=float32),\n",
       "  'reward': 4.481270276259317,\n",
       "  'newState': (array([ -88.16761017, -141.75426483]), array([41,  7,  5])),\n",
       "  'info': {'type': array([41,  7,  5])}},\n",
       " {'iter': 1,\n",
       "  'episode': 41,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -88.16761017, -141.75426483]), array([41,  7,  5])),\n",
       "  'action': array([[-34.82264 , -30.16376 ],\n",
       "         [-18.457754, -46.67626 ],\n",
       "         [-53.509415, -16.702707]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 18.62220001, -48.21154022]), array([ 6, 23, 22])),\n",
       "  'info': {'type': array([ 6, 23, 22])}},\n",
       " {'iter': 1,\n",
       "  'episode': 42,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[12.699619 , 16.600965 ],\n",
       "         [16.277302 , 16.129602 ],\n",
       "         [ 7.9180226, 18.415014 ]], dtype=float32),\n",
       "  'reward': 2.7237684546293566,\n",
       "  'newState': (array([63.10505676, 48.85441589]), array([42, 39, 31])),\n",
       "  'info': {'type': array([42, 39, 31])}},\n",
       " {'iter': 1,\n",
       "  'episode': 42,\n",
       "  'step': 1,\n",
       "  'oldState': (array([63.10505676, 48.85441589]), array([42, 39, 31])),\n",
       "  'action': array([[22.50039 , 50.83562 ],\n",
       "         [39.136726, 54.612297],\n",
       "         [11.549907, 16.768488]], dtype=float32),\n",
       "  'reward': 3.485958324796498,\n",
       "  'newState': (array([-10.08196259, -73.36199188]), array([37, 38, 23])),\n",
       "  'info': {'type': array([37, 38, 23])}},\n",
       " {'iter': 1,\n",
       "  'episode': 42,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-10.08196259, -73.36199188]), array([37, 38, 23])),\n",
       "  'action': array([[-8.41693  , -3.4275093],\n",
       "         [-8.443699 , -9.501868 ],\n",
       "         [-5.0491476, -7.9923778]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 11.82781601, -52.44023705]), array([28, 36,  2])),\n",
       "  'info': {'type': array([28, 36,  2])}},\n",
       " {'iter': 1,\n",
       "  'episode': 43,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 5.83239  ,  4.3092074],\n",
       "         [ 1.6854324,  6.6178126],\n",
       "         [10.651974 , 10.03092  ]], dtype=float32),\n",
       "  'reward': 1.9127476506929275,\n",
       "  'newState': (array([81.83020401, 79.04206085]), array([10, 20,  0])),\n",
       "  'info': {'type': array([10, 20,  0])}},\n",
       " {'iter': 1,\n",
       "  'episode': 43,\n",
       "  'step': 1,\n",
       "  'oldState': (array([81.83020401, 79.04206085]), array([10, 20,  0])),\n",
       "  'action': array([[54.305847, 35.134758],\n",
       "         [45.317055, 24.384068],\n",
       "         [50.631603, 44.29265 ]], dtype=float32),\n",
       "  'reward': 3.4608306007051954,\n",
       "  'newState': (array([-68.42429733, -24.76941681]), array([16, 30,  3])),\n",
       "  'info': {'type': array([16, 30,  3])}},\n",
       " {'iter': 1,\n",
       "  'episode': 43,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-68.42429733, -24.76941681]), array([16, 30,  3])),\n",
       "  'action': array([[-19.074795, -24.542967],\n",
       "         [-22.567835, -23.577133],\n",
       "         [-24.147453,  -9.869979]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-2.63421249, 33.22066498]), array([14, 44, 48])),\n",
       "  'info': {'type': array([14, 44, 48])}},\n",
       " {'iter': 1,\n",
       "  'episode': 44,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 0.7451939, 10.276594 ],\n",
       "         [ 6.949834 , 10.382943 ],\n",
       "         [ 6.843869 , 14.47892  ]], dtype=float32),\n",
       "  'reward': 1.431366836217367,\n",
       "  'newState': (array([85.46110344, 64.86154175]), array([ 5, 49, 10])),\n",
       "  'info': {'type': array([ 5, 49, 10])}},\n",
       " {'iter': 1,\n",
       "  'episode': 44,\n",
       "  'step': 1,\n",
       "  'oldState': (array([85.46110344, 64.86154175]), array([ 5, 49, 10])),\n",
       "  'action': array([[76.4543  , 65.989876],\n",
       "         [15.793109, 46.269527],\n",
       "         [79.92519 , 34.80907 ]], dtype=float32),\n",
       "  'reward': 4.015614826116448,\n",
       "  'newState': (array([-86.71150398, -82.20692444]), array([43, 46, 27])),\n",
       "  'info': {'type': array([43, 46, 27])}},\n",
       " {'iter': 1,\n",
       "  'episode': 44,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-86.71150398, -82.20692444]), array([43, 46, 27])),\n",
       "  'action': array([[-58.77237 , -53.70947 ],\n",
       "         [-67.347015, -25.866127],\n",
       "         [-37.533054, -52.183914]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([76.94093132, 49.55258179]), array([33,  8,  4])),\n",
       "  'info': {'type': array([33,  8,  4])}},\n",
       " {'iter': 1,\n",
       "  'episode': 45,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[31.778324, 31.83468 ],\n",
       "         [37.200367,  7.933627],\n",
       "         [43.22849 , 76.616844]], dtype=float32),\n",
       "  'reward': 2.7362390175407825,\n",
       "  'newState': (array([-12.20718384, -16.38514709]), array([39, 32, 47])),\n",
       "  'info': {'type': array([39, 32, 47])}},\n",
       " {'iter': 1,\n",
       "  'episode': 45,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-12.20718384, -16.38514709]), array([39, 32, 47])),\n",
       "  'action': array([[-11.978258 ,  -9.077286 ],\n",
       "         [ -5.6926312,  -6.5276575],\n",
       "         [ -3.0672312,  -2.8176246]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([8.53093719, 2.03742027]), array([33,  7, 33])),\n",
       "  'info': {'type': array([33,  7, 33])}},\n",
       " {'iter': 1,\n",
       "  'episode': 45,\n",
       "  'step': 2,\n",
       "  'oldState': (array([8.53093719, 2.03742027]), array([33,  7, 33])),\n",
       "  'action': array([[2.6188893, 4.531156 ],\n",
       "         [6.151559 , 1.4593929],\n",
       "         [7.0417213, 1.0052617]], dtype=float32),\n",
       "  'reward': 1.4141330519528685,\n",
       "  'newState': (array([-7.28123283, -4.95839024]), array([14, 13, 43])),\n",
       "  'info': {'type': array([14, 13, 43])}},\n",
       " {'iter': 1,\n",
       "  'episode': 46,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-3.2210648, -3.148068 ],\n",
       "         [-4.5948443, -1.990657 ],\n",
       "         [-3.7924004, -3.8843513]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([111.60830975, 109.02307606]), array([21, 36, 12])),\n",
       "  'info': {'type': array([21, 36, 12])}},\n",
       " {'iter': 1,\n",
       "  'episode': 46,\n",
       "  'step': 1,\n",
       "  'oldState': (array([111.60830975, 109.02307606]), array([21, 36, 12])),\n",
       "  'action': array([[29.807411 , 43.36454  ],\n",
       "         [75.86941  , 88.11724  ],\n",
       "         [86.535835 ,  8.7497225]], dtype=float32),\n",
       "  'reward': 4.1623839551413075,\n",
       "  'newState': (array([-80.60433674, -31.20843029]), array([26, 18, 37])),\n",
       "  'info': {'type': array([26, 18, 37])}},\n",
       " {'iter': 1,\n",
       "  'episode': 46,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-80.60433674, -31.20843029]), array([26, 18, 37])),\n",
       "  'action': array([[-26.217813, -20.49047 ],\n",
       "         [-21.733316, -23.275702],\n",
       "         [-25.002615, -22.798334]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-7.65059376, 35.35607624]), array([35, 12, 41])),\n",
       "  'info': {'type': array([35, 12, 41])}},\n",
       " {'iter': 1,\n",
       "  'episode': 47,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 6.1389327, 16.90125  ],\n",
       "         [22.813522 , 30.717865 ],\n",
       "         [15.709294 ,  1.0670309]], dtype=float32),\n",
       "  'reward': 2.8064084571369317,\n",
       "  'newState': (array([55.33824921, 51.3138504 ]), array([35, 25, 37])),\n",
       "  'info': {'type': array([35, 25, 37])}},\n",
       " {'iter': 1,\n",
       "  'episode': 47,\n",
       "  'step': 1,\n",
       "  'oldState': (array([55.33824921, 51.3138504 ]), array([35, 25, 37])),\n",
       "  'action': array([[42.48192  , 35.930588 ],\n",
       "         [ 5.5946465, 29.073378 ],\n",
       "         [25.812819 , 42.42923  ]], dtype=float32),\n",
       "  'reward': 3.83212964020698,\n",
       "  'newState': (array([-18.5511322 , -56.11934662]), array([ 1, 44, 41])),\n",
       "  'info': {'type': array([ 1, 44, 41])}},\n",
       " {'iter': 1,\n",
       "  'episode': 47,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-18.5511322 , -56.11934662]), array([ 1, 44, 41])),\n",
       "  'action': array([[ -3.5007112,  -5.6187553],\n",
       "         [ -4.827265 , -11.017342 ],\n",
       "         [ -3.7271326, -17.745289 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ -6.49602318, -21.73796082]), array([43,  0, 15])),\n",
       "  'info': {'type': array([43,  0, 15])}},\n",
       " {'iter': 1,\n",
       "  'episode': 48,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.04721941, -4.9313383 ],\n",
       "         [-5.9671893 , -5.0972443 ],\n",
       "         [-1.1640083 , -2.489525  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([107.17841673, 112.51810741]), array([28, 40,  6])),\n",
       "  'info': {'type': array([28, 40,  6])}},\n",
       " {'iter': 1,\n",
       "  'episode': 48,\n",
       "  'step': 1,\n",
       "  'oldState': (array([107.17841673, 112.51810741]), array([28, 40,  6])),\n",
       "  'action': array([[ 82.0692  ,  41.226917],\n",
       "         [ 29.862593,  43.10214 ],\n",
       "         [105.85296 ,  31.768732]], dtype=float32),\n",
       "  'reward': 4.101374507945856,\n",
       "  'newState': (array([-110.60634279,   -3.57967854]), array([49, 32, 26])),\n",
       "  'info': {'type': array([49, 32, 26])}},\n",
       " {'iter': 1,\n",
       "  'episode': 48,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-110.60634279,   -3.57967854]), array([49, 32, 26])),\n",
       "  'action': array([[-1.487002  , -0.4776103 ],\n",
       "         [-0.34321287, -0.34529778],\n",
       "         [-0.6948929 , -0.35821795]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-108.08123493,   -2.39855254]), array([20, 38,  1])),\n",
       "  'info': {'type': array([20, 38,  1])}},\n",
       " {'iter': 1,\n",
       "  'episode': 49,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.684268  , -1.8904597 ],\n",
       "         [-1.3481067 , -0.05495996],\n",
       "         [-2.384146  , -2.391338  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([105.41652107, 104.33675766]), array([16, 25, 19])),\n",
       "  'info': {'type': array([16, 25, 19])}},\n",
       " {'iter': 1,\n",
       "  'episode': 49,\n",
       "  'step': 1,\n",
       "  'oldState': (array([105.41652107, 104.33675766]), array([16, 25, 19])),\n",
       "  'action': array([[60.815243, 53.318592],\n",
       "         [62.050217, 87.41791 ],\n",
       "         [85.04233 , 40.78152 ]], dtype=float32),\n",
       "  'reward': 4.489262106909446,\n",
       "  'newState': (array([-102.49127007,  -77.18126297]), array([30,  0, 42])),\n",
       "  'info': {'type': array([30,  0, 42])}},\n",
       " {'iter': 1,\n",
       "  'episode': 49,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-102.49127007,  -77.18126297]), array([30,  0, 42])),\n",
       "  'action': array([[-55.847847 , -74.502846 ],\n",
       "         [-62.362434 , -55.500874 ],\n",
       "         [-46.383522 ,  -1.5003718]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([62.10254097, 54.32282639]), array([47, 21, 33])),\n",
       "  'info': {'type': array([47, 21, 33])}},\n",
       " {'iter': 1,\n",
       "  'episode': 50,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[25.895266, 47.571453],\n",
       "         [36.649204, 28.160353],\n",
       "         [50.13106 , 21.761486]], dtype=float32),\n",
       "  'reward': 3.364067354549992,\n",
       "  'newState': (array([-12.67553711,   2.50671387]), array([ 1, 25, 38])),\n",
       "  'info': {'type': array([ 1, 25, 38])}},\n",
       " {'iter': 1,\n",
       "  'episode': 50,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-12.67553711,   2.50671387]), array([ 1, 25, 38])),\n",
       "  'action': array([[1.5840577, 1.1018875],\n",
       "         [1.8565177, 1.9208105],\n",
       "         [2.2779362, 1.8269738]], dtype=float32),\n",
       "  'reward': 1.1006508633512633,\n",
       "  'newState': (array([-18.39404869,  -2.34295797]), array([12, 48, 18])),\n",
       "  'info': {'type': array([12, 48, 18])}},\n",
       " {'iter': 1,\n",
       "  'episode': 50,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-18.39404869,  -2.34295797]), array([12, 48, 18])),\n",
       "  'action': array([[-0.5447342 , -1.7013419 ],\n",
       "         [-0.96649003, -0.5242418 ],\n",
       "         [-0.44209135, -0.88665736]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-16.44073308,   0.76928282]), array([13, 13, 24])),\n",
       "  'info': {'type': array([13, 13, 24])}},\n",
       " {'iter': 2,\n",
       "  'episode': 1,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.01422403, 0.04019357],\n",
       "         [0.34939292, 0.01620932],\n",
       "         [0.16725788, 0.2857997 ]], dtype=float32),\n",
       "  'reward': -3.9687644215846283,\n",
       "  'newState': (array([99.46912515, 99.6577974 ]), array([44, 26, 19])),\n",
       "  'info': {'type': array([44, 26, 19])}},\n",
       " {'iter': 2,\n",
       "  'episode': 1,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.46912515, 99.6577974 ]), array([44, 26, 19])),\n",
       "  'action': array([[85.396545, 72.17133 ],\n",
       "         [44.35262 , 25.45045 ],\n",
       "         [98.61833 , 66.1675  ]], dtype=float32),\n",
       "  'reward': 4.23398657375043,\n",
       "  'newState': (array([-128.89836752,  -64.13147873]), array([39, 34, 15])),\n",
       "  'info': {'type': array([39, 34, 15])}},\n",
       " {'iter': 2,\n",
       "  'episode': 1,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-128.89836752,  -64.13147873]), array([39, 34, 15])),\n",
       "  'action': array([[-27.574656, -18.685976],\n",
       "         [-23.283012, -33.36155 ],\n",
       "         [-55.462917, -49.44236 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-22.57778037,  37.3584047 ]), array([37, 38, 32])),\n",
       "  'info': {'type': array([37, 38, 32])}},\n",
       " {'iter': 2,\n",
       "  'episode': 2,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[36.901848, 10.514861],\n",
       "         [14.434594, 17.885149],\n",
       "         [ 6.993552, 35.22038 ]], dtype=float32),\n",
       "  'reward': 3.19749631348864,\n",
       "  'newState': (array([41.6700058 , 36.37961197]), array([36, 34, 46])),\n",
       "  'info': {'type': array([36, 34, 46])}},\n",
       " {'iter': 2,\n",
       "  'episode': 2,\n",
       "  'step': 1,\n",
       "  'oldState': (array([41.6700058 , 36.37961197]), array([36, 34, 46])),\n",
       "  'action': array([[12.792665 ,  7.9832616],\n",
       "         [ 8.927025 , 35.98937  ],\n",
       "         [27.600357 ,  9.603331 ]], dtype=float32),\n",
       "  'reward': 3.2753771857060934,\n",
       "  'newState': (array([ -7.65003967, -17.19634628]), array([ 1, 32, 30])),\n",
       "  'info': {'type': array([ 1, 32, 30])}},\n",
       " {'iter': 2,\n",
       "  'episode': 2,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -7.65003967, -17.19634628]), array([ 1, 32, 30])),\n",
       "  'action': array([[-1.5563258 , -0.40598464],\n",
       "         [-5.3997526 , -1.5909436 ],\n",
       "         [-5.7153535 , -6.471132  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 5.02139282, -8.72828674]), array([37,  7, 48])),\n",
       "  'info': {'type': array([37,  7, 48])}},\n",
       " {'iter': 2,\n",
       "  'episode': 3,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.8164592 , 0.75817716],\n",
       "         [1.6233566 , 4.649958  ],\n",
       "         [2.9339125 , 1.9892296 ]], dtype=float32),\n",
       "  'reward': 1.4688990537068933,\n",
       "  'newState': (array([91.6262722 , 92.60263491]), array([32, 43, 41])),\n",
       "  'info': {'type': array([32, 43, 41])}},\n",
       " {'iter': 2,\n",
       "  'episode': 3,\n",
       "  'step': 1,\n",
       "  'oldState': (array([91.6262722 , 92.60263491]), array([32, 43, 41])),\n",
       "  'action': array([[82.62995  , 58.85953  ],\n",
       "         [ 4.6958346, 43.710518 ],\n",
       "         [29.892075 , 46.989807 ]], dtype=float32),\n",
       "  'reward': 4.152838858236586,\n",
       "  'newState': (array([-25.59158516, -56.95722532]), array([ 5,  1, 33])),\n",
       "  'info': {'type': array([ 5,  1, 33])}},\n",
       " {'iter': 2,\n",
       "  'episode': 3,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-25.59158516, -56.95722532]), array([ 5,  1, 33])),\n",
       "  'action': array([[-18.199707  ,  -0.53100514],\n",
       "         [ -1.7473413 , -18.940495  ],\n",
       "         [-21.886002  , -24.319841  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 16.24146461, -13.16588163]), array([30, 18, 49])),\n",
       "  'info': {'type': array([30, 18, 49])}},\n",
       " {'iter': 2,\n",
       "  'episode': 4,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 8.953312 ,  1.8386979],\n",
       "         [12.499548 ,  5.0717325],\n",
       "         [15.671309 , 14.726641 ]], dtype=float32),\n",
       "  'reward': 1.9369800026594106,\n",
       "  'newState': (array([62.8758316 , 78.36292839]), array([17, 18, 31])),\n",
       "  'info': {'type': array([17, 18, 31])}},\n",
       " {'iter': 2,\n",
       "  'episode': 4,\n",
       "  'step': 1,\n",
       "  'oldState': (array([62.8758316 , 78.36292839]), array([17, 18, 31])),\n",
       "  'action': array([[73.39606 ,  6.795724],\n",
       "         [73.72957 , 49.87248 ],\n",
       "         [ 4.888801, 37.562424]], dtype=float32),\n",
       "  'reward': 3.9333222744485394,\n",
       "  'newState': (array([-89.13858795, -15.86769295]), array([ 7, 21, 18])),\n",
       "  'info': {'type': array([ 7, 21, 18])}},\n",
       " {'iter': 2,\n",
       "  'episode': 4,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-89.13858795, -15.86769295]), array([ 7, 21, 18])),\n",
       "  'action': array([[-3.69331  , -2.4660711],\n",
       "         [-3.0566676, -4.5151987],\n",
       "         [-7.4920354, -6.002966 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-74.89657497,  -2.88345718]), array([46, 44, 27])),\n",
       "  'info': {'type': array([46, 44, 27])}},\n",
       " {'iter': 2,\n",
       "  'episode': 5,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.84818447, -0.2987152 ],\n",
       "         [-0.67817414, -0.8819873 ],\n",
       "         [-1.0681151 , -0.7321984 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([102.59447384, 101.91290092]), array([ 9,  4, 13])),\n",
       "  'info': {'type': array([ 9,  4, 13])}},\n",
       " {'iter': 2,\n",
       "  'episode': 5,\n",
       "  'step': 1,\n",
       "  'oldState': (array([102.59447384, 101.91290092]), array([ 9,  4, 13])),\n",
       "  'action': array([[29.77441 , 51.79444 ],\n",
       "         [60.879974, 84.26171 ],\n",
       "         [89.49926 , 25.920027]], dtype=float32),\n",
       "  'reward': 4.231153197374552,\n",
       "  'newState': (array([-77.55918217, -60.06328011]), array([23, 31, 37])),\n",
       "  'info': {'type': array([23, 31, 37])}},\n",
       " {'iter': 2,\n",
       "  'episode': 5,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-77.55918217, -60.06328011]), array([23, 31, 37])),\n",
       "  'action': array([[-49.34853 , -19.620258],\n",
       "         [-28.461142,  -9.956361],\n",
       "         [-44.620216, -10.444345]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 44.8707037 , -20.04231453]), array([ 0, 18, 31])),\n",
       "  'info': {'type': array([ 0, 18, 31])}},\n",
       " {'iter': 2,\n",
       "  'episode': 6,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[21.757103, 23.656675],\n",
       "         [17.286285, 12.854507],\n",
       "         [15.300234, 24.326258]], dtype=float32),\n",
       "  'reward': 2.8117233112322095,\n",
       "  'newState': (array([45.6563797 , 39.16255951]), array([ 1, 20, 14])),\n",
       "  'info': {'type': array([ 1, 20, 14])}},\n",
       " {'iter': 2,\n",
       "  'episode': 6,\n",
       "  'step': 1,\n",
       "  'oldState': (array([45.6563797 , 39.16255951]), array([ 1, 20, 14])),\n",
       "  'action': array([[44.258987,  7.559128],\n",
       "         [31.455484,  6.933227],\n",
       "         [22.842648, 31.3331  ]], dtype=float32),\n",
       "  'reward': 2.811652358459235,\n",
       "  'newState': (array([-52.90073395,  -6.6628952 ]), array([41,  4, 25])),\n",
       "  'info': {'type': array([41,  4, 25])}},\n",
       " {'iter': 2,\n",
       "  'episode': 6,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-52.90073395,  -6.6628952 ]), array([41,  4, 25])),\n",
       "  'action': array([[-2.7496154, -6.34421  ],\n",
       "         [-2.046698 , -2.226301 ],\n",
       "         [-1.1356249, -2.984333 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-46.96879578,   4.8919487 ]), array([19, 27, 28])),\n",
       "  'info': {'type': array([19, 27, 28])}},\n",
       " {'iter': 2,\n",
       "  'episode': 7,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[2.7149603 , 1.7584183 ],\n",
       "         [3.051142  , 0.02078687],\n",
       "         [0.5632341 , 4.3562326 ]], dtype=float32),\n",
       "  'reward': -1.783078236795588,\n",
       "  'newState': (array([93.67066383, 93.86456203]), array([ 8, 45, 12])),\n",
       "  'info': {'type': array([ 8, 45, 12])}},\n",
       " {'iter': 2,\n",
       "  'episode': 7,\n",
       "  'step': 1,\n",
       "  'oldState': (array([93.67066383, 93.86456203]), array([ 8, 45, 12])),\n",
       "  'action': array([[81.194084, 12.908467],\n",
       "         [91.692345, 61.667294],\n",
       "         [71.16102 , 87.68907 ]], dtype=float32),\n",
       "  'reward': 4.330295182083891,\n",
       "  'newState': (array([-150.376791  ,  -68.40026951]), array([46, 49, 11])),\n",
       "  'info': {'type': array([46, 49, 11])}},\n",
       " {'iter': 2,\n",
       "  'episode': 7,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-150.376791  ,  -68.40026951]), array([46, 49, 11])),\n",
       "  'action': array([[-58.840076, -14.497316],\n",
       "         [-39.525635,  -8.444205],\n",
       "         [-53.047867, -27.49626 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  1.03678322, -17.96248722]), array([ 8, 10, 23])),\n",
       "  'info': {'type': array([ 8, 10, 23])}},\n",
       " {'iter': 2,\n",
       "  'episode': 8,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.8912281 , 0.21137132],\n",
       "         [0.23648465, 0.8504822 ],\n",
       "         [0.5242434 , 0.9570279 ]], dtype=float32),\n",
       "  'reward': -0.11161238844409815,\n",
       "  'newState': (array([98.34804392, 97.98111868]), array([24, 25, 18])),\n",
       "  'info': {'type': array([24, 25, 18])}},\n",
       " {'iter': 2,\n",
       "  'episode': 8,\n",
       "  'step': 1,\n",
       "  'oldState': (array([98.34804392, 97.98111868]), array([24, 25, 18])),\n",
       "  'action': array([[57.377327, 68.24972 ],\n",
       "         [83.95544 , 73.016975],\n",
       "         [55.411423, 71.08833 ]], dtype=float32),\n",
       "  'reward': 4.351988164882455,\n",
       "  'newState': (array([ -98.39614248, -114.37390757]), array([18,  5, 47])),\n",
       "  'info': {'type': array([18,  5, 47])}},\n",
       " {'iter': 2,\n",
       "  'episode': 8,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -98.39614248, -114.37390757]), array([18,  5, 47])),\n",
       "  'action': array([[-45.14649 , -59.17141 ],\n",
       "         [-68.81591 , -34.24363 ],\n",
       "         [-21.322151, -70.67487 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([36.88840342, 49.71599722]), array([42, 46, 21])),\n",
       "  'info': {'type': array([42, 46, 21])}},\n",
       " {'iter': 2,\n",
       "  'episode': 9,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[16.865091, 44.588512],\n",
       "         [14.153776,  0.702878],\n",
       "         [ 7.47273 , 12.68545 ]], dtype=float32),\n",
       "  'reward': 0.9982165520251186,\n",
       "  'newState': (array([61.50840378, 42.02316284]), array([ 9, 42, 13])),\n",
       "  'info': {'type': array([ 9, 42, 13])}},\n",
       " {'iter': 2,\n",
       "  'episode': 9,\n",
       "  'step': 1,\n",
       "  'oldState': (array([61.50840378, 42.02316284]), array([ 9, 42, 13])),\n",
       "  'action': array([[19.768787, 28.539389],\n",
       "         [17.32851 , 46.828133],\n",
       "         [23.366297, 53.76739 ]], dtype=float32),\n",
       "  'reward': 3.826582726109274,\n",
       "  'newState': (array([  1.04481125, -87.11175537]), array([18, 23, 45])),\n",
       "  'info': {'type': array([18, 23, 45])}},\n",
       " {'iter': 2,\n",
       "  'episode': 9,\n",
       "  'step': 2,\n",
       "  'oldState': (array([  1.04481125, -87.11175537]), array([18, 23, 45])),\n",
       "  'action': array([[0.63489914, 0.9779958 ],\n",
       "         [0.5549972 , 0.8825003 ],\n",
       "         [0.76643264, 0.6986037 ]], dtype=float32),\n",
       "  'reward': 0.07130797573798184,\n",
       "  'newState': (array([ -0.91151774, -89.67085505]), array([31, 33, 14])),\n",
       "  'info': {'type': array([31, 33, 14])}},\n",
       " {'iter': 2,\n",
       "  'episode': 10,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.88766307, -0.782446  ],\n",
       "         [-0.64492226, -0.7931777 ],\n",
       "         [-0.07106605, -0.6297073 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([101.6036514 , 102.20533109]), array([47, 40, 49])),\n",
       "  'info': {'type': array([47, 40, 49])}},\n",
       " {'iter': 2,\n",
       "  'episode': 10,\n",
       "  'step': 1,\n",
       "  'oldState': (array([101.6036514 , 102.20533109]), array([47, 40, 49])),\n",
       "  'action': array([[74.428314, 97.06527 ],\n",
       "         [78.56405 , 52.86611 ],\n",
       "         [96.59521 , 68.65886 ]], dtype=float32),\n",
       "  'reward': 4.496614218555441,\n",
       "  'newState': (array([-147.98393404, -116.38490939]), array([ 8,  1, 22])),\n",
       "  'info': {'type': array([ 8,  1, 22])}},\n",
       " {'iter': 2,\n",
       "  'episode': 10,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-147.98393404, -116.38490939]), array([ 8,  1, 22])),\n",
       "  'action': array([[-62.777843, -13.636032],\n",
       "         [ -7.916467, -87.59479 ],\n",
       "         [-73.04823 , -56.98685 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-4.24138033, 41.83275723]), array([ 2, 22,  1])),\n",
       "  'info': {'type': array([ 2, 22,  1])}},\n",
       " {'iter': 2,\n",
       "  'episode': 11,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[17.78251  , 33.757294 ],\n",
       "         [ 1.3512001, 18.005354 ],\n",
       "         [32.13958  , 27.90004  ]], dtype=float32),\n",
       "  'reward': 2.9587181411514605,\n",
       "  'newState': (array([48.72670746, 20.33731079]), array([ 8,  7, 48])),\n",
       "  'info': {'type': array([ 8,  7, 48])}},\n",
       " {'iter': 2,\n",
       "  'episode': 11,\n",
       "  'step': 1,\n",
       "  'oldState': (array([48.72670746, 20.33731079]), array([ 8,  7, 48])),\n",
       "  'action': array([[45.53132 , 41.03518 ],\n",
       "         [30.424475, 22.168562],\n",
       "         [39.88926 , 18.269323]], dtype=float32),\n",
       "  'reward': 3.924924692762734,\n",
       "  'newState': (array([-67.11834717, -61.13575745]), array([23, 13, 48])),\n",
       "  'info': {'type': array([23, 13, 48])}},\n",
       " {'iter': 2,\n",
       "  'episode': 11,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-67.11834717, -61.13575745]), array([23, 13, 48])),\n",
       "  'action': array([[-57.613087, -51.514343],\n",
       "         [-59.58838 , -43.12893 ],\n",
       "         [-40.766834, -28.62213 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([90.84994507, 62.1296463 ]), array([ 0, 42, 39])),\n",
       "  'info': {'type': array([ 0, 42, 39])}},\n",
       " {'iter': 2,\n",
       "  'episode': 12,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[21.289017  , 15.572741  ],\n",
       "         [ 2.9287024 ,  0.38283956],\n",
       "         [ 7.0418563 ,  9.541404  ]], dtype=float32),\n",
       "  'reward': 0.7192894234704725,\n",
       "  'newState': (array([68.7404232 , 74.50301743]), array([ 3, 43, 43])),\n",
       "  'info': {'type': array([ 3, 43, 43])}},\n",
       " {'iter': 2,\n",
       "  'episode': 12,\n",
       "  'step': 1,\n",
       "  'oldState': (array([68.7404232 , 74.50301743]), array([ 3, 43, 43])),\n",
       "  'action': array([[ 5.812127, 45.244156],\n",
       "         [64.39704 , 14.607743],\n",
       "         [29.176908, 22.097935]], dtype=float32),\n",
       "  'reward': 3.2571480407647018,\n",
       "  'newState': (array([-30.64565468,  -7.44681168]), array([10, 34, 33])),\n",
       "  'info': {'type': array([10, 34, 33])}},\n",
       " {'iter': 2,\n",
       "  'episode': 12,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-30.64565468,  -7.44681168]), array([10, 34, 33])),\n",
       "  'action': array([[-7.259713 , -6.7451463],\n",
       "         [-0.6080775, -3.7917273],\n",
       "         [-2.9741974, -2.9271824]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-19.80366707,   6.01724434]), array([11,  2, 10])),\n",
       "  'info': {'type': array([11,  2, 10])}},\n",
       " {'iter': 2,\n",
       "  'episode': 13,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.0925956, 3.7272112],\n",
       "         [1.2137403, 2.2749448],\n",
       "         [3.0973785, 1.3864561]], dtype=float32),\n",
       "  'reward': 0.5977464392188455,\n",
       "  'newState': (array([94.59628582, 92.61138773]), array([27,  5, 26])),\n",
       "  'info': {'type': array([27,  5, 26])}},\n",
       " {'iter': 2,\n",
       "  'episode': 13,\n",
       "  'step': 1,\n",
       "  'oldState': (array([94.59628582, 92.61138773]), array([27,  5, 26])),\n",
       "  'action': array([[29.198175, 24.628145],\n",
       "         [10.520012, 86.06129 ],\n",
       "         [79.60472 , 80.43784 ]], dtype=float32),\n",
       "  'reward': 4.229958644674718,\n",
       "  'newState': (array([-24.72662067, -98.51588583]), array([ 3, 31, 11])),\n",
       "  'info': {'type': array([ 3, 31, 11])}},\n",
       " {'iter': 2,\n",
       "  'episode': 13,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-24.72662067, -98.51588583]), array([ 3, 31, 11])),\n",
       "  'action': array([[ -6.739927 ,  -8.883043 ],\n",
       "         [-13.628246 ,  -5.3871417],\n",
       "         [ -0.5987369, -20.894629 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ -3.75970936, -63.35107183]), array([ 3,  1, 13])),\n",
       "  'info': {'type': array([ 3,  1, 13])}},\n",
       " {'iter': 2,\n",
       "  'episode': 14,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.1583686 , -0.01436498],\n",
       "         [-1.6009564 , -2.485678  ],\n",
       "         [-3.3362808 , -1.9807085 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([107.09560585, 104.48075151]), array([17,  8, 38])),\n",
       "  'info': {'type': array([17,  8, 38])}},\n",
       " {'iter': 2,\n",
       "  'episode': 14,\n",
       "  'step': 1,\n",
       "  'oldState': (array([107.09560585, 104.48075151]), array([17,  8, 38])),\n",
       "  'action': array([[ 14.903125,  30.331312],\n",
       "         [ 15.928077, 102.20784 ],\n",
       "         [ 25.054409,  39.45752 ]], dtype=float32),\n",
       "  'reward': 3.829890128445488,\n",
       "  'newState': (array([ 51.20999336, -67.51592207]), array([ 4,  6, 12])),\n",
       "  'info': {'type': array([ 4,  6, 12])}},\n",
       " {'iter': 2,\n",
       "  'episode': 14,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 51.20999336, -67.51592207]), array([ 4,  6, 12])),\n",
       "  'action': array([[43.735325, 11.585212],\n",
       "         [22.182093, 36.473846],\n",
       "         [35.89834 , 17.59717 ]], dtype=float32),\n",
       "  'reward': 3.838516800095226,\n",
       "  'newState': (array([ -50.60576439, -133.17214918]), array([ 9,  5, 15])),\n",
       "  'info': {'type': array([ 9,  5, 15])}},\n",
       " {'iter': 2,\n",
       "  'episode': 15,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-30.213558, -21.447813],\n",
       "         [-43.889732, -16.421707],\n",
       "         [-32.704296,  -1.716438]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([206.80758667, 139.58596039]), array([20, 31, 26])),\n",
       "  'info': {'type': array([20, 31, 26])}},\n",
       " {'iter': 2,\n",
       "  'episode': 15,\n",
       "  'step': 1,\n",
       "  'oldState': (array([206.80758667, 139.58596039]), array([20, 31, 26])),\n",
       "  'action': array([[115.948944,  93.44715 ],\n",
       "         [ 38.371254, 113.27244 ],\n",
       "         [166.4819  ,  55.726097]], dtype=float32),\n",
       "  'reward': 4.963384832682679,\n",
       "  'newState': (array([-113.99450684, -122.85971832]), array([ 7, 43,  2])),\n",
       "  'info': {'type': array([ 7, 43,  2])}},\n",
       " {'iter': 2,\n",
       "  'episode': 15,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-113.99450684, -122.85971832]), array([ 7, 43,  2])),\n",
       "  'action': array([[-34.477863, -66.566025],\n",
       "         [-90.66044 , -83.43356 ],\n",
       "         [ -4.660269, -26.83477 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([15.80406189, 53.97463226]), array([32, 46, 11])),\n",
       "  'info': {'type': array([32, 46, 11])}},\n",
       " {'iter': 2,\n",
       "  'episode': 16,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[40.26505  ,  3.0418746],\n",
       "         [ 3.1743922, 38.407284 ],\n",
       "         [41.05248  , 50.658245 ]], dtype=float32),\n",
       "  'reward': 3.717753893556744,\n",
       "  'newState': (array([15.50807953,  7.89259338]), array([18, 44,  0])),\n",
       "  'info': {'type': array([18, 44,  0])}},\n",
       " {'iter': 2,\n",
       "  'episode': 16,\n",
       "  'step': 1,\n",
       "  'oldState': (array([15.50807953,  7.89259338]), array([18, 44,  0])),\n",
       "  'action': array([[10.582263  , 11.962293  ],\n",
       "         [ 5.59249   , 14.330443  ],\n",
       "         [ 6.7526503 ,  0.14392725]], dtype=float32),\n",
       "  'reward': 2.574358376828367,\n",
       "  'newState': (array([ -7.41932297, -18.54406929]), array([37, 47,  9])),\n",
       "  'info': {'type': array([37, 47,  9])}},\n",
       " {'iter': 2,\n",
       "  'episode': 16,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -7.41932297, -18.54406929]), array([37, 47,  9])),\n",
       "  'action': array([[-5.5487237 , -6.722395  ],\n",
       "         [-0.77477854, -1.8770227 ],\n",
       "         [-6.4587016 , -5.427512  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 5.36288071, -4.51713943]), array([26, 20, 15])),\n",
       "  'info': {'type': array([26, 20, 15])}},\n",
       " {'iter': 2,\n",
       "  'episode': 17,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[2.1438787, 3.1325812],\n",
       "         [3.048053 , 1.8753287],\n",
       "         [3.5862613, 1.1484193]], dtype=float32),\n",
       "  'reward': 0.7329481905722552,\n",
       "  'newState': (array([91.22180748, 93.84367085]), array([1, 5, 2])),\n",
       "  'info': {'type': array([1, 5, 2])}},\n",
       " {'iter': 2,\n",
       "  'episode': 17,\n",
       "  'step': 1,\n",
       "  'oldState': (array([91.22180748, 93.84367085]), array([1, 5, 2])),\n",
       "  'action': array([[23.250708, 51.007877],\n",
       "         [32.52145 , 25.088821],\n",
       "         [11.41998 , 53.33342 ]], dtype=float32),\n",
       "  'reward': 3.4499524880368506,\n",
       "  'newState': (array([ 24.02966881, -35.5864439 ]), array([25, 28, 19])),\n",
       "  'info': {'type': array([25, 28, 19])}},\n",
       " {'iter': 2,\n",
       "  'episode': 17,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 24.02966881, -35.5864439 ]), array([25, 28, 19])),\n",
       "  'action': array([[18.019533 , 13.314363 ],\n",
       "         [21.638325 ,  9.692833 ],\n",
       "         [12.966995 ,  4.2727265]], dtype=float32),\n",
       "  'reward': 2.638643663585646,\n",
       "  'newState': (array([-28.59518623, -62.86636448]), array([43, 17,  5])),\n",
       "  'info': {'type': array([43, 17,  5])}},\n",
       " {'iter': 2,\n",
       "  'episode': 18,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-19.361645 ,  -9.819774 ],\n",
       "         [-28.212666 ,  -1.3460993],\n",
       "         [-16.191645 , -12.582945 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([163.76595306, 123.74881744]), array([45, 15, 10])),\n",
       "  'info': {'type': array([45, 15, 10])}},\n",
       " {'iter': 2,\n",
       "  'episode': 18,\n",
       "  'step': 1,\n",
       "  'oldState': (array([163.76595306, 123.74881744]), array([45, 15, 10])),\n",
       "  'action': array([[140.56915 ,  66.48445 ],\n",
       "         [118.739525,  97.73486 ],\n",
       "         [126.374664, 105.747795]], dtype=float32),\n",
       "  'reward': 4.939471513139858,\n",
       "  'newState': (array([-221.91739655, -146.21828461]), array([29, 17, 17])),\n",
       "  'info': {'type': array([29, 17, 17])}},\n",
       " {'iter': 2,\n",
       "  'episode': 18,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-221.91739655, -146.21828461]), array([29, 17, 17])),\n",
       "  'action': array([[ -38.9899  ,  -99.49367 ],\n",
       "         [ -22.712051, -129.52582 ],\n",
       "         [  -8.516208,  -79.02683 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-151.69924164,  161.82804108]), array([46,  7, 17])),\n",
       "  'info': {'type': array([46,  7, 17])}},\n",
       " {'iter': 2,\n",
       "  'episode': 19,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 24.049517, 103.29505 ],\n",
       "         [ 91.77699 ,  46.543896],\n",
       "         [140.04677 ,  82.215004]], dtype=float32),\n",
       "  'reward': 3.695924428223999,\n",
       "  'newState': (array([-155.87327576, -132.05395508]), array([22,  0,  7])),\n",
       "  'info': {'type': array([22,  0,  7])}},\n",
       " {'iter': 2,\n",
       "  'episode': 19,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-155.87327576, -132.05395508]), array([22,  0,  7])),\n",
       "  'action': array([[-106.783516 ,  -16.735744 ],\n",
       "         [ -72.044914 ,  -57.380882 ],\n",
       "         [  -6.3194766,  -92.27184  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([29.27462769, 34.33450317]), array([29, 28, 35])),\n",
       "  'info': {'type': array([29, 28, 35])}},\n",
       " {'iter': 2,\n",
       "  'episode': 19,\n",
       "  'step': 2,\n",
       "  'oldState': (array([29.27462769, 34.33450317]), array([29, 28, 35])),\n",
       "  'action': array([[15.864696, 14.514617],\n",
       "         [14.194955, 26.958647],\n",
       "         [23.900719, 25.756826]], dtype=float32),\n",
       "  'reward': 3.3595605153458066,\n",
       "  'newState': (array([-24.68574142, -32.89558411]), array([43, 34, 40])),\n",
       "  'info': {'type': array([43, 34, 40])}},\n",
       " {'iter': 2,\n",
       "  'episode': 20,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-23.487623 , -12.897725 ],\n",
       "         [-19.29283  ,  -1.4500211],\n",
       "         [-14.138228 ,  -6.6206317]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([156.9186821 , 120.96837807]), array([ 5, 28, 41])),\n",
       "  'info': {'type': array([ 5, 28, 41])}},\n",
       " {'iter': 2,\n",
       "  'episode': 20,\n",
       "  'step': 1,\n",
       "  'oldState': (array([156.9186821 , 120.96837807]), array([ 5, 28, 41])),\n",
       "  'action': array([[ 44.097458, 105.456314],\n",
       "         [ 10.257613, 145.05424 ],\n",
       "         [ 27.704649, 125.09202 ]], dtype=float32),\n",
       "  'reward': 4.925465662754529,\n",
       "  'newState': (array([  74.8589592 , -254.63419151]), array([34, 34, 19])),\n",
       "  'info': {'type': array([34, 34, 19])}},\n",
       " {'iter': 2,\n",
       "  'episode': 20,\n",
       "  'step': 2,\n",
       "  'oldState': (array([  74.8589592 , -254.63419151]), array([34, 34, 19])),\n",
       "  'action': array([[62.94652  , 74.8062   ],\n",
       "         [16.55697  , 38.005013 ],\n",
       "         [ 6.7684298, 10.752541 ]], dtype=float32),\n",
       "  'reward': 3.6658010585280847,\n",
       "  'newState': (array([ -11.41296768, -378.19794273]), array([13, 37, 25])),\n",
       "  'info': {'type': array([13, 37, 25])}},\n",
       " {'iter': 2,\n",
       "  'episode': 21,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -5.5549693,  -5.7949963],\n",
       "         [ -6.1629443, -11.001626 ],\n",
       "         [-11.008052 ,  -9.360798 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([122.7259655 , 126.15742111]), array([ 4, 43, 11])),\n",
       "  'info': {'type': array([ 4, 43, 11])}},\n",
       " {'iter': 2,\n",
       "  'episode': 21,\n",
       "  'step': 1,\n",
       "  'oldState': (array([122.7259655 , 126.15742111]), array([ 4, 43, 11])),\n",
       "  'action': array([[31.500732, 85.13424 ],\n",
       "         [87.08304 , 86.29868 ],\n",
       "         [78.750114, 56.418354]], dtype=float32),\n",
       "  'reward': 4.473410359291392,\n",
       "  'newState': (array([ -74.60792732, -101.69385147]), array([29, 12, 25])),\n",
       "  'info': {'type': array([29, 12, 25])}},\n",
       " {'iter': 2,\n",
       "  'episode': 21,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -74.60792732, -101.69385147]), array([29, 12, 25])),\n",
       "  'action': array([[ -9.453826, -20.37918 ],\n",
       "         [-20.88041 , -29.055807],\n",
       "         [-12.205924,  -9.455536]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-32.06776619, -42.80332565]), array([32, 40, 42])),\n",
       "  'info': {'type': array([32, 40, 42])}},\n",
       " {'iter': 2,\n",
       "  'episode': 22,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-29.977169, -10.8387  ],\n",
       "         [-25.971312, -12.889293],\n",
       "         [ -9.568516,  -8.420638]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([165.51699829, 132.14863205]), array([23, 25, 43])),\n",
       "  'info': {'type': array([23, 25, 43])}},\n",
       " {'iter': 2,\n",
       "  'episode': 22,\n",
       "  'step': 1,\n",
       "  'oldState': (array([165.51699829, 132.14863205]), array([23, 25, 43])),\n",
       "  'action': array([[130.72925 ,  54.798084],\n",
       "         [ 17.040285, 125.030785],\n",
       "         [ 96.22493 ,  44.62562 ]], dtype=float32),\n",
       "  'reward': 4.896121174609578,\n",
       "  'newState': (array([-78.47746277, -92.30586624]), array([40, 24, 31])),\n",
       "  'info': {'type': array([40, 24, 31])}},\n",
       " {'iter': 2,\n",
       "  'episode': 22,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-78.47746277, -92.30586624]), array([40, 24, 31])),\n",
       "  'action': array([[-55.539444, -42.60105 ],\n",
       "         [-16.48841 , -52.578392],\n",
       "         [-76.4578  , -58.412395]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([70.00819397, 61.28597641]), array([28,  0, 22])),\n",
       "  'info': {'type': array([28,  0, 22])}},\n",
       " {'iter': 2,\n",
       "  'episode': 23,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[52.93646  , 40.29045  ],\n",
       "         [64.305534 ,  4.7716074],\n",
       "         [25.813637 , 41.71934  ]], dtype=float32),\n",
       "  'reward': 2.5921041469696813,\n",
       "  'newState': (array([-43.05563354,  13.21859741]), array([24, 22, 10])),\n",
       "  'info': {'type': array([24, 22, 10])}},\n",
       " {'iter': 2,\n",
       "  'episode': 23,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-43.05563354,  13.21859741]), array([24, 22, 10])),\n",
       "  'action': array([[ 5.7667546,  8.106126 ],\n",
       "         [12.599163 , 11.087921 ],\n",
       "         [ 1.2424897,  7.154966 ]], dtype=float32),\n",
       "  'reward': 2.0760491781074895,\n",
       "  'newState': (array([-62.66403961, -13.13041496]), array([43, 31,  9])),\n",
       "  'info': {'type': array([43, 31,  9])}},\n",
       " {'iter': 2,\n",
       "  'episode': 23,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-62.66403961, -13.13041496]), array([43, 31,  9])),\n",
       "  'action': array([[ -0.8531833 ,  -0.20398383],\n",
       "         [ -2.8644392 , -10.963287  ],\n",
       "         [ -2.1720662 ,  -8.06769   ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-56.77435112,   6.1045475 ]), array([39,  6, 30])),\n",
       "  'info': {'type': array([39,  6, 30])}},\n",
       " {'iter': 2,\n",
       "  'episode': 24,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.5460336 , 5.5342827 ],\n",
       "         [2.8867624 , 1.4712044 ],\n",
       "         [5.5293074 , 0.91422397]], dtype=float32),\n",
       "  'reward': 0.7930383231534116,\n",
       "  'newState': (array([88.03789711, 92.08028889]), array([ 3, 18, 12])),\n",
       "  'info': {'type': array([ 3, 18, 12])}},\n",
       " {'iter': 2,\n",
       "  'episode': 24,\n",
       "  'step': 1,\n",
       "  'oldState': (array([88.03789711, 92.08028889]), array([ 3, 18, 12])),\n",
       "  'action': array([[46.893726, 51.731323],\n",
       "         [60.510723, 40.217693],\n",
       "         [60.98491 , 77.267296]], dtype=float32),\n",
       "  'reward': 4.157276767600946,\n",
       "  'newState': (array([-80.35146141, -77.13601971]), array([ 9, 10, 27])),\n",
       "  'info': {'type': array([ 9, 10, 27])}},\n",
       " {'iter': 2,\n",
       "  'episode': 24,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-80.35146141, -77.13601971]), array([ 9, 10, 27])),\n",
       "  'action': array([[-55.742264 , -55.897026 ],\n",
       "         [-63.634743 , -55.62958  ],\n",
       "         [-10.5543785, -48.170696 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([49.57991982, 82.56129169]), array([ 1, 21, 42])),\n",
       "  'info': {'type': array([ 1, 21, 42])}},\n",
       " {'iter': 2,\n",
       "  'episode': 25,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[26.422594, 46.4817  ],\n",
       "         [16.92958 , 76.47639 ],\n",
       "         [44.60611 , 30.159925]], dtype=float32),\n",
       "  'reward': 3.951488436371961,\n",
       "  'newState': (array([ 12.04171753, -53.11801147]), array([ 6,  9, 36])),\n",
       "  'info': {'type': array([ 6,  9, 36])}},\n",
       " {'iter': 2,\n",
       "  'episode': 25,\n",
       "  'step': 1,\n",
       "  'oldState': (array([ 12.04171753, -53.11801147]), array([ 6,  9, 36])),\n",
       "  'action': array([[ 0.3973202,  4.2614827],\n",
       "         [11.441836 ,  6.217607 ],\n",
       "         [ 4.4625096,  3.4537587]], dtype=float32),\n",
       "  'reward': 1.6743040561932634,\n",
       "  'newState': (array([ -4.25994873, -67.05085945]), array([23,  8, 23])),\n",
       "  'info': {'type': array([23,  8, 23])}},\n",
       " {'iter': 2,\n",
       "  'episode': 25,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -4.25994873, -67.05085945]), array([23,  8, 23])),\n",
       "  'action': array([[-0.36988226, -2.661907  ],\n",
       "         [-0.5217964 , -0.53841496],\n",
       "         [-1.2956206 , -3.0710025 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ -2.07264948, -60.77953529]), array([18, 42, 21])),\n",
       "  'info': {'type': array([18, 42, 21])}},\n",
       " {'iter': 2,\n",
       "  'episode': 26,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.8700157, -1.9772582],\n",
       "         [-2.060723 , -1.7182024],\n",
       "         [-1.5439409, -2.0349376]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([105.47467995, 105.73039818]), array([ 3, 14, 20])),\n",
       "  'info': {'type': array([ 3, 14, 20])}},\n",
       " {'iter': 2,\n",
       "  'episode': 26,\n",
       "  'step': 1,\n",
       "  'oldState': (array([105.47467995, 105.73039818]), array([ 3, 14, 20])),\n",
       "  'action': array([[71.58741 , 51.08821 ],\n",
       "         [ 9.948888, 92.61926 ],\n",
       "         [30.825989, 35.654167]], dtype=float32),\n",
       "  'reward': 4.3283726365657875,\n",
       "  'newState': (array([ -6.88760948, -73.63123512]), array([43, 21,  9])),\n",
       "  'info': {'type': array([43, 21,  9])}},\n",
       " {'iter': 2,\n",
       "  'episode': 26,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -6.88760948, -73.63123512]), array([43, 21,  9])),\n",
       "  'action': array([[-4.903674 , -1.6384062],\n",
       "         [-4.4280057, -6.6572266],\n",
       "         [-1.9805102, -6.0301332]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  4.42458153, -59.30546951]), array([42,  2, 20])),\n",
       "  'info': {'type': array([42,  2, 20])}},\n",
       " {'iter': 2,\n",
       "  'episode': 27,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[2.9310806 , 0.10646655],\n",
       "         [2.108922  , 0.92035764],\n",
       "         [2.2132607 , 3.380104  ]], dtype=float32),\n",
       "  'reward': 0.44440215161188246,\n",
       "  'newState': (array([92.74673653, 95.59307194]), array([43, 16, 13])),\n",
       "  'info': {'type': array([43, 16, 13])}},\n",
       " {'iter': 2,\n",
       "  'episode': 27,\n",
       "  'step': 1,\n",
       "  'oldState': (array([92.74673653, 95.59307194]), array([43, 16, 13])),\n",
       "  'action': array([[47.351925  ,  0.10048199],\n",
       "         [22.555151  , 46.592094  ],\n",
       "         [79.59699   , 52.805946  ]], dtype=float32),\n",
       "  'reward': 4.039667545166217,\n",
       "  'newState': (array([-56.75732231,  -3.90544796]), array([42, 35, 11])),\n",
       "  'info': {'type': array([42, 35, 11])}},\n",
       " {'iter': 2,\n",
       "  'episode': 27,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-56.75732231,  -3.90544796]), array([42, 35, 11])),\n",
       "  'action': array([[-2.0129888 , -1.560363  ],\n",
       "         [-0.9381932 , -3.3023455 ],\n",
       "         [-0.44008937, -1.2834448 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-53.36605096,   2.24070549]), array([28, 42, 21])),\n",
       "  'info': {'type': array([28, 42, 21])}},\n",
       " {'iter': 2,\n",
       "  'episode': 28,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.7208136, 1.4539512],\n",
       "         [1.9196507, 1.0022296],\n",
       "         [1.499509 , 1.7168515]], dtype=float32),\n",
       "  'reward': -0.04666373340887746,\n",
       "  'newState': (array([95.86002684, 95.82696772]), array([34, 44, 42])),\n",
       "  'info': {'type': array([34, 44, 42])}},\n",
       " {'iter': 2,\n",
       "  'episode': 28,\n",
       "  'step': 1,\n",
       "  'oldState': (array([95.86002684, 95.82696772]), array([34, 44, 42])),\n",
       "  'action': array([[78.7029  , 63.09643 ],\n",
       "         [42.10542 , 28.275793],\n",
       "         [69.108864, 91.84644 ]], dtype=float32),\n",
       "  'reward': 4.240739262497441,\n",
       "  'newState': (array([-94.05714846, -87.39169073]), array([28, 18,  8])),\n",
       "  'info': {'type': array([28, 18,  8])}},\n",
       " {'iter': 2,\n",
       "  'episode': 28,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-94.05714846, -87.39169073]), array([28, 18,  8])),\n",
       "  'action': array([[-18.26403 , -43.737392],\n",
       "         [-52.238304, -58.593063],\n",
       "         [-72.511795, -76.14366 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([48.95698118, 91.08243036]), array([30,  0, 13])),\n",
       "  'info': {'type': array([30,  0, 13])}},\n",
       " {'iter': 2,\n",
       "  'episode': 29,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[34.458492, 75.105225],\n",
       "         [46.73903 , 38.744278],\n",
       "         [90.11086 , 62.474052]], dtype=float32),\n",
       "  'reward': 3.6971862461585405,\n",
       "  'newState': (array([-71.30838013, -76.32354736]), array([18, 38, 11])),\n",
       "  'info': {'type': array([18, 38, 11])}},\n",
       " {'iter': 2,\n",
       "  'episode': 29,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-71.30838013, -76.32354736]), array([18, 38, 11])),\n",
       "  'action': array([[-50.70277 , -46.774746],\n",
       "         [-42.46127 , -20.533426],\n",
       "         [-39.78894 , -56.726254]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([61.64459229, 47.71087646]), array([19, 12,  4])),\n",
       "  'info': {'type': array([19, 12,  4])}},\n",
       " {'iter': 2,\n",
       "  'episode': 29,\n",
       "  'step': 2,\n",
       "  'oldState': (array([61.64459229, 47.71087646]), array([19, 12,  4])),\n",
       "  'action': array([[11.464395, 30.678791],\n",
       "         [31.584549, 33.872738],\n",
       "         [38.996788, 22.69783 ]], dtype=float32),\n",
       "  'reward': 3.0030225384541196,\n",
       "  'newState': (array([-20.40113831, -39.53848267]), array([45, 25, 40])),\n",
       "  'info': {'type': array([45, 25, 40])}},\n",
       " {'iter': 2,\n",
       "  'episode': 30,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -7.857572 , -18.810009 ],\n",
       "         [ -7.874741 , -13.645807 ],\n",
       "         [ -1.9575155,  -1.1459935]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([117.68982887, 133.60181046]), array([35,  5, 31])),\n",
       "  'info': {'type': array([35,  5, 31])}},\n",
       " {'iter': 2,\n",
       "  'episode': 30,\n",
       "  'step': 1,\n",
       "  'oldState': (array([117.68982887, 133.60181046]), array([35,  5, 31])),\n",
       "  'action': array([[ 11.053012,  42.464127],\n",
       "         [ 64.91337 ,  54.62289 ],\n",
       "         [128.99881 , 127.69395 ]], dtype=float32),\n",
       "  'reward': 3.888466827696981,\n",
       "  'newState': (array([-87.27535057, -91.17916489]), array([29,  2, 32])),\n",
       "  'info': {'type': array([29,  2, 32])}},\n",
       " {'iter': 2,\n",
       "  'episode': 30,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-87.27535057, -91.17916489]), array([29,  2, 32])),\n",
       "  'action': array([[-36.19743  , -47.541004 ],\n",
       "         [-36.92153  ,  -1.5698401],\n",
       "         [-12.435953 , -54.746624 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-1.72044182, 12.67830276]), array([ 7, 29,  8])),\n",
       "  'info': {'type': array([ 7, 29,  8])}},\n",
       " {'iter': 2,\n",
       "  'episode': 31,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 6.5595036,  7.976024 ],\n",
       "         [12.167426 ,  7.986777 ],\n",
       "         [ 5.771468 , 10.814882 ]], dtype=float32),\n",
       "  'reward': 2.0506522587989537,\n",
       "  'newState': (array([75.50160217, 73.22231674]), array([27, 33, 29])),\n",
       "  'info': {'type': array([27, 33, 29])}},\n",
       " {'iter': 2,\n",
       "  'episode': 31,\n",
       "  'step': 1,\n",
       "  'oldState': (array([75.50160217, 73.22231674]), array([27, 33, 29])),\n",
       "  'action': array([[39.224182 ,  3.0633023],\n",
       "         [48.822445 , 51.110275 ],\n",
       "         [40.586647 ,  9.301182 ]], dtype=float32),\n",
       "  'reward': 3.8457975427989655,\n",
       "  'newState': (array([-53.13166809,   9.74755859]), array([ 4, 38, 33])),\n",
       "  'info': {'type': array([ 4, 38, 33])}},\n",
       " {'iter': 2,\n",
       "  'episode': 31,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-53.13166809,   9.74755859]), array([ 4, 38, 33])),\n",
       "  'action': array([[1.3582846, 4.186462 ],\n",
       "         [7.335497 , 8.661551 ],\n",
       "         [9.161531 , 1.5565504]], dtype=float32),\n",
       "  'reward': 2.1538215974186175,\n",
       "  'newState': (array([-70.98698044,  -4.65700436]), array([ 9,  3, 14])),\n",
       "  'info': {'type': array([ 9,  3, 14])}},\n",
       " {'iter': 2,\n",
       "  'episode': 32,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.4851292 , -1.9364729 ],\n",
       "         [-1.1780136 , -2.315167  ],\n",
       "         [-2.2060297 , -0.46939346]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([104.8691721, 104.7210331]), array([20, 35, 28])),\n",
       "  'info': {'type': array([20, 35, 28])}},\n",
       " {'iter': 2,\n",
       "  'episode': 32,\n",
       "  'step': 1,\n",
       "  'oldState': (array([104.8691721, 104.7210331]), array([20, 35, 28])),\n",
       "  'action': array([[76.71288 , 92.29214 ],\n",
       "         [72.95225 , 54.694363],\n",
       "         [82.8071  , 34.493668]], dtype=float32),\n",
       "  'reward': 4.340671949010118,\n",
       "  'newState': (array([-127.60305691,  -76.75913048]), array([45, 28,  4])),\n",
       "  'info': {'type': array([45, 28,  4])}},\n",
       " {'iter': 2,\n",
       "  'episode': 32,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-127.60305691,  -76.75913048]), array([45, 28,  4])),\n",
       "  'action': array([[-71.43711  , -40.090054 ],\n",
       "         [-49.52401  ,  -9.8517885],\n",
       "         [-75.610146 ,  -6.1401005]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 68.96820164, -20.67719078]), array([15, 11, 31])),\n",
       "  'info': {'type': array([15, 11, 31])}},\n",
       " {'iter': 2,\n",
       "  'episode': 33,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[15.936697 , 30.490873 ],\n",
       "         [21.12471  , 55.777565 ],\n",
       "         [ 0.9999692, 14.120081 ]], dtype=float32),\n",
       "  'reward': 3.4899359577216393,\n",
       "  'newState': (array([61.93862152, -0.38851929]), array([36, 12, 38])),\n",
       "  'info': {'type': array([36, 12, 38])}},\n",
       " {'iter': 2,\n",
       "  'episode': 33,\n",
       "  'step': 1,\n",
       "  'oldState': (array([61.93862152, -0.38851929]), array([36, 12, 38])),\n",
       "  'action': array([[ 5.471031  , 49.34354   ],\n",
       "         [51.541706  , 54.334248  ],\n",
       "         [ 0.12384556, 61.69156   ]], dtype=float32),\n",
       "  'reward': 3.0911682751921603,\n",
       "  'newState': (array([   4.8020401 , -165.75787354]), array([19, 16, 47])),\n",
       "  'info': {'type': array([19, 16, 47])}},\n",
       " {'iter': 2,\n",
       "  'episode': 33,\n",
       "  'step': 2,\n",
       "  'oldState': (array([   4.8020401 , -165.75787354]), array([19, 16, 47])),\n",
       "  'action': array([[4.3993983 , 4.5248537 ],\n",
       "         [4.009233  , 0.66098434],\n",
       "         [0.14759877, 2.3426032 ]], dtype=float32),\n",
       "  'reward': 0.7854217746102498,\n",
       "  'newState': (array([  -3.75419044, -173.28631496]), array([36, 10,  6])),\n",
       "  'info': {'type': array([36, 10,  6])}},\n",
       " {'iter': 2,\n",
       "  'episode': 34,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.3340585, -1.6669117],\n",
       "         [-3.2070084, -2.0481386],\n",
       "         [-0.6949754, -2.7745054]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([106.2360425 , 106.48955536]), array([26, 36, 30])),\n",
       "  'info': {'type': array([26, 36, 30])}},\n",
       " {'iter': 2,\n",
       "  'episode': 34,\n",
       "  'step': 1,\n",
       "  'oldState': (array([106.2360425 , 106.48955536]), array([26, 36, 30])),\n",
       "  'action': array([[39.83277 , 76.427956],\n",
       "         [27.055296, 99.98379 ],\n",
       "         [97.99156 , 85.69737 ]], dtype=float32),\n",
       "  'reward': 4.543255887105929,\n",
       "  'newState': (array([ -58.64359617, -155.6195755 ]), array([35,  0, 38])),\n",
       "  'info': {'type': array([35,  0, 38])}},\n",
       " {'iter': 2,\n",
       "  'episode': 34,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -58.64359617, -155.6195755 ]), array([35,  0, 38])),\n",
       "  'action': array([[-23.888975, -51.513268],\n",
       "         [-16.041508,  -9.456627],\n",
       "         [-30.770222,  -4.811411]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 12.05710268, -89.83827209]), array([18, 31, 41])),\n",
       "  'info': {'type': array([18, 31, 41])}},\n",
       " {'iter': 2,\n",
       "  'episode': 35,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 9.7916355,  8.210727 ],\n",
       "         [11.088255 ,  8.821993 ],\n",
       "         [11.378208 ,  4.7844486]], dtype=float32),\n",
       "  'reward': 2.251412848158995,\n",
       "  'newState': (array([67.7419014 , 78.18283272]), array([31, 48, 42])),\n",
       "  'info': {'type': array([31, 48, 42])}},\n",
       " {'iter': 2,\n",
       "  'episode': 35,\n",
       "  'step': 1,\n",
       "  'oldState': (array([67.7419014 , 78.18283272]), array([31, 48, 42])),\n",
       "  'action': array([[39.116695 , 14.23965  ],\n",
       "         [44.691883 , 57.64055  ],\n",
       "         [62.34838  ,  4.6429086]], dtype=float32),\n",
       "  'reward': 4.007086956903011,\n",
       "  'newState': (array([-78.41505051,   1.65973091]), array([49, 22,  0])),\n",
       "  'info': {'type': array([49, 22,  0])}},\n",
       " {'iter': 2,\n",
       "  'episode': 35,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-78.41505051,   1.65973091]), array([49, 22,  0])),\n",
       "  'action': array([[0.9624804 , 0.26933315],\n",
       "         [1.0868452 , 0.27002367],\n",
       "         [1.2641659 , 1.4417382 ]], dtype=float32),\n",
       "  'reward': -0.4320738041043569,\n",
       "  'newState': (array([-81.72854185,  -0.32136416]), array([ 6, 45, 32])),\n",
       "  'info': {'type': array([ 6, 45, 32])}},\n",
       " {'iter': 2,\n",
       "  'episode': 36,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.27437085, -0.08669283],\n",
       "         [-0.22970997, -0.09795878],\n",
       "         [-0.07912143, -0.2545096 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([100.58320224, 100.43916121]), array([27,  0, 26])),\n",
       "  'info': {'type': array([27,  0, 26])}},\n",
       " {'iter': 2,\n",
       "  'episode': 36,\n",
       "  'step': 1,\n",
       "  'oldState': (array([100.58320224, 100.43916121]), array([27,  0, 26])),\n",
       "  'action': array([[55.118023, 77.12627 ],\n",
       "         [90.92213 , 35.22405 ],\n",
       "         [34.141518, 45.259186]], dtype=float32),\n",
       "  'reward': 4.188548308781504,\n",
       "  'newState': (array([-79.5984689 , -57.17033586]), array([20, 26,  1])),\n",
       "  'info': {'type': array([20, 26,  1])}},\n",
       " {'iter': 2,\n",
       "  'episode': 36,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-79.5984689 , -57.17033586]), array([20, 26,  1])),\n",
       "  'action': array([[-24.04544  , -14.392119 ],\n",
       "         [ -2.5434065, -16.867664 ],\n",
       "         [-21.704529 , -21.108433 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-31.30509198,  -4.80211839]), array([37, 13, 40])),\n",
       "  'info': {'type': array([37, 13, 40])}},\n",
       " {'iter': 2,\n",
       "  'episode': 37,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-3.3798752 , -0.24611607],\n",
       "         [-1.4886768 , -4.4536767 ],\n",
       "         [-2.9578345 , -4.6449265 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([107.82638645, 109.34471893]), array([18, 18, 38])),\n",
       "  'info': {'type': array([18, 18, 38])}},\n",
       " {'iter': 2,\n",
       "  'episode': 37,\n",
       "  'step': 1,\n",
       "  'oldState': (array([107.82638645, 109.34471893]), array([18, 18, 38])),\n",
       "  'action': array([[93.00004 , 45.10535 ],\n",
       "         [98.61717 , 52.90488 ],\n",
       "         [25.092684, 36.45119 ]], dtype=float32),\n",
       "  'reward': 4.1833815071058895,\n",
       "  'newState': (array([-108.88351345,  -25.11670685]), array([49, 38, 23])),\n",
       "  'info': {'type': array([49, 38, 23])}},\n",
       " {'iter': 2,\n",
       "  'episode': 37,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-108.88351345,  -25.11670685]), array([49, 38, 23])),\n",
       "  'action': array([[-16.714733 , -12.361013 ],\n",
       "         [ -0.7998604, -15.176834 ],\n",
       "         [-25.11396  , -14.099336 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-66.25495815,  16.52047729]), array([ 4,  5, 23])),\n",
       "  'info': {'type': array([ 4,  5, 23])}},\n",
       " {'iter': 2,\n",
       "  'episode': 38,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[16.31598  , 11.638201 ],\n",
       "         [10.168793 ,  0.9710147],\n",
       "         [10.698571 ,  9.184496 ]], dtype=float32),\n",
       "  'reward': 1.172311284268574,\n",
       "  'newState': (array([62.81665421, 78.20628738]), array([ 2, 19, 36])),\n",
       "  'info': {'type': array([ 2, 19, 36])}},\n",
       " {'iter': 2,\n",
       "  'episode': 38,\n",
       "  'step': 1,\n",
       "  'oldState': (array([62.81665421, 78.20628738]), array([ 2, 19, 36])),\n",
       "  'action': array([[37.795498, 27.929928],\n",
       "         [27.267542,  9.160896],\n",
       "         [62.31873 , 32.021557]], dtype=float32),\n",
       "  'reward': 3.737491502908145,\n",
       "  'newState': (array([-64.5651207,   9.0939064]), array([17, 21, 13])),\n",
       "  'info': {'type': array([17, 21, 13])}},\n",
       " {'iter': 2,\n",
       "  'episode': 38,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-64.5651207,   9.0939064]), array([17, 21, 13])),\n",
       "  'action': array([[7.5126276 , 0.45389143],\n",
       "         [4.6415453 , 7.4545217 ],\n",
       "         [7.715429  , 8.289787  ]], dtype=float32),\n",
       "  'reward': 2.206177981629891,\n",
       "  'newState': (array([-84.4347229 ,  -7.10429382]), array([42, 26, 49])),\n",
       "  'info': {'type': array([42, 26, 49])}},\n",
       " {'iter': 2,\n",
       "  'episode': 39,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.6295033 , -0.2822972 ],\n",
       "         [-5.403822  , -3.1613345 ],\n",
       "         [-0.06681667, -6.5235224 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([108.10014153, 109.96715355]), array([32,  8,  8])),\n",
       "  'info': {'type': array([32,  8,  8])}},\n",
       " {'iter': 2,\n",
       "  'episode': 39,\n",
       "  'step': 1,\n",
       "  'oldState': (array([108.10014153, 109.96715355]), array([32,  8,  8])),\n",
       "  'action': array([[ 91.75444 ,  52.146015],\n",
       "         [ 31.22812 ,  64.372116],\n",
       "         [101.06404 ,  26.48993 ]], dtype=float32),\n",
       "  'reward': 4.514947276183773,\n",
       "  'newState': (array([-115.94645882,  -33.04090309]), array([20, 46,  4])),\n",
       "  'info': {'type': array([20, 46,  4])}},\n",
       " {'iter': 2,\n",
       "  'episode': 39,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-115.94645882,  -33.04090309]), array([20, 46,  4])),\n",
       "  'action': array([[-17.517696 ,  -6.4456134],\n",
       "         [ -1.0145061, -20.057945 ],\n",
       "         [-24.58148  , -15.65111  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-72.83277702,   9.11376762]), array([18, 21, 39])),\n",
       "  'info': {'type': array([18, 21, 39])}},\n",
       " {'iter': 2,\n",
       "  'episode': 40,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.56075096, 3.8734243 ],\n",
       "         [5.2339926 , 4.0131254 ],\n",
       "         [0.6152269 , 3.9284153 ]], dtype=float32),\n",
       "  'reward': 0.6857068613365103,\n",
       "  'newState': (array([93.59002972, 88.18503475]), array([29, 10, 25])),\n",
       "  'info': {'type': array([29, 10, 25])}},\n",
       " {'iter': 2,\n",
       "  'episode': 40,\n",
       "  'step': 1,\n",
       "  'oldState': (array([93.59002972, 88.18503475]), array([29, 10, 25])),\n",
       "  'action': array([[62.114704 , 68.52939  ],\n",
       "         [ 1.3684655,  2.781935 ],\n",
       "         [36.549583 , 53.59418  ]], dtype=float32),\n",
       "  'reward': 3.7891736126958007,\n",
       "  'newState': (array([ -6.44272327, -36.72046757]), array([23, 30, 26])),\n",
       "  'info': {'type': array([23, 30, 26])}},\n",
       " {'iter': 2,\n",
       "  'episode': 40,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -6.44272327, -36.72046757]), array([23, 30, 26])),\n",
       "  'action': array([[-3.106765 , -1.4670969],\n",
       "         [-3.1546664, -6.4125533],\n",
       "         [-4.868593 , -4.567022 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  4.68730164, -24.27379513]), array([13, 11, 42])),\n",
       "  'info': {'type': array([13, 11, 42])}},\n",
       " {'iter': 2,\n",
       "  'episode': 41,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.0215119, 3.290677 ],\n",
       "         [2.234872 , 4.640205 ],\n",
       "         [4.5061007, 2.4523833]], dtype=float32),\n",
       "  'reward': 1.012129292590768,\n",
       "  'newState': (array([92.23751545, 89.6167345 ]), array([10, 24, 24])),\n",
       "  'info': {'type': array([10, 24, 24])}},\n",
       " {'iter': 2,\n",
       "  'episode': 41,\n",
       "  'step': 1,\n",
       "  'oldState': (array([92.23751545, 89.6167345 ]), array([10, 24, 24])),\n",
       "  'action': array([[61.716373, 78.809425],\n",
       "         [35.972927, 50.181618],\n",
       "         [32.436264, 28.36516 ]], dtype=float32),\n",
       "  'reward': 4.030754834800063,\n",
       "  'newState': (array([-37.88804913, -67.73946667]), array([47,  4, 43])),\n",
       "  'info': {'type': array([47,  4, 43])}},\n",
       " {'iter': 2,\n",
       "  'episode': 41,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-37.88804913, -67.73946667]), array([47,  4, 43])),\n",
       "  'action': array([[-12.144431, -25.208776],\n",
       "         [-23.429914, -15.633899],\n",
       "         [-18.174715,  -2.900916]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 15.86101246, -23.99587536]), array([27, 13,  6])),\n",
       "  'info': {'type': array([27, 13,  6])}},\n",
       " {'iter': 2,\n",
       "  'episode': 42,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 2.811226 ,  9.103968 ],\n",
       "         [14.086966 ,  7.9944415],\n",
       "         [13.461106 ,  4.709175 ]], dtype=float32),\n",
       "  'reward': 1.750450455010322,\n",
       "  'newState': (array([69.64070129, 78.19241524]), array([ 2,  3, 29])),\n",
       "  'info': {'type': array([ 2,  3, 29])}},\n",
       " {'iter': 2,\n",
       "  'episode': 42,\n",
       "  'step': 1,\n",
       "  'oldState': (array([69.64070129, 78.19241524]), array([ 2,  3, 29])),\n",
       "  'action': array([[60.70546 , 37.388123],\n",
       "         [76.3652  ,  9.492628],\n",
       "         [ 8.154419, 18.564486]], dtype=float32),\n",
       "  'reward': 3.242334791244221,\n",
       "  'newState': (array([-75.58436584,  12.74717903]), array([42,  4, 28])),\n",
       "  'info': {'type': array([42,  4, 28])}},\n",
       " {'iter': 2,\n",
       "  'episode': 42,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-75.58436584,  12.74717903]), array([42,  4, 28])),\n",
       "  'action': array([[6.676867  , 0.18571995],\n",
       "         [2.8128984 , 8.828298  ],\n",
       "         [8.198149  , 8.197159  ]], dtype=float32),\n",
       "  'reward': 2.253661701621012,\n",
       "  'newState': (array([-93.27227974,  -4.46399689]), array([35, 37, 18])),\n",
       "  'info': {'type': array([35, 37, 18])}},\n",
       " {'iter': 2,\n",
       "  'episode': 43,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.5039897, -3.0908732],\n",
       "         [-3.9336846, -2.0320516],\n",
       "         [-2.519136 , -4.1351376]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([107.95681047, 109.25806236]), array([38, 13, 46])),\n",
       "  'info': {'type': array([38, 13, 46])}},\n",
       " {'iter': 2,\n",
       "  'episode': 43,\n",
       "  'step': 1,\n",
       "  'oldState': (array([107.95681047, 109.25806236]), array([38, 13, 46])),\n",
       "  'action': array([[38.614727, 45.533463],\n",
       "         [71.48968 , 90.17942 ],\n",
       "         [38.009495, 95.93621 ]], dtype=float32),\n",
       "  'reward': 4.357149346705394,\n",
       "  'newState': (array([ -40.15708113, -122.39104652]), array([14, 41,  6])),\n",
       "  'info': {'type': array([14, 41,  6])}},\n",
       " {'iter': 2,\n",
       "  'episode': 43,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -40.15708113, -122.39104652]), array([14, 41,  6])),\n",
       "  'action': array([[-33.02711  , -29.27168  ],\n",
       "         [-34.643715 , -33.915928 ],\n",
       "         [ -0.4291093, -22.887634 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 27.94284868, -36.31580544]), array([27, 16, 20])),\n",
       "  'info': {'type': array([27, 16, 20])}},\n",
       " {'iter': 2,\n",
       "  'episode': 44,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[17.337126  ,  6.775209  ],\n",
       "         [ 0.47239178, 23.953833  ],\n",
       "         [12.267095  ,  7.9473705 ]], dtype=float32),\n",
       "  'reward': 3.0490561257035886,\n",
       "  'newState': (array([69.92338943, 61.32358551]), array([23, 35,  7])),\n",
       "  'info': {'type': array([23, 35,  7])}},\n",
       " {'iter': 2,\n",
       "  'episode': 44,\n",
       "  'step': 1,\n",
       "  'oldState': (array([69.92338943, 61.32358551]), array([23, 35,  7])),\n",
       "  'action': array([[63.436073 , 53.75574  ],\n",
       "         [30.082035 ,  2.6853182],\n",
       "         [62.496853 ,  1.8965548]], dtype=float32),\n",
       "  'reward': 2.4489046763873303,\n",
       "  'newState': (array([-86.09157944,   2.98597336]), array([ 6, 21,  0])),\n",
       "  'info': {'type': array([ 6, 21,  0])}},\n",
       " {'iter': 2,\n",
       "  'episode': 44,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-86.09157944,   2.98597336]), array([ 6, 21,  0])),\n",
       "  'action': array([[0.2403195 , 0.10709979],\n",
       "         [0.8169394 , 2.7335112 ],\n",
       "         [0.5782079 , 0.9055581 ]], dtype=float32),\n",
       "  'reward': 0.4652818492600977,\n",
       "  'newState': (array([-87.72704625,  -0.76019573]), array([26,  9, 41])),\n",
       "  'info': {'type': array([26,  9, 41])}},\n",
       " {'iter': 2,\n",
       "  'episode': 45,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.53613925, -0.5534238 ],\n",
       "         [-0.06298208, -0.0478509 ],\n",
       "         [-0.07403098, -0.3248564 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([100.67315233, 100.92613113]), array([28,  3, 21])),\n",
       "  'info': {'type': array([28,  3, 21])}},\n",
       " {'iter': 2,\n",
       "  'episode': 45,\n",
       "  'step': 1,\n",
       "  'oldState': (array([100.67315233, 100.92613113]), array([28,  3, 21])),\n",
       "  'action': array([[84.88868 , 34.086536],\n",
       "         [42.04201 , 72.22474 ],\n",
       "         [ 4.641978, 91.18366 ]], dtype=float32),\n",
       "  'reward': 4.48096201738779,\n",
       "  'newState': (array([-30.89952528, -96.56880295]), array([47, 33,  7])),\n",
       "  'info': {'type': array([47, 33,  7])}},\n",
       " {'iter': 2,\n",
       "  'episode': 45,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-30.89952528, -96.56880295]), array([47, 33,  7])),\n",
       "  'action': array([[-28.151367 , -20.242313 ],\n",
       "         [-19.180544 , -11.599782 ],\n",
       "         [-26.592148 ,  -3.2512357]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 43.02453172, -61.47547257]), array([ 8, 39, 33])),\n",
       "  'info': {'type': array([ 8, 39, 33])}},\n",
       " {'iter': 2,\n",
       "  'episode': 46,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[38.90492  , 24.273155 ],\n",
       "         [28.205875 ,  5.961348 ],\n",
       "         [ 7.3980637, 11.560623 ]], dtype=float32),\n",
       "  'reward': 2.5330020538214253,\n",
       "  'newState': (array([25.49114227, 58.20487213]), array([39, 35,  7])),\n",
       "  'info': {'type': array([39, 35,  7])}},\n",
       " {'iter': 2,\n",
       "  'episode': 46,\n",
       "  'step': 1,\n",
       "  'oldState': (array([25.49114227, 58.20487213]), array([39, 35,  7])),\n",
       "  'action': array([[18.372316, 11.296813],\n",
       "         [15.230132, 23.092312],\n",
       "         [31.008307, 37.943485]], dtype=float32),\n",
       "  'reward': 3.123941957573027,\n",
       "  'newState': (array([-39.11961365, -14.12773895]), array([41, 27, 40])),\n",
       "  'info': {'type': array([41, 27, 40])}},\n",
       " {'iter': 2,\n",
       "  'episode': 46,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-39.11961365, -14.12773895]), array([41, 27, 40])),\n",
       "  'action': array([[ -7.483032,  -8.92806 ],\n",
       "         [-13.864653, -13.372835],\n",
       "         [ -7.484393, -11.280938]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-10.28753662,  19.45409393]), array([ 7, 36, 45])),\n",
       "  'info': {'type': array([ 7, 36, 45])}},\n",
       " {'iter': 2,\n",
       "  'episode': 47,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[11.167712 ,  7.1550617],\n",
       "         [13.178136 , 14.933404 ],\n",
       "         [ 5.4658623,  0.4076648]], dtype=float32),\n",
       "  'reward': 2.542360334604917,\n",
       "  'newState': (array([70.18828964, 77.5038681 ]), array([30,  9, 47])),\n",
       "  'info': {'type': array([30,  9, 47])}},\n",
       " {'iter': 2,\n",
       "  'episode': 47,\n",
       "  'step': 1,\n",
       "  'oldState': (array([70.18828964, 77.5038681 ]), array([30,  9, 47])),\n",
       "  'action': array([[20.293205, 42.27212 ],\n",
       "         [ 9.940983, 10.738044],\n",
       "         [ 3.430072, 61.372105]], dtype=float32),\n",
       "  'reward': 3.578205370948894,\n",
       "  'newState': (array([ 36.52402878, -36.87840271]), array([24, 46, 21])),\n",
       "  'info': {'type': array([24, 46, 21])}},\n",
       " {'iter': 2,\n",
       "  'episode': 47,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 36.52402878, -36.87840271]), array([24, 46, 21])),\n",
       "  'action': array([[33.97025 , 35.025166],\n",
       "         [16.306442, 30.68862 ],\n",
       "         [21.803318, 28.079964]], dtype=float32),\n",
       "  'reward': 3.562792020283577,\n",
       "  'newState': (array([ -35.55598068, -130.67214966]), array([ 0, 19, 19])),\n",
       "  'info': {'type': array([ 0, 19, 19])}},\n",
       " {'iter': 2,\n",
       "  'episode': 48,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-12.19427  , -25.277174 ],\n",
       "         [ -6.4530954, -34.265938 ],\n",
       "         [ -7.3039246, -27.109715 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([125.95129013, 186.65283203]), array([21, 27, 33])),\n",
       "  'info': {'type': array([21, 27, 33])}},\n",
       " {'iter': 2,\n",
       "  'episode': 48,\n",
       "  'step': 1,\n",
       "  'oldState': (array([125.95129013, 186.65283203]), array([21, 27, 33])),\n",
       "  'action': array([[  2.5944269, 174.88664  ],\n",
       "         [151.4057   ,  17.44758  ],\n",
       "         [150.59738  ,   4.546401 ]], dtype=float32),\n",
       "  'reward': 3.2553423593633295,\n",
       "  'newState': (array([-178.64621353,  -10.22779846]), array([40, 46, 42])),\n",
       "  'info': {'type': array([40, 46, 42])}},\n",
       " {'iter': 2,\n",
       "  'episode': 48,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-178.64621353,  -10.22779846]), array([40, 46, 42])),\n",
       "  'action': array([[-2.7992473, -1.9318005],\n",
       "         [-7.4336433, -3.5108147],\n",
       "         [-5.3521576, -7.259058 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-163.06116486,    2.47387505]), array([21, 30, 47])),\n",
       "  'info': {'type': array([21, 30, 47])}},\n",
       " {'iter': 2,\n",
       "  'episode': 49,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.59563345, 1.4094709 ],\n",
       "         [0.177194  , 1.2443249 ],\n",
       "         [0.77230936, 1.0857931 ]], dtype=float32),\n",
       "  'reward': -0.02353788378904416,\n",
       "  'newState': (array([98.45486319, 96.26041126]), array([18,  3, 35])),\n",
       "  'info': {'type': array([18,  3, 35])}},\n",
       " {'iter': 2,\n",
       "  'episode': 49,\n",
       "  'step': 1,\n",
       "  'oldState': (array([98.45486319, 96.26041126]), array([18,  3, 35])),\n",
       "  'action': array([[91.833984, 11.587701],\n",
       "         [46.62498 , 69.901146],\n",
       "         [12.420317, 52.387318]], dtype=float32),\n",
       "  'reward': 4.2875133790053175,\n",
       "  'newState': (array([-52.42442453, -37.61574841]), array([31, 29, 39])),\n",
       "  'info': {'type': array([31, 29, 39])}},\n",
       " {'iter': 2,\n",
       "  'episode': 49,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-52.42442453, -37.61574841]), array([31, 29, 39])),\n",
       "  'action': array([[-37.45094  ,  -5.9376545],\n",
       "         [-12.0721   , -25.71298  ],\n",
       "         [-12.482724 ,  -8.961199 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([9.58133948, 2.99608326]), array([22, 10, 42])),\n",
       "  'info': {'type': array([22, 10, 42])}},\n",
       " {'iter': 2,\n",
       "  'episode': 50,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[9.171788 , 1.0463638],\n",
       "         [8.979245 , 5.961505 ],\n",
       "         [7.8692436, 3.9931746]], dtype=float32),\n",
       "  'reward': 1.982486101402332,\n",
       "  'newState': (array([73.97972298, 88.99895668]), array([ 8, 31, 12])),\n",
       "  'info': {'type': array([ 8, 31, 12])}},\n",
       " {'iter': 2,\n",
       "  'episode': 50,\n",
       "  'step': 1,\n",
       "  'oldState': (array([73.97972298, 88.99895668]), array([ 8, 31, 12])),\n",
       "  'action': array([[75.21716  , 64.122475 ],\n",
       "         [ 3.5623026, 26.154942 ],\n",
       "         [77.603004 , 27.624239 ]], dtype=float32),\n",
       "  'reward': 3.757287935886403,\n",
       "  'newState': (array([-82.40275383, -28.90270042]), array([18,  7, 23])),\n",
       "  'info': {'type': array([18,  7, 23])}},\n",
       " {'iter': 2,\n",
       "  'episode': 50,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-82.40275383, -28.90270042]), array([18,  7, 23])),\n",
       "  'action': array([[ -2.9162347, -23.066137 ],\n",
       "         [-22.59196  , -21.406273 ],\n",
       "         [ -8.686251 , -13.065778 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-48.20830727,  28.63548851]), array([ 8, 23, 46])),\n",
       "  'info': {'type': array([ 8, 23, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 1,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 9.167456, 16.197731],\n",
       "         [13.080093, 27.73296 ],\n",
       "         [11.330371,  4.433866]], dtype=float32),\n",
       "  'reward': 2.8884861356697846,\n",
       "  'newState': (array([66.42208099, 51.63544464]), array([34, 30,  3])),\n",
       "  'info': {'type': array([34, 30,  3])}},\n",
       " {'iter': 3,\n",
       "  'episode': 1,\n",
       "  'step': 1,\n",
       "  'oldState': (array([66.42208099, 51.63544464]), array([34, 30,  3])),\n",
       "  'action': array([[10.551768, 42.3307  ],\n",
       "         [63.590065, 39.444065],\n",
       "         [48.80404 , 46.35687 ]], dtype=float32),\n",
       "  'reward': 3.0451819861534988,\n",
       "  'newState': (array([-56.52378845, -76.49619293]), array([48, 42,  4])),\n",
       "  'info': {'type': array([48, 42,  4])}},\n",
       " {'iter': 3,\n",
       "  'episode': 1,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-56.52378845, -76.49619293]), array([48, 42,  4])),\n",
       "  'action': array([[-33.787647, -44.776016],\n",
       "         [-24.449228, -19.527016],\n",
       "         [-17.58102 , -56.08507 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([19.29411316, 43.89191437]), array([48, 15, 24])),\n",
       "  'info': {'type': array([48, 15, 24])}},\n",
       " {'iter': 3,\n",
       "  'episode': 2,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 3.1327434, 35.333096 ],\n",
       "         [23.724977 , 15.69604  ],\n",
       "         [11.680722 , 41.374645 ]], dtype=float32),\n",
       "  'reward': 2.2443079410686737,\n",
       "  'newState': (array([61.46155548,  7.59622192]), array([30, 42, 26])),\n",
       "  'info': {'type': array([30, 42, 26])}},\n",
       " {'iter': 3,\n",
       "  'episode': 2,\n",
       "  'step': 1,\n",
       "  'oldState': (array([61.46155548,  7.59622192]), array([30, 42, 26])),\n",
       "  'action': array([[10.25559  , 24.297039 ],\n",
       "         [ 2.4040186, 29.103912 ],\n",
       "         [13.433053 , 13.801538 ]], dtype=float32),\n",
       "  'reward': 3.0339594314926535,\n",
       "  'newState': (array([ 35.36889267, -59.60626984]), array([34, 45, 47])),\n",
       "  'info': {'type': array([34, 45, 47])}},\n",
       " {'iter': 3,\n",
       "  'episode': 2,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 35.36889267, -59.60626984]), array([34, 45, 47])),\n",
       "  'action': array([[17.62857  , 34.826344 ],\n",
       "         [19.563427 ,  3.5953467],\n",
       "         [13.770388 ,  8.944573 ]], dtype=float32),\n",
       "  'reward': 2.3962670472329846,\n",
       "  'newState': (array([ -15.59349442, -106.97253418]), array([23, 40, 35])),\n",
       "  'info': {'type': array([23, 40, 35])}},\n",
       " {'iter': 3,\n",
       "  'episode': 3,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -7.9879265 , -12.273715  ],\n",
       "         [ -0.43086836,  -1.8036448 ],\n",
       "         [ -8.679374  ,  -9.896761  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([117.09816742, 123.97412109]), array([16, 23, 47])),\n",
       "  'info': {'type': array([16, 23, 47])}},\n",
       " {'iter': 3,\n",
       "  'episode': 3,\n",
       "  'step': 1,\n",
       "  'oldState': (array([117.09816742, 123.97412109]), array([16, 23, 47])),\n",
       "  'action': array([[ 61.221222, 116.55105 ],\n",
       "         [102.09637 ,  32.7512  ],\n",
       "         [ 40.433666,  95.49561 ]], dtype=float32),\n",
       "  'reward': 4.38311450385254,\n",
       "  'newState': (array([ -86.65309906, -120.82373047]), array([26, 14, 23])),\n",
       "  'info': {'type': array([26, 14, 23])}},\n",
       " {'iter': 3,\n",
       "  'episode': 3,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -86.65309906, -120.82373047]), array([26, 14, 23])),\n",
       "  'action': array([[-21.002453, -12.667288],\n",
       "         [-58.614918,  -8.789764],\n",
       "         [-18.732866, -14.68378 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 11.69713593, -84.68289948]), array([24, 49, 24])),\n",
       "  'info': {'type': array([24, 49, 24])}},\n",
       " {'iter': 3,\n",
       "  'episode': 4,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[2.7772267, 3.9898424],\n",
       "         [1.6652876, 2.8362179],\n",
       "         [4.6503325, 6.180282 ]], dtype=float32),\n",
       "  'reward': 1.1155915401382759,\n",
       "  'newState': (array([90.90715313, 86.99365807]), array([15,  3,  9])),\n",
       "  'info': {'type': array([15,  3,  9])}},\n",
       " {'iter': 3,\n",
       "  'episode': 4,\n",
       "  'step': 1,\n",
       "  'oldState': (array([90.90715313, 86.99365807]), array([15,  3,  9])),\n",
       "  'action': array([[72.99452  , 29.060957 ],\n",
       "         [ 0.9259561, 54.454998 ],\n",
       "         [65.68684  , 46.69113  ]], dtype=float32),\n",
       "  'reward': 4.401655592932038,\n",
       "  'newState': (array([-48.70016193, -43.21343422]), array([46, 20,  2])),\n",
       "  'info': {'type': array([46, 20,  2])}},\n",
       " {'iter': 3,\n",
       "  'episode': 4,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-48.70016193, -43.21343422]), array([46, 20,  2])),\n",
       "  'action': array([[-24.19786  , -16.858662 ],\n",
       "         [-25.569176 ,  -5.3097854],\n",
       "         [-26.281214 , -31.700151 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([27.34808636, 10.65516472]), array([30, 12, 25])),\n",
       "  'info': {'type': array([30, 12, 25])}},\n",
       " {'iter': 3,\n",
       "  'episode': 5,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[24.722673 ,  3.5593324],\n",
       "         [21.20567  , 16.08836  ],\n",
       "         [27.111837 , 20.848305 ]], dtype=float32),\n",
       "  'reward': 2.999181730220872,\n",
       "  'newState': (array([26.95981598, 59.50400543]), array([ 0, 33, 34])),\n",
       "  'info': {'type': array([ 0, 33, 34])}},\n",
       " {'iter': 3,\n",
       "  'episode': 5,\n",
       "  'step': 1,\n",
       "  'oldState': (array([26.95981598, 59.50400543]), array([ 0, 33, 34])),\n",
       "  'action': array([[ 6.5019655,  3.0554504],\n",
       "         [34.422062 , 13.040936 ],\n",
       "         [44.03033  , 48.812828 ]], dtype=float32),\n",
       "  'reward': 3.5641503838863837,\n",
       "  'newState': (array([-57.99454498,  -5.40520477]), array([13, 11, 26])),\n",
       "  'info': {'type': array([13, 11, 26])}},\n",
       " {'iter': 3,\n",
       "  'episode': 5,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-57.99454498,  -5.40520477]), array([13, 11, 26])),\n",
       "  'action': array([[-5.1229386 , -3.5933027 ],\n",
       "         [-3.2386136 , -5.226288  ],\n",
       "         [-0.01959713, -4.0349813 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-49.61339569,   7.44936752]), array([24, 43, 41])),\n",
       "  'info': {'type': array([24, 43, 41])}},\n",
       " {'iter': 3,\n",
       "  'episode': 6,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[4.325338 , 3.471281 ],\n",
       "         [6.8945704, 4.996738 ],\n",
       "         [0.2926777, 6.7797394]], dtype=float32),\n",
       "  'reward': 1.5775591964735893,\n",
       "  'newState': (array([88.48741436, 84.75224113]), array([47, 13, 40])),\n",
       "  'info': {'type': array([47, 13, 40])}},\n",
       " {'iter': 3,\n",
       "  'episode': 6,\n",
       "  'step': 1,\n",
       "  'oldState': (array([88.48741436, 84.75224113]), array([47, 13, 40])),\n",
       "  'action': array([[11.180031, 78.99328 ],\n",
       "         [18.956118, 13.183386],\n",
       "         [44.162045, 45.568798]], dtype=float32),\n",
       "  'reward': 3.268631016792704,\n",
       "  'newState': (array([ 14.18921947, -52.99322701]), array([31, 38, 15])),\n",
       "  'info': {'type': array([31, 38, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 6,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 14.18921947, -52.99322701]), array([31, 38, 15])),\n",
       "  'action': array([[0.25647315, 6.342205  ],\n",
       "         [5.599534  , 0.19413039],\n",
       "         [7.373889  , 9.430413  ]], dtype=float32),\n",
       "  'reward': -0.7398655281842622,\n",
       "  'newState': (array([  0.95932293, -68.9599762 ]), array([25, 41, 31])),\n",
       "  'info': {'type': array([25, 41, 31])}},\n",
       " {'iter': 3,\n",
       "  'episode': 7,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.2091611 , 0.07423552],\n",
       "         [0.8894272 , 0.39430222],\n",
       "         [0.45049056, 0.5229995 ]], dtype=float32),\n",
       "  'reward': -1.1053549201748472,\n",
       "  'newState': (array([98.45092118, 99.00846273]), array([46, 33, 38])),\n",
       "  'info': {'type': array([46, 33, 38])}},\n",
       " {'iter': 3,\n",
       "  'episode': 7,\n",
       "  'step': 1,\n",
       "  'oldState': (array([98.45092118, 99.00846273]), array([46, 33, 38])),\n",
       "  'action': array([[ 8.893257 , 15.059709 ],\n",
       "         [ 4.757305 , 48.4839   ],\n",
       "         [ 1.3765793, 53.479404 ]], dtype=float32),\n",
       "  'reward': 3.2545570154317986,\n",
       "  'newState': (array([ 83.42377961, -18.01454753]), array([28, 43, 20])),\n",
       "  'info': {'type': array([28, 43, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 7,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 83.42377961, -18.01454753]), array([28, 43, 20])),\n",
       "  'action': array([[13.016043, 49.97875 ],\n",
       "         [58.12829 , 17.584803],\n",
       "         [20.955315, 72.415985]], dtype=float32),\n",
       "  'reward': 3.14139891574659,\n",
       "  'newState': (array([  -8.67586792, -157.99408549]), array([14,  9, 42])),\n",
       "  'info': {'type': array([14,  9, 42])}},\n",
       " {'iter': 3,\n",
       "  'episode': 8,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-7.750513 , -4.1189613],\n",
       "         [-7.639215 , -4.2400355],\n",
       "         [-3.9894128, -3.6339948]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([119.37914085, 111.9929924 ]), array([ 3, 17, 15])),\n",
       "  'info': {'type': array([ 3, 17, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 8,\n",
       "  'step': 1,\n",
       "  'oldState': (array([119.37914085, 111.9929924 ]), array([ 3, 17, 15])),\n",
       "  'action': array([[91.04994 , 88.89467 ],\n",
       "         [95.804474,  8.956698],\n",
       "         [46.264523, 47.00564 ]], dtype=float32),\n",
       "  'reward': 3.39535875945333,\n",
       "  'newState': (array([-113.73980141,  -32.86400223]), array([ 3, 47,  6])),\n",
       "  'info': {'type': array([ 3, 47,  6])}},\n",
       " {'iter': 3,\n",
       "  'episode': 8,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-113.73980141,  -32.86400223]), array([ 3, 47,  6])),\n",
       "  'action': array([[ -2.3666499, -24.02993  ],\n",
       "         [-23.511808 , -31.631584 ],\n",
       "         [-23.665339 , -28.21914  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-64.19600487,  51.01665115]), array([42,  5, 20])),\n",
       "  'info': {'type': array([42,  5, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 9,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[25.759705, 15.743514],\n",
       "         [20.694551, 47.058586],\n",
       "         [20.32906 , 19.801012]], dtype=float32),\n",
       "  'reward': 3.6239982301770155,\n",
       "  'newState': (array([33.21669006, 17.39688873]), array([13, 24, 46])),\n",
       "  'info': {'type': array([13, 24, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 9,\n",
       "  'step': 1,\n",
       "  'oldState': (array([33.21669006, 17.39688873]), array([13, 24, 46])),\n",
       "  'action': array([[19.650223, 16.063265],\n",
       "         [ 7.509665, 25.22017 ],\n",
       "         [32.664787, 11.601334]], dtype=float32),\n",
       "  'reward': 3.500345928907849,\n",
       "  'newState': (array([-26.60798645, -35.48787689]), array([15, 36, 16])),\n",
       "  'info': {'type': array([15, 36, 16])}},\n",
       " {'iter': 3,\n",
       "  'episode': 9,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-26.60798645, -35.48787689]), array([15, 36, 16])),\n",
       "  'action': array([[ -1.9291775 , -21.643959  ],\n",
       "         [-11.641678  , -26.10243   ],\n",
       "         [-17.504097  ,  -0.58740914]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 4.46696472, 12.84592438]), array([ 9, 19, 24])),\n",
       "  'info': {'type': array([ 9, 19, 24])}},\n",
       " {'iter': 3,\n",
       "  'episode': 10,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[12.671823 , 10.718164 ],\n",
       "         [ 9.885531 ,  4.393945 ],\n",
       "         [ 4.932875 ,  3.1494553]], dtype=float32),\n",
       "  'reward': 1.8997680303412972,\n",
       "  'newState': (array([72.50977135, 81.73843384]), array([18, 14,  6])),\n",
       "  'info': {'type': array([18, 14,  6])}},\n",
       " {'iter': 3,\n",
       "  'episode': 10,\n",
       "  'step': 1,\n",
       "  'oldState': (array([72.50977135, 81.73843384]), array([18, 14,  6])),\n",
       "  'action': array([[24.59989 , 69.23815 ],\n",
       "         [13.167968,  5.748094],\n",
       "         [38.361256, 19.968971]], dtype=float32),\n",
       "  'reward': 2.803427226094339,\n",
       "  'newState': (array([ -3.6193409 , -13.21678162]), array([27, 23,  5])),\n",
       "  'info': {'type': array([27, 23,  5])}},\n",
       " {'iter': 3,\n",
       "  'episode': 10,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -3.6193409 , -13.21678162]), array([27, 23,  5])),\n",
       "  'action': array([[-0.8623981 , -3.4235413 ],\n",
       "         [-3.3908722 , -2.2845216 ],\n",
       "         [-0.84722185, -2.1947784 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 1.4811511 , -5.31394005]), array([ 4, 23, 46])),\n",
       "  'info': {'type': array([ 4, 23, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 11,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.2088826 , 0.15885383],\n",
       "         [0.5915783 , 0.9345513 ],\n",
       "         [1.4632623 , 0.67787075]], dtype=float32),\n",
       "  'reward': 0.07528323459262505,\n",
       "  'newState': (array([96.73627687, 98.22872412]), array([39,  2, 13])),\n",
       "  'info': {'type': array([39,  2, 13])}},\n",
       " {'iter': 3,\n",
       "  'episode': 11,\n",
       "  'step': 1,\n",
       "  'oldState': (array([96.73627687, 98.22872412]), array([39,  2, 13])),\n",
       "  'action': array([[59.265675 , 70.63717  ],\n",
       "         [30.210836 , 43.419426 ],\n",
       "         [62.13862  ,  9.3835745]], dtype=float32),\n",
       "  'reward': 4.115761049978288,\n",
       "  'newState': (array([-54.8788507 , -25.21144617]), array([42, 26, 24])),\n",
       "  'info': {'type': array([42, 26, 24])}},\n",
       " {'iter': 3,\n",
       "  'episode': 11,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-54.8788507 , -25.21144617]), array([42, 26, 24])),\n",
       "  'action': array([[-24.502655 ,  -1.6697775],\n",
       "         [-10.494064 , -19.022076 ],\n",
       "         [ -5.9280233,  -2.7960753]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-13.95410705,  -1.72351778]), array([17, 23,  1])),\n",
       "  'info': {'type': array([17, 23,  1])}},\n",
       " {'iter': 3,\n",
       "  'episode': 12,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.2267627 , -0.49268505],\n",
       "         [-1.0136803 , -1.6938473 ],\n",
       "         [-0.69545346, -1.3124661 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([102.9358964, 103.4989984]), array([45, 21, 47])),\n",
       "  'info': {'type': array([45, 21, 47])}},\n",
       " {'iter': 3,\n",
       "  'episode': 12,\n",
       "  'step': 1,\n",
       "  'oldState': (array([102.9358964, 103.4989984]), array([45, 21, 47])),\n",
       "  'action': array([[33.956966  , 95.26995   ],\n",
       "         [19.582952  , 89.88173   ],\n",
       "         [32.420277  ,  0.79253507]], dtype=float32),\n",
       "  'reward': 3.6967751983687447,\n",
       "  'newState': (array([ 16.97570658, -82.44521546]), array([17, 33, 43])),\n",
       "  'info': {'type': array([17, 33, 43])}},\n",
       " {'iter': 3,\n",
       "  'episode': 12,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 16.97570658, -82.44521546]), array([17, 33, 43])),\n",
       "  'action': array([[10.001876  ,  1.2137915 ],\n",
       "         [ 6.265632  , 11.425264  ],\n",
       "         [13.824986  ,  0.69801587]], dtype=float32),\n",
       "  'reward': 2.5224298970360572,\n",
       "  'newState': (array([-13.11678839, -95.78228784]), array([11, 34,  2])),\n",
       "  'info': {'type': array([11, 34,  2])}},\n",
       " {'iter': 3,\n",
       "  'episode': 13,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-11.559146 ,  -7.6874413],\n",
       "         [ -6.5128675,  -1.1458044],\n",
       "         [-13.10974  ,  -0.042559 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([131.18175507, 108.8758049 ]), array([32, 26, 19])),\n",
       "  'info': {'type': array([32, 26, 19])}},\n",
       " {'iter': 3,\n",
       "  'episode': 13,\n",
       "  'step': 1,\n",
       "  'oldState': (array([131.18175507, 108.8758049 ]), array([32, 26, 19])),\n",
       "  'action': array([[120.79665  , 111.07455  ],\n",
       "         [ 85.19647  ,  86.90719  ],\n",
       "         [  2.1000996, 102.36303  ]], dtype=float32),\n",
       "  'reward': 4.647080305806214,\n",
       "  'newState': (array([ -76.91147614, -191.46895218]), array([26, 26,  7])),\n",
       "  'info': {'type': array([26, 26,  7])}},\n",
       " {'iter': 3,\n",
       "  'episode': 13,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -76.91147614, -191.46895218]), array([26, 26,  7])),\n",
       "  'action': array([[-49.972084 , -67.678345 ],\n",
       "         [-76.64027  , -56.846752 ],\n",
       "         [ -2.8540711, -70.793785 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([52.55493927,  3.84992599]), array([35, 31, 15])),\n",
       "  'info': {'type': array([35, 31, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 14,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[39.262386, 39.62726 ],\n",
       "         [45.766815, 44.96645 ],\n",
       "         [14.574003, 24.320793]], dtype=float32),\n",
       "  'reward': 3.7481483212340057,\n",
       "  'newState': (array([ 0.39678955, -8.91449738]), array([28, 12, 46])),\n",
       "  'info': {'type': array([28, 12, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 14,\n",
       "  'step': 1,\n",
       "  'oldState': (array([ 0.39678955, -8.91449738]), array([28, 12, 46])),\n",
       "  'action': array([[0.25238127, 0.12916915],\n",
       "         [0.03799639, 0.09229122],\n",
       "         [0.15575683, 0.14592864]], dtype=float32),\n",
       "  'reward': -1.4217385068635295,\n",
       "  'newState': (array([-0.04934493, -9.2818864 ]), array([23,  6,  5])),\n",
       "  'info': {'type': array([23,  6,  5])}},\n",
       " {'iter': 3,\n",
       "  'episode': 14,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-0.04934493, -9.2818864 ]), array([23,  6,  5])),\n",
       "  'action': array([[-0.03636894, -0.01612185],\n",
       "         [-0.03784946, -0.00863905],\n",
       "         [-0.0193916 , -0.02719886]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 0.04426508, -9.22992663]), array([28, 34, 23])),\n",
       "  'info': {'type': array([28, 34, 23])}},\n",
       " {'iter': 3,\n",
       "  'episode': 15,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.00478173, 0.03623189],\n",
       "         [0.04328821, 0.01496147],\n",
       "         [0.02805085, 0.02193282]], dtype=float32),\n",
       "  'reward': -4.541905849151144,\n",
       "  'newState': (array([99.92387921, 99.92687382]), array([21, 10, 15])),\n",
       "  'info': {'type': array([21, 10, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 15,\n",
       "  'step': 1,\n",
       "  'oldState': (array([99.92387921, 99.92687382]), array([21, 10, 15])),\n",
       "  'action': array([[31.858507, 38.616104],\n",
       "         [19.450922, 38.2116  ],\n",
       "         [86.68262 ,  2.224343]], dtype=float32),\n",
       "  'reward': 3.835492207564316,\n",
       "  'newState': (array([-38.06817096,  20.87482609]), array([14, 23,  1])),\n",
       "  'info': {'type': array([14, 23,  1])}},\n",
       " {'iter': 3,\n",
       "  'episode': 15,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-38.06817096,  20.87482609]), array([14, 23,  1])),\n",
       "  'action': array([[ 0.13069794,  1.761024  ],\n",
       "         [ 4.955723  , 18.116425  ],\n",
       "         [19.776978  , 13.153638  ]], dtype=float32),\n",
       "  'reward': 1.0956081201484542,\n",
       "  'newState': (array([-62.93156856, -12.15625988]), array([20, 11, 12])),\n",
       "  'info': {'type': array([20, 11, 12])}},\n",
       " {'iter': 3,\n",
       "  'episode': 16,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -3.0447867,  -4.111195 ],\n",
       "         [-10.933185 ,  -7.1725326],\n",
       "         [ -6.626507 ,  -9.953879 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([120.60447693, 121.23760605]), array([47, 26, 18])),\n",
       "  'info': {'type': array([47, 26, 18])}},\n",
       " {'iter': 3,\n",
       "  'episode': 16,\n",
       "  'step': 1,\n",
       "  'oldState': (array([120.60447693, 121.23760605]), array([47, 26, 18])),\n",
       "  'action': array([[ 65.80393 ,  17.911861],\n",
       "         [ 93.85862 ,  27.452446],\n",
       "         [ 39.69651 , 117.338936]], dtype=float32),\n",
       "  'reward': 4.108947977984932,\n",
       "  'newState': (array([-78.7545929 , -41.46564102]), array([45,  1, 28])),\n",
       "  'info': {'type': array([45,  1, 28])}},\n",
       " {'iter': 3,\n",
       "  'episode': 16,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-78.7545929 , -41.46564102]), array([45,  1, 28])),\n",
       "  'action': array([[ -5.6556535,  -2.8967566],\n",
       "         [-12.909925 , -20.016005 ],\n",
       "         [ -3.1433377,  -5.510862 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-57.04567719, -13.04201698]), array([23, 38, 20])),\n",
       "  'info': {'type': array([23, 38, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 17,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-11.45778  ,  -1.817818 ],\n",
       "         [ -6.0813484, -12.424724 ],\n",
       "         [ -3.931311 ,  -0.4374601]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([121.470438  , 114.68000126]), array([33, 46, 30])),\n",
       "  'info': {'type': array([33, 46, 30])}},\n",
       " {'iter': 3,\n",
       "  'episode': 17,\n",
       "  'step': 1,\n",
       "  'oldState': (array([121.470438  , 114.68000126]), array([33, 46, 30])),\n",
       "  'action': array([[ 16.50915 , 104.76988 ],\n",
       "         [ 68.19069 ,  49.741314],\n",
       "         [ 90.63054 ,  58.19036 ]], dtype=float32),\n",
       "  'reward': 3.874549935475801,\n",
       "  'newState': (array([-53.8599453 , -98.02156734]), array([ 0, 14, 33])),\n",
       "  'info': {'type': array([ 0, 14, 33])}},\n",
       " {'iter': 3,\n",
       "  'episode': 17,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-53.8599453 , -98.02156734]), array([ 0, 14, 33])),\n",
       "  'action': array([[ -5.1119685 , -33.895058  ],\n",
       "         [-41.719685  , -42.435394  ],\n",
       "         [-23.12282   ,  -0.06605456]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 16.09453011, -21.62506008]), array([44, 16,  0])),\n",
       "  'info': {'type': array([44, 16,  0])}},\n",
       " {'iter': 3,\n",
       "  'episode': 18,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 5.9503736,  3.0837717],\n",
       "         [13.405061 ,  9.378479 ],\n",
       "         [ 2.9180079, 13.603993 ]], dtype=float32),\n",
       "  'reward': 2.108085899204455,\n",
       "  'newState': (array([77.72655869, 73.93375587]), array([45, 45, 30])),\n",
       "  'info': {'type': array([45, 45, 30])}},\n",
       " {'iter': 3,\n",
       "  'episode': 18,\n",
       "  'step': 1,\n",
       "  'oldState': (array([77.72655869, 73.93375587]), array([45, 45, 30])),\n",
       "  'action': array([[14.395424, 38.675667],\n",
       "         [55.836796, 46.535553],\n",
       "         [23.308702, 61.977142]], dtype=float32),\n",
       "  'reward': 3.5516747378856084,\n",
       "  'newState': (array([-15.81436539, -73.25459862]), array([18, 36, 10])),\n",
       "  'info': {'type': array([18, 36, 10])}},\n",
       " {'iter': 3,\n",
       "  'episode': 18,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-15.81436539, -73.25459862]), array([18, 36, 10])),\n",
       "  'action': array([[-14.867068 ,  -0.573968 ],\n",
       "         [ -2.1264894, -13.285049 ],\n",
       "         [-12.508032 ,  -4.890805 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 13.68722343, -54.504776  ]), array([45, 24, 14])),\n",
       "  'info': {'type': array([45, 24, 14])}},\n",
       " {'iter': 3,\n",
       "  'episode': 19,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 1.1149659 ,  3.7331991 ],\n",
       "         [13.652433  ,  0.77083325],\n",
       "         [11.786856  ,  5.071712  ]], dtype=float32),\n",
       "  'reward': 0.05898092033030404,\n",
       "  'newState': (array([73.44574547, 90.42425537]), array([39, 35, 33])),\n",
       "  'info': {'type': array([39, 35, 33])}},\n",
       " {'iter': 3,\n",
       "  'episode': 19,\n",
       "  'step': 1,\n",
       "  'oldState': (array([73.44574547, 90.42425537]), array([39, 35, 33])),\n",
       "  'action': array([[89.3056  , 11.950301],\n",
       "         [59.914234, 79.16734 ],\n",
       "         [36.4365  , 44.150375]], dtype=float32),\n",
       "  'reward': 4.420965629557237,\n",
       "  'newState': (array([-112.21059608,  -44.84376526]), array([42,  0,  5])),\n",
       "  'info': {'type': array([42,  0,  5])}},\n",
       " {'iter': 3,\n",
       "  'episode': 19,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-112.21059608,  -44.84376526]), array([42,  0,  5])),\n",
       "  'action': array([[-12.514882, -23.007496],\n",
       "         [-33.868034, -35.801777],\n",
       "         [-37.3004  ,  -3.766977]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-28.52727699,  17.73248291]), array([26, 12, 49])),\n",
       "  'info': {'type': array([26, 12, 49])}},\n",
       " {'iter': 3,\n",
       "  'episode': 20,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 3.8753018,  9.655554 ],\n",
       "         [ 2.330264 ,  9.771847 ],\n",
       "         [16.947556 ,  5.868142 ]], dtype=float32),\n",
       "  'reward': 1.9962917261211461,\n",
       "  'newState': (array([76.84687805, 74.70445633]), array([42, 20, 46])),\n",
       "  'info': {'type': array([42, 20, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 20,\n",
       "  'step': 1,\n",
       "  'oldState': (array([76.84687805, 74.70445633]), array([42, 20, 46])),\n",
       "  'action': array([[65.73579 , 65.06929 ],\n",
       "         [23.31553 , 66.23714 ],\n",
       "         [47.263237, 27.662825]], dtype=float32),\n",
       "  'reward': 4.242786421365164,\n",
       "  'newState': (array([-59.46766663, -84.26479721]), array([24,  4, 18])),\n",
       "  'info': {'type': array([24,  4, 18])}},\n",
       " {'iter': 3,\n",
       "  'episode': 20,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-59.46766663, -84.26479721]), array([24,  4, 18])),\n",
       "  'action': array([[-31.788073, -34.867607],\n",
       "         [ -7.599171, -57.966084],\n",
       "         [-20.0678  , -58.553127]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-1.26190186e-02,  6.71220284e+01]), array([28, 49, 19])),\n",
       "  'info': {'type': array([28, 49, 19])}},\n",
       " {'iter': 3,\n",
       "  'episode': 21,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[40.355625 , 51.179836 ],\n",
       "         [20.464338 , 30.763483 ],\n",
       "         [ 8.099188 ,  5.0686316]], dtype=float32),\n",
       "  'reward': 3.4733080159147676,\n",
       "  'newState': (array([31.08084869, 12.98804474]), array([15, 17,  7])),\n",
       "  'info': {'type': array([15, 17,  7])}},\n",
       " {'iter': 3,\n",
       "  'episode': 21,\n",
       "  'step': 1,\n",
       "  'oldState': (array([31.08084869, 12.98804474]), array([15, 17,  7])),\n",
       "  'action': array([[23.952145 ,  8.797716 ],\n",
       "         [ 0.4041134, 22.058586 ],\n",
       "         [17.015411 , 23.31699  ]], dtype=float32),\n",
       "  'reward': 3.2336894012393054,\n",
       "  'newState': (array([-10.29082108, -41.18524933]), array([39,  0,  2])),\n",
       "  'info': {'type': array([39,  0,  2])}},\n",
       " {'iter': 3,\n",
       "  'episode': 21,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-10.29082108, -41.18524933]), array([39,  0,  2])),\n",
       "  'action': array([[-6.728635 , -1.366071 ],\n",
       "         [-1.5429262, -0.8563797],\n",
       "         [-9.928463 , -3.280957 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  7.90920258, -35.68184185]), array([26,  4, 16])),\n",
       "  'info': {'type': array([26,  4, 16])}},\n",
       " {'iter': 3,\n",
       "  'episode': 22,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[6.3253736, 1.3400973],\n",
       "         [4.502865 , 7.543132 ],\n",
       "         [4.715175 , 2.049833 ]], dtype=float32),\n",
       "  'reward': 1.950439621446872,\n",
       "  'newState': (array([84.45658684, 89.06693745]), array([13,  4, 30])),\n",
       "  'info': {'type': array([13,  4, 30])}},\n",
       " {'iter': 3,\n",
       "  'episode': 22,\n",
       "  'step': 1,\n",
       "  'oldState': (array([84.45658684, 89.06693745]), array([13,  4, 30])),\n",
       "  'action': array([[ 8.23395 , 39.060776],\n",
       "         [47.841972, 79.57086 ],\n",
       "         [78.017586, 39.85386 ]], dtype=float32),\n",
       "  'reward': 4.000040101439251,\n",
       "  'newState': (array([-49.63691902, -69.4185667 ]), array([20, 36, 34])),\n",
       "  'info': {'type': array([20, 36, 34])}},\n",
       " {'iter': 3,\n",
       "  'episode': 22,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-49.63691902, -69.4185667 ]), array([20, 36, 34])),\n",
       "  'action': array([[-22.656225, -47.08465 ],\n",
       "         [-40.32736 ,  -6.091264],\n",
       "         [-48.905853,  -6.367556]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([62.25251579, -9.87509823]), array([36, 31, 44])),\n",
       "  'info': {'type': array([36, 31, 44])}},\n",
       " {'iter': 3,\n",
       "  'episode': 23,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[28.370977, 37.005974],\n",
       "         [54.395134, 44.46176 ],\n",
       "         [47.022743, 12.090371]], dtype=float32),\n",
       "  'reward': 3.6494034013121044,\n",
       "  'newState': (array([-29.78884888,   6.44189453]), array([35, 32,  5])),\n",
       "  'info': {'type': array([35, 32,  5])}},\n",
       " {'iter': 3,\n",
       "  'episode': 23,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-29.78884888,   6.44189453]), array([35, 32,  5])),\n",
       "  'action': array([[3.304773 , 5.0992637],\n",
       "         [4.516665 , 5.980735 ],\n",
       "         [4.414023 , 3.9843242]], dtype=float32),\n",
       "  'reward': 1.523769975298865,\n",
       "  'newState': (array([-42.02430916,  -8.62242794]), array([33,  0,  9])),\n",
       "  'info': {'type': array([33,  0,  9])}},\n",
       " {'iter': 3,\n",
       "  'episode': 23,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-42.02430916,  -8.62242794]), array([33,  0,  9])),\n",
       "  'action': array([[-1.1655761, -4.304831 ],\n",
       "         [-5.3554835, -5.186669 ],\n",
       "         [-1.6213756, -1.6056299]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-33.88187408,   2.47470188]), array([31, 35, 24])),\n",
       "  'info': {'type': array([31, 35, 24])}},\n",
       " {'iter': 3,\n",
       "  'episode': 24,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[2.1325314 , 1.4287748 ],\n",
       "         [0.63724124, 1.0332376 ],\n",
       "         [0.31426698, 2.3998234 ]], dtype=float32),\n",
       "  'reward': 0.3527836071893478,\n",
       "  'newState': (array([96.91596055, 95.13816452]), array([38, 11, 44])),\n",
       "  'info': {'type': array([38, 11, 44])}},\n",
       " {'iter': 3,\n",
       "  'episode': 24,\n",
       "  'step': 1,\n",
       "  'oldState': (array([96.91596055, 95.13816452]), array([38, 11, 44])),\n",
       "  'action': array([[40.346584, 84.453125],\n",
       "         [36.235367, 23.882248],\n",
       "         [15.621522, 87.8112  ]], dtype=float32),\n",
       "  'reward': 4.080884810267108,\n",
       "  'newState': (array([   4.7124846 , -101.00841141]), array([43,  7, 48])),\n",
       "  'info': {'type': array([43,  7, 48])}},\n",
       " {'iter': 3,\n",
       "  'episode': 24,\n",
       "  'step': 2,\n",
       "  'oldState': (array([   4.7124846 , -101.00841141]), array([43,  7, 48])),\n",
       "  'action': array([[1.4540428 , 3.1452923 ],\n",
       "         [3.87291   , 0.344437  ],\n",
       "         [0.21609315, 4.373454  ]], dtype=float32),\n",
       "  'reward': 0.8344648322797683,\n",
       "  'newState': (array([  -0.8305614 , -108.87159491]), array([32, 29, 40])),\n",
       "  'info': {'type': array([32, 29, 40])}},\n",
       " {'iter': 3,\n",
       "  'episode': 25,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.35698527, -0.2431115 ],\n",
       "         [-0.73909694, -0.39083418],\n",
       "         [-0.5144509 , -0.79096997]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([101.61053312, 101.42491567]), array([24, 43, 10])),\n",
       "  'info': {'type': array([24, 43, 10])}},\n",
       " {'iter': 3,\n",
       "  'episode': 25,\n",
       "  'step': 1,\n",
       "  'oldState': (array([101.61053312, 101.42491567]), array([24, 43, 10])),\n",
       "  'action': array([[28.400223, 85.38469 ],\n",
       "         [14.720259, 53.309456],\n",
       "         [37.632183, 58.82415 ]], dtype=float32),\n",
       "  'reward': 3.8568483360126367,\n",
       "  'newState': (array([ 20.85786283, -96.09339488]), array([30, 49, 18])),\n",
       "  'info': {'type': array([30, 49, 18])}},\n",
       " {'iter': 3,\n",
       "  'episode': 25,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 20.85786283, -96.09339488]), array([30, 49, 18])),\n",
       "  'action': array([[13.264692 ,  7.5386004],\n",
       "         [17.744967 , 11.942094 ],\n",
       "         [18.143486 ,  1.7449678]], dtype=float32),\n",
       "  'reward': 2.607207067079399,\n",
       "  'newState': (array([ -28.29528201, -117.31905711]), array([10, 39,  6])),\n",
       "  'info': {'type': array([10, 39,  6])}},\n",
       " {'iter': 3,\n",
       "  'episode': 26,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -5.5719557,  -4.400784 ],\n",
       "         [-24.496073 , -26.763922 ],\n",
       "         [ -5.2480526, -11.182732 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([135.31607819, 142.347435  ]), array([ 7, 15, 12])),\n",
       "  'info': {'type': array([ 7, 15, 12])}},\n",
       " {'iter': 3,\n",
       "  'episode': 26,\n",
       "  'step': 1,\n",
       "  'oldState': (array([135.31607819, 142.347435  ]), array([ 7, 15, 12])),\n",
       "  'action': array([[133.65959 ,  21.91651 ],\n",
       "         [ 82.026695,  26.985085],\n",
       "         [118.30028 , 128.4074  ]], dtype=float32),\n",
       "  'reward': 4.405729036604079,\n",
       "  'newState': (array([-198.67049408,  -34.96155548]), array([ 0,  3, 15])),\n",
       "  'info': {'type': array([ 0,  3, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 26,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-198.67049408,  -34.96155548]), array([ 0,  3, 15])),\n",
       "  'action': array([[-21.071321 , -25.14407  ],\n",
       "         [-32.11547  , -27.429985 ],\n",
       "         [ -0.5286657, -33.24807  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-144.95503616,   50.86057281]), array([ 3, 17,  2])),\n",
       "  'info': {'type': array([ 3, 17,  2])}},\n",
       " {'iter': 3,\n",
       "  'episode': 27,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 1.7818762, 20.718908 ],\n",
       "         [22.943735 , 35.606384 ],\n",
       "         [ 4.753655 , 31.495947 ]], dtype=float32),\n",
       "  'reward': 2.4911246455328477,\n",
       "  'newState': (array([70.52073479, 12.17875671]), array([15,  0, 19])),\n",
       "  'info': {'type': array([15,  0, 19])}},\n",
       " {'iter': 3,\n",
       "  'episode': 27,\n",
       "  'step': 1,\n",
       "  'oldState': (array([70.52073479, 12.17875671]), array([15,  0, 19])),\n",
       "  'action': array([[65.17066 , 60.703793],\n",
       "         [ 9.788167, 12.409698],\n",
       "         [62.90479 , 60.094425]], dtype=float32),\n",
       "  'reward': 4.531956538877125,\n",
       "  'newState': (array([ -67.34288216, -121.02915955]), array([44, 23, 21])),\n",
       "  'info': {'type': array([44, 23, 21])}},\n",
       " {'iter': 3,\n",
       "  'episode': 27,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -67.34288216, -121.02915955]), array([44, 23, 21])),\n",
       "  'action': array([[-46.214706, -53.56433 ],\n",
       "         [-52.89995 , -38.73    ],\n",
       "         [-12.502485,  -1.825585]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 44.27425957, -26.90924835]), array([ 0, 30, 20])),\n",
       "  'info': {'type': array([ 0, 30, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 28,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[11.795308  ,  0.90270823],\n",
       "         [20.59645   , 20.96295   ],\n",
       "         [24.404306  , 43.042362  ]], dtype=float32),\n",
       "  'reward': 2.9053018908345223,\n",
       "  'newState': (array([43.20393372, 35.09197998]), array([ 1, 45, 20])),\n",
       "  'info': {'type': array([ 1, 45, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 28,\n",
       "  'step': 1,\n",
       "  'oldState': (array([43.20393372, 35.09197998]), array([ 1, 45, 20])),\n",
       "  'action': array([[31.368128 ,  9.6553955],\n",
       "         [20.14881  , 11.018358 ],\n",
       "         [38.64188  , 33.900608 ]], dtype=float32),\n",
       "  'reward': 2.9865085988908375,\n",
       "  'newState': (array([-46.95487976, -19.48238373]), array([42, 12, 22])),\n",
       "  'info': {'type': array([42, 12, 22])}},\n",
       " {'iter': 3,\n",
       "  'episode': 28,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-46.95487976, -19.48238373]), array([42, 12, 22])),\n",
       "  'action': array([[ -6.4055843 ,  -9.4469185 ],\n",
       "         [-13.860226  , -16.841545  ],\n",
       "         [ -0.61333025,  -8.600423  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-26.07573891,  15.40650177]), array([14, 24, 46])),\n",
       "  'info': {'type': array([14, 24, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 29,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[12.306787 , 14.7036915],\n",
       "         [12.995791 ,  5.816657 ],\n",
       "         [12.196107 ,  6.421549 ]], dtype=float32),\n",
       "  'reward': 2.101685683311386,\n",
       "  'newState': (array([62.50131607, 73.05810356]), array([44, 43, 40])),\n",
       "  'info': {'type': array([44, 43, 40])}},\n",
       " {'iter': 3,\n",
       "  'episode': 29,\n",
       "  'step': 1,\n",
       "  'oldState': (array([62.50131607, 73.05810356]), array([44, 43, 40])),\n",
       "  'action': array([[63.304714, 35.048225],\n",
       "         [38.010883, 66.355835],\n",
       "         [35.69589 , 32.54606 ]], dtype=float32),\n",
       "  'reward': 4.1875509586934285,\n",
       "  'newState': (array([-74.5101738 , -60.89201546]), array([32, 16,  6])),\n",
       "  'info': {'type': array([32, 16,  6])}},\n",
       " {'iter': 3,\n",
       "  'episode': 29,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-74.5101738 , -60.89201546]), array([32, 16,  6])),\n",
       "  'action': array([[-36.390507 , -25.642166 ],\n",
       "         [ -3.8955646, -48.972958 ],\n",
       "         [-14.613135 , -24.469204 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-19.61096573,  38.19231987]), array([24, 13, 25])),\n",
       "  'info': {'type': array([24, 13, 25])}},\n",
       " {'iter': 3,\n",
       "  'episode': 30,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[23.6917  , 34.892807],\n",
       "         [ 2.928531, 21.63565 ],\n",
       "         [ 9.478791, 32.24983 ]], dtype=float32),\n",
       "  'reward': 3.146724298232816,\n",
       "  'newState': (array([63.90097809, 11.22171021]), array([35, 31, 39])),\n",
       "  'info': {'type': array([35, 31, 39])}},\n",
       " {'iter': 3,\n",
       "  'episode': 30,\n",
       "  'step': 1,\n",
       "  'oldState': (array([63.90097809, 11.22171021]), array([35, 31, 39])),\n",
       "  'action': array([[56.59202 ,  9.344108],\n",
       "         [ 6.757282, 14.639614],\n",
       "         [46.359432, 51.44626 ]], dtype=float32),\n",
       "  'reward': 3.839879730822587,\n",
       "  'newState': (array([-45.80775452, -64.20826721]), array([14, 49, 29])),\n",
       "  'info': {'type': array([14, 49, 29])}},\n",
       " {'iter': 3,\n",
       "  'episode': 30,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-45.80775452, -64.20826721]), array([14, 49, 29])),\n",
       "  'action': array([[-25.291437 , -38.638348 ],\n",
       "         [ -0.2543043, -20.90373  ],\n",
       "         [-26.081728 , -15.923487 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 5.81971741, 11.2572937 ]), array([48, 46, 13])),\n",
       "  'info': {'type': array([48, 46, 13])}},\n",
       " {'iter': 3,\n",
       "  'episode': 31,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 6.2339873,  3.1908007],\n",
       "         [ 1.3424104, 10.8227625],\n",
       "         [ 5.8897614,  8.071624 ]], dtype=float32),\n",
       "  'reward': 2.1976052491855724,\n",
       "  'newState': (array([86.53384018, 77.914814  ]), array([19, 15, 33])),\n",
       "  'info': {'type': array([19, 15, 33])}},\n",
       " {'iter': 3,\n",
       "  'episode': 31,\n",
       "  'step': 1,\n",
       "  'oldState': (array([86.53384018, 77.914814  ]), array([19, 15, 33])),\n",
       "  'action': array([[25.032042, 55.33581 ],\n",
       "         [53.08223 , 24.128906],\n",
       "         [47.923058, 57.444572]], dtype=float32),\n",
       "  'reward': 3.919853217064318,\n",
       "  'newState': (array([-39.50349045, -58.99448776]), array([41, 35, 25])),\n",
       "  'info': {'type': array([41, 35, 25])}},\n",
       " {'iter': 3,\n",
       "  'episode': 31,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-39.50349045, -58.99448776]), array([41, 35, 25])),\n",
       "  'action': array([[-18.659958, -10.210093],\n",
       "         [-22.536531, -23.6116  ],\n",
       "         [-18.465963, -38.394657]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([20.15896225, 13.22186661]), array([34, 22, 33])),\n",
       "  'info': {'type': array([34, 22, 33])}},\n",
       " {'iter': 3,\n",
       "  'episode': 32,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 9.126005 ,  4.138979 ],\n",
       "         [15.5092945, 17.673506 ],\n",
       "         [ 8.134096 ,  8.15983  ]], dtype=float32),\n",
       "  'reward': 2.628277153053599,\n",
       "  'newState': (array([67.23060608, 70.02768517]), array([35, 14,  7])),\n",
       "  'info': {'type': array([35, 14,  7])}},\n",
       " {'iter': 3,\n",
       "  'episode': 32,\n",
       "  'step': 1,\n",
       "  'oldState': (array([67.23060608, 70.02768517]), array([35, 14,  7])),\n",
       "  'action': array([[69.67423 , 49.006184],\n",
       "         [58.54491 , 69.76871 ],\n",
       "         [47.34028 , 24.293217]], dtype=float32),\n",
       "  'reward': 4.247635842929779,\n",
       "  'newState': (array([-108.32881165,  -73.04041481]), array([32,  3,  3])),\n",
       "  'info': {'type': array([32,  3,  3])}},\n",
       " {'iter': 3,\n",
       "  'episode': 32,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-108.32881165,  -73.04041481]), array([32,  3,  3])),\n",
       "  'action': array([[-10.210367 , -51.23899  ],\n",
       "         [-40.254917 ,  -8.907542 ],\n",
       "         [ -6.2505856, -50.358837 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-51.61293793,  37.46495628]), array([31, 32, 46])),\n",
       "  'info': {'type': array([31, 32, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 33,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[29.088894 ,  1.1661458],\n",
       "         [12.958079 ,  3.9182322],\n",
       "         [14.416784 , 34.34998  ]], dtype=float32),\n",
       "  'reward': 2.2421287528553586,\n",
       "  'newState': (array([43.53623962, 60.56564331]), array([25, 21, 28])),\n",
       "  'info': {'type': array([25, 21, 28])}},\n",
       " {'iter': 3,\n",
       "  'episode': 33,\n",
       "  'step': 1,\n",
       "  'oldState': (array([43.53623962, 60.56564331]), array([25, 21, 28])),\n",
       "  'action': array([[26.742323, 40.267246],\n",
       "         [56.45956 , 21.885439],\n",
       "         [20.14675 ,  4.47119 ]], dtype=float32),\n",
       "  'reward': 3.1980506741280124,\n",
       "  'newState': (array([-59.81239319,  -6.05823517]), array([35, 36, 20])),\n",
       "  'info': {'type': array([35, 36, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 33,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-59.81239319,  -6.05823517]), array([35, 36, 20])),\n",
       "  'action': array([[-4.6571345 , -0.46498424],\n",
       "         [-1.2707483 , -3.9260538 ],\n",
       "         [-4.314308  , -2.950775  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-49.57020187,   1.28357792]), array([ 0, 40, 14])),\n",
       "  'info': {'type': array([ 0, 40, 14])}},\n",
       " {'iter': 3,\n",
       "  'episode': 34,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.8587152 , 0.45643592],\n",
       "         [0.6240156 , 0.03731999],\n",
       "         [0.840578  , 0.03435007]], dtype=float32),\n",
       "  'reward': -1.9647285091315325,\n",
       "  'newState': (array([97.67669106, 99.47189403]), array([14, 40, 47])),\n",
       "  'info': {'type': array([14, 40, 47])}},\n",
       " {'iter': 3,\n",
       "  'episode': 34,\n",
       "  'step': 1,\n",
       "  'oldState': (array([97.67669106, 99.47189403]), array([14, 40, 47])),\n",
       "  'action': array([[54.36433 , 58.649033],\n",
       "         [13.068095, 88.23065 ],\n",
       "         [61.022583, 24.35693 ]], dtype=float32),\n",
       "  'reward': 4.397545374586616,\n",
       "  'newState': (array([-30.77832603, -71.76472402]), array([27,  7, 42])),\n",
       "  'info': {'type': array([27,  7, 42])}},\n",
       " {'iter': 3,\n",
       "  'episode': 34,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-30.77832603, -71.76472402]), array([27,  7, 42])),\n",
       "  'action': array([[-19.685307, -25.650743],\n",
       "         [ -7.153549, -28.878199],\n",
       "         [-23.50464 , -14.523944]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([19.5651722 , -2.71183705]), array([14, 29, 18])),\n",
       "  'info': {'type': array([14, 29, 18])}},\n",
       " {'iter': 3,\n",
       "  'episode': 35,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[10.703533, 18.08823 ],\n",
       "         [ 1.395173, 14.104203],\n",
       "         [12.538705, 17.46403 ]], dtype=float32),\n",
       "  'reward': 2.592221159947367,\n",
       "  'newState': (array([75.36258888, 50.34353638]), array([14, 10, 35])),\n",
       "  'info': {'type': array([14, 10, 35])}},\n",
       " {'iter': 3,\n",
       "  'episode': 35,\n",
       "  'step': 1,\n",
       "  'oldState': (array([75.36258888, 50.34353638]), array([14, 10, 35])),\n",
       "  'action': array([[43.579494 , 49.282204 ],\n",
       "         [34.994087 , 67.19312  ],\n",
       "         [66.526344 ,  6.3570256]], dtype=float32),\n",
       "  'reward': 4.153051532979712,\n",
       "  'newState': (array([-69.73732567, -72.48881531]), array([49, 29, 15])),\n",
       "  'info': {'type': array([49, 29, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 35,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-69.73732567, -72.48881531]), array([49, 29, 15])),\n",
       "  'action': array([[-66.59847  , -32.86667  ],\n",
       "         [-69.104996 , -47.794636 ],\n",
       "         [ -6.3031716, -28.763927 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([72.2693119 , 36.93641663]), array([25,  4,  5])),\n",
       "  'info': {'type': array([25,  4,  5])}},\n",
       " {'iter': 3,\n",
       "  'episode': 36,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[52.313694 ,  2.6658692],\n",
       "         [11.644029 , 26.193388 ],\n",
       "         [58.55512  , 61.047558 ]], dtype=float32),\n",
       "  'reward': 3.607023588431175,\n",
       "  'newState': (array([-22.51284027,  10.09318542]), array([41, 36, 40])),\n",
       "  'info': {'type': array([41, 36, 40])}},\n",
       " {'iter': 3,\n",
       "  'episode': 36,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-22.51284027,  10.09318542]), array([41, 36, 40])),\n",
       "  'action': array([[9.474976 , 7.1758513],\n",
       "         [1.182642 , 7.0765767],\n",
       "         [1.908565 , 6.238652 ]], dtype=float32),\n",
       "  'reward': 2.107233574859083,\n",
       "  'newState': (array([-35.07902336, -10.39789581]), array([22, 29, 16])),\n",
       "  'info': {'type': array([22, 29, 16])}},\n",
       " {'iter': 3,\n",
       "  'episode': 36,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-35.07902336, -10.39789581]), array([22, 29, 16])),\n",
       "  'action': array([[-4.468898 , -9.999428 ],\n",
       "         [-5.6786976, -6.7263474],\n",
       "         [-7.5648828, -4.169743 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-17.36654472,  10.49762154]), array([ 8, 29, 38])),\n",
       "  'info': {'type': array([ 8, 29, 38])}},\n",
       " {'iter': 3,\n",
       "  'episode': 37,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[8.731751 , 7.8188343],\n",
       "         [1.9400808, 1.2082887],\n",
       "         [6.9909716, 1.1167158]], dtype=float32),\n",
       "  'reward': 1.0187335452061719,\n",
       "  'newState': (array([82.33719635, 89.85616207]), array([38, 14, 42])),\n",
       "  'info': {'type': array([38, 14, 42])}},\n",
       " {'iter': 3,\n",
       "  'episode': 37,\n",
       "  'step': 1,\n",
       "  'oldState': (array([82.33719635, 89.85616207]), array([38, 14, 42])),\n",
       "  'action': array([[27.704803, 20.885195],\n",
       "         [40.693676,  9.440434],\n",
       "         [44.340546, 11.683414]], dtype=float32),\n",
       "  'reward': 3.4758913404660503,\n",
       "  'newState': (array([-30.40183258,  47.84711742]), array([36,  0,  4])),\n",
       "  'info': {'type': array([36,  0,  4])}},\n",
       " {'iter': 3,\n",
       "  'episode': 37,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-30.40183258,  47.84711742]), array([36,  0,  4])),\n",
       "  'action': array([[20.264078 ,  6.7896833],\n",
       "         [16.57014  , 29.76103  ],\n",
       "         [ 8.061257 , 18.512451 ]], dtype=float32),\n",
       "  'reward': 3.035957024526669,\n",
       "  'newState': (array([-75.29730988,  -7.21604633]), array([44, 37, 20])),\n",
       "  'info': {'type': array([44, 37, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 38,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-5.942287  , -0.7212537 ],\n",
       "         [-5.2904735 , -0.82326704],\n",
       "         [-1.8887612 , -7.045542  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([113.12152195, 108.59006214]), array([ 9, 16, 35])),\n",
       "  'info': {'type': array([ 9, 16, 35])}},\n",
       " {'iter': 3,\n",
       "  'episode': 38,\n",
       "  'step': 1,\n",
       "  'oldState': (array([113.12152195, 108.59006214]), array([ 9, 16, 35])),\n",
       "  'action': array([[ 85.512054,  86.6639  ],\n",
       "         [111.106735,  90.94867 ],\n",
       "         [ 71.48304 ,  97.421425]], dtype=float32),\n",
       "  'reward': 4.862155076689759,\n",
       "  'newState': (array([-154.98031521, -166.44393444]), array([38,  8, 15])),\n",
       "  'info': {'type': array([38,  8, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 38,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-154.98031521, -166.44393444]), array([38,  8, 15])),\n",
       "  'action': array([[ -24.720263,  -88.200096],\n",
       "         [ -89.68647 , -110.57184 ],\n",
       "         [-148.43428 ,  -86.14875 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([107.86068821, 118.47675037]), array([39,  2, 49])),\n",
       "  'info': {'type': array([39,  2, 49])}},\n",
       " {'iter': 3,\n",
       "  'episode': 39,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[36.65303  , 12.242659 ],\n",
       "         [53.94705  , 57.897785 ],\n",
       "         [82.61106  ,  6.7217555]], dtype=float32),\n",
       "  'reward': 3.9195581462297175,\n",
       "  'newState': (array([-73.21115112,  23.13780212]), array([35, 33, 15])),\n",
       "  'info': {'type': array([35, 33, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 39,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-73.21115112,  23.13780212]), array([35, 33, 15])),\n",
       "  'action': array([[ 1.9632392,  7.62753  ],\n",
       "         [ 8.292559 , 20.170673 ],\n",
       "         [17.050825 ,  0.902271 ]], dtype=float32),\n",
       "  'reward': 2.000805682024713,\n",
       "  'newState': (array([-100.51777458,   -5.56267166]), array([15, 15, 30])),\n",
       "  'info': {'type': array([15, 15, 30])}},\n",
       " {'iter': 3,\n",
       "  'episode': 39,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-100.51777458,   -5.56267166]), array([15, 15, 30])),\n",
       "  'action': array([[-3.3556993 , -3.3428314 ],\n",
       "         [-0.67579573, -3.613344  ],\n",
       "         [-2.0605667 , -1.5192307 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-94.42571259,   2.91273403]), array([ 2, 34, 19])),\n",
       "  'info': {'type': array([ 2, 34, 19])}},\n",
       " {'iter': 3,\n",
       "  'episode': 40,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.3973534 , 1.819207  ],\n",
       "         [0.06987465, 0.84498304],\n",
       "         [0.84515816, 1.2865125 ]], dtype=float32),\n",
       "  'reward': 0.06911894288353551,\n",
       "  'newState': (array([97.68761373, 96.04929733]), array([29, 18, 38])),\n",
       "  'info': {'type': array([29, 18, 38])}},\n",
       " {'iter': 3,\n",
       "  'episode': 40,\n",
       "  'step': 1,\n",
       "  'oldState': (array([97.68761373, 96.04929733]), array([29, 18, 38])),\n",
       "  'action': array([[72.546165, 21.531715],\n",
       "         [32.999744, 30.538477],\n",
       "         [46.00528 , 55.250595]], dtype=float32),\n",
       "  'reward': 4.250058492546018,\n",
       "  'newState': (array([-53.86357951, -11.27148819]), array([10, 18, 25])),\n",
       "  'info': {'type': array([10, 18, 25])}},\n",
       " {'iter': 3,\n",
       "  'episode': 40,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-53.86357951, -11.27148819]), array([10, 18, 25])),\n",
       "  'action': array([[-3.278284 , -6.8212876],\n",
       "         [-7.307531 , -9.09782  ],\n",
       "         [-5.6243954, -8.000482 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-37.65336871,  12.64810181]), array([17, 49, 37])),\n",
       "  'info': {'type': array([17, 49, 37])}},\n",
       " {'iter': 3,\n",
       "  'episode': 41,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[4.583861 , 3.066001 ],\n",
       "         [7.6406417, 4.915698 ],\n",
       "         [9.300631 , 4.6171484]], dtype=float32),\n",
       "  'reward': 1.6298663272377418,\n",
       "  'newState': (array([78.47486687, 87.40115261]), array([20, 40, 46])),\n",
       "  'info': {'type': array([20, 40, 46])}},\n",
       " {'iter': 3,\n",
       "  'episode': 41,\n",
       "  'step': 1,\n",
       "  'oldState': (array([78.47486687, 87.40115261]), array([20, 40, 46])),\n",
       "  'action': array([[64.86411  ,  1.5591174],\n",
       "         [69.22109  , 39.67852  ],\n",
       "         [ 2.7895246, 68.328125 ]], dtype=float32),\n",
       "  'reward': 4.026770987325546,\n",
       "  'newState': (array([-58.39985847, -22.16461277]), array([23, 18, 15])),\n",
       "  'info': {'type': array([23, 18, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 41,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-58.39985847, -22.16461277]), array([23, 18, 15])),\n",
       "  'action': array([[ -1.194862 ,  -6.43391  ],\n",
       "         [-13.309253 , -19.856617 ],\n",
       "         [ -4.2404532,  -5.3745995]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-39.6552906 ,   9.50051403]), array([32, 37, 30])),\n",
       "  'info': {'type': array([32, 37, 30])}},\n",
       " {'iter': 3,\n",
       "  'episode': 42,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[5.4982657, 5.984182 ],\n",
       "         [2.4792957, 0.9234508],\n",
       "         [5.430794 , 9.264769 ]], dtype=float32),\n",
       "  'reward': 0.7319048031786555,\n",
       "  'newState': (array([86.59164429, 83.82759857]), array([40,  9,  4])),\n",
       "  'info': {'type': array([40,  9,  4])}},\n",
       " {'iter': 3,\n",
       "  'episode': 42,\n",
       "  'step': 1,\n",
       "  'oldState': (array([86.59164429, 83.82759857]), array([40,  9,  4])),\n",
       "  'action': array([[69.12525 , 33.08124 ],\n",
       "         [77.28366 , 40.22716 ],\n",
       "         [40.608707, 60.786953]], dtype=float32),\n",
       "  'reward': 4.1729020203039076,\n",
       "  'newState': (array([-100.42596436,  -50.2677536 ]), array([16, 15,  0])),\n",
       "  'info': {'type': array([16, 15,  0])}},\n",
       " {'iter': 3,\n",
       "  'episode': 42,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-100.42596436,  -50.2677536 ]), array([16, 15,  0])),\n",
       "  'action': array([[ -8.106682, -46.29952 ],\n",
       "         [-47.144753,  -8.682723],\n",
       "         [-36.109848,  -2.038061]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-9.06468201,  6.75254822]), array([27, 20, 41])),\n",
       "  'info': {'type': array([27, 20, 41])}},\n",
       " {'iter': 3,\n",
       "  'episode': 43,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.56541  , 2.0181692],\n",
       "         [6.689786 , 2.3961449],\n",
       "         [4.7242107, 4.97472  ]], dtype=float32),\n",
       "  'reward': 1.101732334322452,\n",
       "  'newState': (array([85.02059364, 90.61096573]), array([23,  6, 24])),\n",
       "  'info': {'type': array([23,  6, 24])}},\n",
       " {'iter': 3,\n",
       "  'episode': 43,\n",
       "  'step': 1,\n",
       "  'oldState': (array([85.02059364, 90.61096573]), array([23,  6, 24])),\n",
       "  'action': array([[58.96627 , 44.302734],\n",
       "         [66.29038 , 80.973564],\n",
       "         [ 8.903355, 13.051166]], dtype=float32),\n",
       "  'reward': 3.665477325767169,\n",
       "  'newState': (array([-49.13941002, -47.71650314]), array([ 0, 48, 16])),\n",
       "  'info': {'type': array([ 0, 48, 16])}},\n",
       " {'iter': 3,\n",
       "  'episode': 43,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-49.13941002, -47.71650314]), array([ 0, 48, 16])),\n",
       "  'action': array([[-31.61067 ,  -8.90664 ],\n",
       "         [ -7.52818 , -43.358753],\n",
       "         [-39.930534, -17.086329]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([29.92997169, 21.63521957]), array([28, 24,  1])),\n",
       "  'info': {'type': array([28, 24,  1])}},\n",
       " {'iter': 3,\n",
       "  'episode': 44,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 4.555254 ,  3.8185863],\n",
       "         [23.50614  , 27.214369 ],\n",
       "         [14.587265 ,  2.9226346]], dtype=float32),\n",
       "  'reward': 2.631108861183417,\n",
       "  'newState': (array([57.35134125, 66.04441071]), array([ 9, 21,  0])),\n",
       "  'info': {'type': array([ 9, 21,  0])}},\n",
       " {'iter': 3,\n",
       "  'episode': 44,\n",
       "  'step': 1,\n",
       "  'oldState': (array([57.35134125, 66.04441071]), array([ 9, 21,  0])),\n",
       "  'action': array([[17.490025 , 14.413307 ],\n",
       "         [16.716478 ,  6.1420097],\n",
       "         [29.723566 , 60.203823 ]], dtype=float32),\n",
       "  'reward': 2.129095613008653,\n",
       "  'newState': (array([ -6.57872772, -14.71472931]), array([12, 32, 40])),\n",
       "  'info': {'type': array([12, 32, 40])}},\n",
       " {'iter': 3,\n",
       "  'episode': 44,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -6.57872772, -14.71472931]), array([12, 32, 40])),\n",
       "  'action': array([[-0.5415106 , -2.1777658 ],\n",
       "         [-2.2015977 , -0.09798666],\n",
       "         [-0.612361  , -2.8200905 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-3.2232585 , -9.61888599]), array([17, 19, 30])),\n",
       "  'info': {'type': array([17, 19, 30])}},\n",
       " {'iter': 3,\n",
       "  'episode': 45,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-3.1902637, -1.8483102],\n",
       "         [-1.3919071, -2.5535517],\n",
       "         [-1.5868345, -2.239947 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([106.16900539, 106.64180946]), array([23, 33, 18])),\n",
       "  'info': {'type': array([23, 33, 18])}},\n",
       " {'iter': 3,\n",
       "  'episode': 45,\n",
       "  'step': 1,\n",
       "  'oldState': (array([106.16900539, 106.64180946]), array([23, 33, 18])),\n",
       "  'action': array([[ 28.381523, 103.312836],\n",
       "         [ 29.655954,  65.86981 ],\n",
       "         [ 35.394   ,  13.197321]], dtype=float32),\n",
       "  'reward': 3.851992421504936,\n",
       "  'newState': (array([ 12.73753262, -75.7381649 ]), array([46, 22,  3])),\n",
       "  'info': {'type': array([46, 22,  3])}},\n",
       " {'iter': 3,\n",
       "  'episode': 45,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 12.73753262, -75.7381649 ]), array([46, 22,  3])),\n",
       "  'action': array([[ 2.5767324, 11.256291 ],\n",
       "         [11.986547 ,  4.1173153],\n",
       "         [ 7.858551 ,  5.098746 ]], dtype=float32),\n",
       "  'reward': 1.159991862269087,\n",
       "  'newState': (array([ -9.68429852, -96.21051788]), array([34, 49, 24])),\n",
       "  'info': {'type': array([34, 49, 24])}},\n",
       " {'iter': 3,\n",
       "  'episode': 46,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-9.015324 , -6.6569843],\n",
       "         [-4.909582 , -3.4847028],\n",
       "         [-6.2967334, -8.934816 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([120.22163963, 119.07650375]), array([ 6, 37, 33])),\n",
       "  'info': {'type': array([ 6, 37, 33])}},\n",
       " {'iter': 3,\n",
       "  'episode': 46,\n",
       "  'step': 1,\n",
       "  'oldState': (array([120.22163963, 119.07650375]), array([ 6, 37, 33])),\n",
       "  'action': array([[66.47017 , 24.905672],\n",
       "         [87.55824 , 90.078705],\n",
       "         [54.378464, 27.333248]], dtype=float32),\n",
       "  'reward': 4.43435963174303,\n",
       "  'newState': (array([-88.18523598, -23.2411232 ]), array([12, 37, 15])),\n",
       "  'info': {'type': array([12, 37, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 46,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-88.18523598, -23.2411232 ]), array([12, 37, 15])),\n",
       "  'action': array([[-21.115227 , -18.330742 ],\n",
       "         [-12.632492 , -12.487692 ],\n",
       "         [ -2.7028027, -21.732714 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-51.7347126 ,  29.31002426]), array([ 1,  6, 15])),\n",
       "  'info': {'type': array([ 1,  6, 15])}},\n",
       " {'iter': 3,\n",
       "  'episode': 47,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[15.2158985, 18.540136 ],\n",
       "         [ 1.8662434,  7.2729526],\n",
       "         [ 4.432885 , 26.096508 ]], dtype=float32),\n",
       "  'reward': 2.3373911681613664,\n",
       "  'newState': (array([78.48497391, 48.0904007 ]), array([28,  3, 32])),\n",
       "  'info': {'type': array([28,  3, 32])}},\n",
       " {'iter': 3,\n",
       "  'episode': 47,\n",
       "  'step': 1,\n",
       "  'oldState': (array([78.48497391, 48.0904007 ]), array([28,  3, 32])),\n",
       "  'action': array([[67.15519 , 54.49198 ],\n",
       "         [22.097754, 24.60754 ],\n",
       "         [ 5.058943, 49.23566 ]], dtype=float32),\n",
       "  'reward': 4.051221065709223,\n",
       "  'newState': (array([-15.82691574, -80.24477386]), array([21, 44, 29])),\n",
       "  'info': {'type': array([21, 44, 29])}},\n",
       " {'iter': 3,\n",
       "  'episode': 47,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-15.82691574, -80.24477386]), array([21, 44, 29])),\n",
       "  'action': array([[ -1.4198242,  -2.1482627],\n",
       "         [ -7.2424755, -14.955961 ],\n",
       "         [-15.015451 ,  -9.447774 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  7.8508358 , -53.69277573]), array([46,  3,  2])),\n",
       "  'info': {'type': array([46,  3,  2])}},\n",
       " {'iter': 3,\n",
       "  'episode': 48,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.29244044, 0.23209405],\n",
       "         [3.193279  , 4.95763   ],\n",
       "         [2.7578404 , 1.9086398 ]], dtype=float32),\n",
       "  'reward': 0.5742377618923226,\n",
       "  'newState': (array([93.75644016, 92.90163612]), array([28, 20, 43])),\n",
       "  'info': {'type': array([28, 20, 43])}},\n",
       " {'iter': 3,\n",
       "  'episode': 48,\n",
       "  'step': 1,\n",
       "  'oldState': (array([93.75644016, 92.90163612]), array([28, 20, 43])),\n",
       "  'action': array([[ 3.1470652,  1.8823099],\n",
       "         [18.626984 , 11.776229 ],\n",
       "         [80.56873  , 16.809612 ]], dtype=float32),\n",
       "  'reward': 3.05827247332286,\n",
       "  'newState': (array([-8.5863409 , 62.43348503]), array([30, 29, 20])),\n",
       "  'info': {'type': array([30, 29, 20])}},\n",
       " {'iter': 3,\n",
       "  'episode': 48,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-8.5863409 , 62.43348503]), array([30, 29, 20])),\n",
       "  'action': array([[39.692165, 17.083227],\n",
       "         [30.768442, 16.035658],\n",
       "         [ 0.420262, 34.125813]], dtype=float32),\n",
       "  'reward': 3.3132927108909147,\n",
       "  'newState': (array([-79.46721554,  -4.81121254]), array([31, 25, 41])),\n",
       "  'info': {'type': array([31, 25, 41])}},\n",
       " {'iter': 3,\n",
       "  'episode': 49,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-3.3322105 , -1.4382699 ],\n",
       "         [-2.7930102 , -1.4212673 ],\n",
       "         [-3.4410388 , -0.41620135]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([109.56625938, 103.27573848]), array([46, 17, 22])),\n",
       "  'info': {'type': array([46, 17, 22])}},\n",
       " {'iter': 3,\n",
       "  'episode': 49,\n",
       "  'step': 1,\n",
       "  'oldState': (array([109.56625938, 103.27573848]), array([46, 17, 22])),\n",
       "  'action': array([[ 11.670474,  66.7038  ],\n",
       "         [100.72461 , 106.816315],\n",
       "         [101.71309 ,  87.45026 ]], dtype=float32),\n",
       "  'reward': 3.620837369444728,\n",
       "  'newState': (array([-104.54191017, -157.69462895]), array([13, 30, 23])),\n",
       "  'info': {'type': array([13, 30, 23])}},\n",
       " {'iter': 3,\n",
       "  'episode': 49,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-104.54191017, -157.69462895]), array([13, 30, 23])),\n",
       "  'action': array([[-90.95916 , -33.53098 ],\n",
       "         [-31.139397, -50.863487],\n",
       "         [-37.885563,  -5.777619]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 55.44220543, -67.52254033]), array([36, 21,  7])),\n",
       "  'info': {'type': array([36, 21,  7])}},\n",
       " {'iter': 3,\n",
       "  'episode': 50,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[45.010048 ,  7.1137285],\n",
       "         [29.011288 , 50.846554 ],\n",
       "         [54.78742  ,  2.192163 ]], dtype=float32),\n",
       "  'reward': 3.8916027733089016,\n",
       "  'newState': (array([-28.80874634,  39.84755707]), array([ 3, 23, 12])),\n",
       "  'info': {'type': array([ 3, 23, 12])}},\n",
       " {'iter': 3,\n",
       "  'episode': 50,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-28.80874634,  39.84755707]), array([ 3, 23, 12])),\n",
       "  'action': array([[19.042723 ,  9.169427 ],\n",
       "         [26.569706 ,  1.3829441],\n",
       "         [11.445314 , 13.69553  ]], dtype=float32),\n",
       "  'reward': 1.4471293994475525,\n",
       "  'newState': (array([-85.8664856 ,  15.59965515]), array([49, 13,  7])),\n",
       "  'info': {'type': array([49, 13,  7])}},\n",
       " {'iter': 3,\n",
       "  'episode': 50,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-85.8664856 ,  15.59965515]), array([49, 13,  7])),\n",
       "  'action': array([[15.415855 , 14.962186 ],\n",
       "         [ 8.092171 ,  7.78549  ],\n",
       "         [ 1.0158569, 10.144001 ]], dtype=float32),\n",
       "  'reward': 2.573914439488417,\n",
       "  'newState': (array([-110.39036942,  -17.29202271]), array([41, 30, 26])),\n",
       "  'info': {'type': array([41, 30, 26])}},\n",
       " {'iter': 4,\n",
       "  'episode': 1,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-16.345272, -13.065816],\n",
       "         [-10.887763, -16.00374 ],\n",
       "         [-16.25795 ,  -3.46616 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([143.49098587, 132.53571701]), array([ 8, 39, 32])),\n",
       "  'info': {'type': array([ 8, 39, 32])}},\n",
       " {'iter': 4,\n",
       "  'episode': 1,\n",
       "  'step': 1,\n",
       "  'oldState': (array([143.49098587, 132.53571701]), array([ 8, 39, 32])),\n",
       "  'action': array([[ 83.39031 , 109.943695],\n",
       "         [  4.322264, 140.50299 ],\n",
       "         [ 16.898169, 106.26884 ]], dtype=float32),\n",
       "  'reward': 4.83905693482202,\n",
       "  'newState': (array([  38.88023758, -224.17979813]), array([20, 17,  9])),\n",
       "  'info': {'type': array([20, 17,  9])}},\n",
       " {'iter': 4,\n",
       "  'episode': 1,\n",
       "  'step': 2,\n",
       "  'oldState': (array([  38.88023758, -224.17979813]), array([20, 17,  9])),\n",
       "  'action': array([[28.3212  , 33.605682],\n",
       "         [20.525692, 10.831607],\n",
       "         [25.259012,  5.851005]], dtype=float32),\n",
       "  'reward': 3.006781399468872,\n",
       "  'newState': (array([ -35.22566605, -274.46809387]), array([39, 25,  1])),\n",
       "  'info': {'type': array([39, 25,  1])}},\n",
       " {'iter': 4,\n",
       "  'episode': 2,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-25.832449 , -17.307856 ],\n",
       "         [ -0.3078562, -15.322395 ],\n",
       "         [-21.194025 , -28.833754 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([147.3343277 , 161.46400452]), array([31, 35, 43])),\n",
       "  'info': {'type': array([31, 35, 43])}},\n",
       " {'iter': 4,\n",
       "  'episode': 2,\n",
       "  'step': 1,\n",
       "  'oldState': (array([147.3343277 , 161.46400452]), array([31, 35, 43])),\n",
       "  'action': array([[ 78.604546,  71.47062 ],\n",
       "         [107.13025 ,  28.66546 ],\n",
       "         [ 41.096893, 124.06668 ]], dtype=float32),\n",
       "  'reward': 4.333438814780965,\n",
       "  'newState': (array([-79.49736786, -62.73875427]), array([27, 39, 18])),\n",
       "  'info': {'type': array([27, 39, 18])}},\n",
       " {'iter': 4,\n",
       "  'episode': 2,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-79.49736786, -62.73875427]), array([27, 39, 18])),\n",
       "  'action': array([[-44.317383, -47.03002 ],\n",
       "         [ -8.907291, -43.55246 ],\n",
       "         [-45.851437, -39.445953]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([19.57874298, 67.28968811]), array([22,  1, 34])),\n",
       "  'info': {'type': array([22,  1, 34])}},\n",
       " {'iter': 4,\n",
       "  'episode': 3,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[53.772163, 10.211171],\n",
       "         [15.271579, 46.935383],\n",
       "         [19.564405,  7.828582]], dtype=float32),\n",
       "  'reward': 3.865483860436424,\n",
       "  'newState': (array([11.39185333, 35.0248642 ]), array([ 2, 17, 21])),\n",
       "  'info': {'type': array([ 2, 17, 21])}},\n",
       " {'iter': 4,\n",
       "  'episode': 3,\n",
       "  'step': 1,\n",
       "  'oldState': (array([11.39185333, 35.0248642 ]), array([ 2, 17, 21])),\n",
       "  'action': array([[30.055965, 22.437456],\n",
       "         [18.158964, 27.335194],\n",
       "         [14.612228, 26.070847]], dtype=float32),\n",
       "  'reward': 3.5216788221941466,\n",
       "  'newState': (array([-51.43530273, -40.81863403]), array([11, 29, 18])),\n",
       "  'info': {'type': array([11, 29, 18])}},\n",
       " {'iter': 4,\n",
       "  'episode': 3,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-51.43530273, -40.81863403]), array([11, 29, 18])),\n",
       "  'action': array([[-17.621403 , -10.668811 ],\n",
       "         [-22.654726 , -35.093388 ],\n",
       "         [ -3.4238858, -17.050507 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-7.73528671, 21.99407196]), array([11, 43, 19])),\n",
       "  'info': {'type': array([11, 43, 19])}},\n",
       " {'iter': 4,\n",
       "  'episode': 4,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[10.181821 , 20.991528 ],\n",
       "         [11.391715 ,  4.8609147],\n",
       "         [ 1.1886888, 18.736761 ]], dtype=float32),\n",
       "  'reward': 1.933457628867924,\n",
       "  'newState': (array([77.2377758 , 55.41079712]), array([ 3, 19,  0])),\n",
       "  'info': {'type': array([ 3, 19,  0])}},\n",
       " {'iter': 4,\n",
       "  'episode': 4,\n",
       "  'step': 1,\n",
       "  'oldState': (array([77.2377758 , 55.41079712]), array([ 3, 19,  0])),\n",
       "  'action': array([[55.186764 , 52.32338  ],\n",
       "         [40.823345 , 15.419508 ],\n",
       "         [ 8.6131   ,  4.3843822]], dtype=float32),\n",
       "  'reward': 2.9095093249047532,\n",
       "  'newState': (array([-27.38543129, -16.71647644]), array([29, 21, 27])),\n",
       "  'info': {'type': array([29, 21, 27])}},\n",
       " {'iter': 4,\n",
       "  'episode': 4,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-27.38543129, -16.71647644]), array([29, 21, 27])),\n",
       "  'action': array([[ -9.545338, -12.662184],\n",
       "         [-12.354385, -13.800733],\n",
       "         [ -9.947242,  -7.752017]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 4.4615345 , 17.49845886]), array([49, 32, 22])),\n",
       "  'info': {'type': array([49, 32, 22])}},\n",
       " {'iter': 4,\n",
       "  'episode': 5,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 1.1793855 ,  4.39409   ],\n",
       "         [ 6.3446593 ,  0.23310214],\n",
       "         [17.44873   ,  4.186936  ]], dtype=float32),\n",
       "  'reward': -0.5973475514713608,\n",
       "  'newState': (array([75.02722549, 91.18587112]), array([20, 35, 17])),\n",
       "  'info': {'type': array([20, 35, 17])}},\n",
       " {'iter': 4,\n",
       "  'episode': 5,\n",
       "  'step': 1,\n",
       "  'oldState': (array([75.02722549, 91.18587112]), array([20, 35, 17])),\n",
       "  'action': array([[21.259983 , 36.42063  ],\n",
       "         [ 3.1099935, 77.66776  ],\n",
       "         [86.77385  , 12.1855135]], dtype=float32),\n",
       "  'reward': 4.049749988680186,\n",
       "  'newState': (array([-36.11660385, -35.0880394 ]), array([ 5, 11,  5])),\n",
       "  'info': {'type': array([ 5, 11,  5])}},\n",
       " {'iter': 4,\n",
       "  'episode': 5,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-36.11660385, -35.0880394 ]), array([ 5, 11,  5])),\n",
       "  'action': array([[-32.261196 ,  -4.576177 ],\n",
       "         [ -5.571744 , -30.755186 ],\n",
       "         [ -3.6418986,  -3.0181243]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([5.35823441, 3.26144791]), array([ 9, 46, 10])),\n",
       "  'info': {'type': array([ 9, 46, 10])}},\n",
       " {'iter': 4,\n",
       "  'episode': 6,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[1.0338513, 2.0799432],\n",
       "         [0.6488041, 3.3316934],\n",
       "         [2.2209764, 5.024483 ]], dtype=float32),\n",
       "  'reward': 0.82732140489314,\n",
       "  'newState': (array([96.09636831, 89.56388092]), array([29, 32, 38])),\n",
       "  'info': {'type': array([29, 32, 38])}},\n",
       " {'iter': 4,\n",
       "  'episode': 6,\n",
       "  'step': 1,\n",
       "  'oldState': (array([96.09636831, 89.56388092]), array([29, 32, 38])),\n",
       "  'action': array([[89.288055, 75.8793  ],\n",
       "         [11.87445 ,  8.978756],\n",
       "         [55.20015 , 76.00737 ]], dtype=float32),\n",
       "  'reward': 3.8971451904858743,\n",
       "  'newState': (array([-60.26628733, -71.30155182]), array([42, 23, 40])),\n",
       "  'info': {'type': array([42, 23, 40])}},\n",
       " {'iter': 4,\n",
       "  'episode': 6,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-60.26628733, -71.30155182]), array([42, 23, 40])),\n",
       "  'action': array([[-32.68808 , -55.559742],\n",
       "         [-36.779522, -40.676327],\n",
       "         [-48.740993, -53.788513]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([57.94231558, 78.72303009]), array([31, 18, 40])),\n",
       "  'info': {'type': array([31, 18, 40])}},\n",
       " {'iter': 4,\n",
       "  'episode': 7,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[78.00997 , 26.02998 ],\n",
       "         [64.444115, 60.19487 ],\n",
       "         [25.73274 , 32.40361 ]], dtype=float32),\n",
       "  'reward': 4.189195635947201,\n",
       "  'newState': (array([-68.18682861, -18.62846375]), array([ 5, 48, 28])),\n",
       "  'info': {'type': array([ 5, 48, 28])}},\n",
       " {'iter': 4,\n",
       "  'episode': 7,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-68.18682861, -18.62846375]), array([ 5, 48, 28])),\n",
       "  'action': array([[-17.972864 , -10.221014 ],\n",
       "         [ -6.252687 , -13.13464  ],\n",
       "         [ -2.7650745,  -7.163058 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-41.19620323,  11.89024734]), array([15, 40, 42])),\n",
       "  'info': {'type': array([15, 40, 42])}},\n",
       " {'iter': 4,\n",
       "  'episode': 7,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-41.19620323,  11.89024734]), array([15, 40, 42])),\n",
       "  'action': array([[1.7576736, 6.856837 ],\n",
       "         [1.8989036, 1.7640951],\n",
       "         [1.5481436, 8.528895 ]], dtype=float32),\n",
       "  'reward': 1.3216111200265146,\n",
       "  'newState': (array([-46.40092373,  -5.2595787 ]), array([18, 10, 40])),\n",
       "  'info': {'type': array([18, 10, 40])}},\n",
       " {'iter': 4,\n",
       "  'episode': 8,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.4345248 , -1.2685107 ],\n",
       "         [-0.35071027, -1.1689802 ],\n",
       "         [-2.902817  , -1.5090235 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([105.68805218, 103.94651461]), array([25,  4, 49])),\n",
       "  'info': {'type': array([25,  4, 49])}},\n",
       " {'iter': 4,\n",
       "  'episode': 8,\n",
       "  'step': 1,\n",
       "  'oldState': (array([105.68805218, 103.94651461]), array([25,  4, 49])),\n",
       "  'action': array([[55.588333,  1.41299 ],\n",
       "         [53.621544, 58.840508],\n",
       "         [ 9.586755, 66.05828 ]], dtype=float32),\n",
       "  'reward': 4.214425572933471,\n",
       "  'newState': (array([-13.10857868, -22.36526823]), array([18, 49, 22])),\n",
       "  'info': {'type': array([18, 49, 22])}},\n",
       " {'iter': 4,\n",
       "  'episode': 8,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-13.10857868, -22.36526823]), array([18, 49, 22])),\n",
       "  'action': array([[ -4.086976 ,  -4.2760158],\n",
       "         [ -5.7892685, -12.774635 ],\n",
       "         [ -8.016232 ,  -6.716578 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([4.78389645, 1.40196085]), array([46, 13, 21])),\n",
       "  'info': {'type': array([46, 13, 21])}},\n",
       " {'iter': 4,\n",
       "  'episode': 9,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[2.929005 , 4.52322  ],\n",
       "         [2.6340165, 0.3113978],\n",
       "         [4.778458 , 2.1985269]], dtype=float32),\n",
       "  'reward': -0.16925145537281724,\n",
       "  'newState': (array([89.65851974, 92.96685553]), array([16, 17, 30])),\n",
       "  'info': {'type': array([16, 17, 30])}},\n",
       " {'iter': 4,\n",
       "  'episode': 9,\n",
       "  'step': 1,\n",
       "  'oldState': (array([89.65851974, 92.96685553]), array([16, 17, 30])),\n",
       "  'action': array([[78.089775, 57.536243],\n",
       "         [13.522295, 48.302048],\n",
       "         [57.91006 , 89.58986 ]], dtype=float32),\n",
       "  'reward': 4.531073528072303,\n",
       "  'newState': (array([ -59.8636055 , -102.46129084]), array([48, 49, 14])),\n",
       "  'info': {'type': array([48, 49, 14])}},\n",
       " {'iter': 4,\n",
       "  'episode': 9,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -59.8636055 , -102.46129084]), array([48, 49, 14])),\n",
       "  'action': array([[ -2.059947, -51.806213],\n",
       "         [-18.621254, -50.519455],\n",
       "         [-11.605654, -32.115288]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-27.57674789,  31.97965765]), array([30, 10, 21])),\n",
       "  'info': {'type': array([30, 10, 21])}},\n",
       " {'iter': 4,\n",
       "  'episode': 10,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 8.249717 , 21.481052 ],\n",
       "         [28.729126 , 14.348513 ],\n",
       "         [ 3.6392455,  5.884584 ]], dtype=float32),\n",
       "  'reward': 2.4389081083566175,\n",
       "  'newState': (array([59.38191223, 58.28585052]), array([ 4,  7, 20])),\n",
       "  'info': {'type': array([ 4,  7, 20])}},\n",
       " {'iter': 4,\n",
       "  'episode': 10,\n",
       "  'step': 1,\n",
       "  'oldState': (array([59.38191223, 58.28585052]), array([ 4,  7, 20])),\n",
       "  'action': array([[33.676582 ,  5.9591494],\n",
       "         [20.5727   , 51.787193 ],\n",
       "         [45.480087 , 35.688766 ]], dtype=float32),\n",
       "  'reward': 4.1815433231639565,\n",
       "  'newState': (array([-40.34745789, -35.14925385]), array([34, 41, 35])),\n",
       "  'info': {'type': array([34, 41, 35])}},\n",
       " {'iter': 4,\n",
       "  'episode': 10,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-40.34745789, -35.14925385]), array([34, 41, 35])),\n",
       "  'action': array([[-13.683431,  -9.028631],\n",
       "         [-31.689672, -16.527925],\n",
       "         [-19.164469, -23.93202 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([24.19011688, 14.33932495]), array([13, 11, 45])),\n",
       "  'info': {'type': array([13, 11, 45])}},\n",
       " {'iter': 4,\n",
       "  'episode': 11,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[17.78914  , 23.197142 ],\n",
       "         [12.991263 ,  1.8542852],\n",
       "         [ 6.425274 , 16.656506 ]], dtype=float32),\n",
       "  'reward': 1.586660606682702,\n",
       "  'newState': (array([62.79432297, 58.29206848]), array([ 2, 21, 17])),\n",
       "  'info': {'type': array([ 2, 21, 17])}},\n",
       " {'iter': 4,\n",
       "  'episode': 11,\n",
       "  'step': 1,\n",
       "  'oldState': (array([62.79432297, 58.29206848]), array([ 2, 21, 17])),\n",
       "  'action': array([[23.746113, 59.53449 ],\n",
       "         [58.80066 , 12.539492],\n",
       "         [49.9236  ,  4.915151]], dtype=float32),\n",
       "  'reward': 3.187903269095399,\n",
       "  'newState': (array([-69.67604446, -18.69706726]), array([30, 34, 27])),\n",
       "  'info': {'type': array([30, 34, 27])}},\n",
       " {'iter': 4,\n",
       "  'episode': 11,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-69.67604446, -18.69706726]), array([30, 34, 27])),\n",
       "  'action': array([[ -5.281468 ,  -2.6350923],\n",
       "         [ -5.9736834, -12.298649 ],\n",
       "         [ -6.256424 ,  -3.3566546]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-52.16446877,  -0.40667152]), array([21, 35, 28])),\n",
       "  'info': {'type': array([21, 35, 28])}},\n",
       " {'iter': 4,\n",
       "  'episode': 12,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.17216215, -0.33300486],\n",
       "         [-0.09969946, -0.31098303],\n",
       "         [-0.0173906 , -0.13713278]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([100.28925222, 100.78112066]), array([34, 27, 10])),\n",
       "  'info': {'type': array([34, 27, 10])}},\n",
       " {'iter': 4,\n",
       "  'episode': 12,\n",
       "  'step': 1,\n",
       "  'oldState': (array([100.28925222, 100.78112066]), array([34, 27, 10])),\n",
       "  'action': array([[14.341186 ,  6.4484715],\n",
       "         [33.571136 , 20.677631 ],\n",
       "         [ 3.7598066, 44.256813 ]], dtype=float32),\n",
       "  'reward': 2.9724858713535727,\n",
       "  'newState': (array([48.61712164, 29.39820135]), array([ 8, 11, 17])),\n",
       "  'info': {'type': array([ 8, 11, 17])}},\n",
       " {'iter': 4,\n",
       "  'episode': 12,\n",
       "  'step': 2,\n",
       "  'oldState': (array([48.61712164, 29.39820135]), array([ 8, 11, 17])),\n",
       "  'action': array([[32.505363 , 24.100445 ],\n",
       "         [29.611221 , 47.259563 ],\n",
       "         [ 4.2490225, 28.391108 ]], dtype=float32),\n",
       "  'reward': 3.597713026781989,\n",
       "  'newState': (array([-17.74848658, -70.35291255]), array([27, 25, 22])),\n",
       "  'info': {'type': array([27, 25, 22])}},\n",
       " {'iter': 4,\n",
       "  'episode': 13,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-14.683948 ,  -9.967923 ],\n",
       "         [-14.625974 ,  -2.1146894],\n",
       "         [-15.8398905,  -1.0424669]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([145.14981079, 113.12508011]), array([36, 14,  3])),\n",
       "  'info': {'type': array([36, 14,  3])}},\n",
       " {'iter': 4,\n",
       "  'episode': 13,\n",
       "  'step': 1,\n",
       "  'oldState': (array([145.14981079, 113.12508011]), array([36, 14,  3])),\n",
       "  'action': array([[  7.8988285,  96.23693  ],\n",
       "         [ 22.174288 ,  20.962433 ],\n",
       "         [134.54071  , 132.22433  ]], dtype=float32),\n",
       "  'reward': 2.523756081235596,\n",
       "  'newState': (array([ -19.46401978, -136.29862595]), array([28, 20,  8])),\n",
       "  'info': {'type': array([28, 20,  8])}},\n",
       " {'iter': 4,\n",
       "  'episode': 13,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -19.46401978, -136.29862595]), array([28, 20,  8])),\n",
       "  'action': array([[-18.278357 , -16.616539 ],\n",
       "         [ -6.0050483, -16.4532   ],\n",
       "         [-10.081642 ,  -9.933673 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 14.90102768, -93.29521179]), array([43, 35,  8])),\n",
       "  'info': {'type': array([43, 35,  8])}},\n",
       " {'iter': 4,\n",
       "  'episode': 14,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[4.2041163, 8.600294 ],\n",
       "         [4.5704837, 0.2660977],\n",
       "         [3.0642571, 6.0991583]], dtype=float32),\n",
       "  'reward': -0.11311790378649884,\n",
       "  'newState': (array([88.16114235, 85.03444958]), array([17, 46, 32])),\n",
       "  'info': {'type': array([17, 46, 32])}},\n",
       " {'iter': 4,\n",
       "  'episode': 14,\n",
       "  'step': 1,\n",
       "  'oldState': (array([88.16114235, 85.03444958]), array([17, 46, 32])),\n",
       "  'action': array([[74.5291   ,  5.3549266],\n",
       "         [69.84629  , 64.28069  ],\n",
       "         [ 5.4618077, 32.169163 ]], dtype=float32),\n",
       "  'reward': 4.009375044431667,\n",
       "  'newState': (array([-61.67606163, -16.77032948]), array([34, 19, 27])),\n",
       "  'info': {'type': array([34, 19, 27])}},\n",
       " {'iter': 4,\n",
       "  'episode': 14,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-61.67606163, -16.77032948]), array([34, 19, 27])),\n",
       "  'action': array([[-16.74011  ,  -0.7943488],\n",
       "         [ -3.8806112, -16.63644  ],\n",
       "         [ -3.4426503,  -8.163745 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-37.61268997,   8.82420635]), array([31, 16, 27])),\n",
       "  'info': {'type': array([31, 16, 27])}},\n",
       " {'iter': 4,\n",
       "  'episode': 15,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[4.021319 , 7.490449 ],\n",
       "         [8.453867 , 1.3322828],\n",
       "         [2.950794 , 6.758122 ]], dtype=float32),\n",
       "  'reward': 0.8058364574696624,\n",
       "  'newState': (array([84.57402039, 84.41914558]), array([42, 46, 15])),\n",
       "  'info': {'type': array([42, 46, 15])}},\n",
       " {'iter': 4,\n",
       "  'episode': 15,\n",
       "  'step': 1,\n",
       "  'oldState': (array([84.57402039, 84.41914558]), array([42, 46, 15])),\n",
       "  'action': array([[60.38014 , 76.17342 ],\n",
       "         [28.141066, 51.17955 ],\n",
       "         [17.057314, 51.296722]], dtype=float32),\n",
       "  'reward': 4.04489204104683,\n",
       "  'newState': (array([-21.00449371, -94.23054314]), array([26, 37, 24])),\n",
       "  'info': {'type': array([26, 37, 24])}},\n",
       " {'iter': 4,\n",
       "  'episode': 15,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-21.00449371, -94.23054314]), array([26, 37, 24])),\n",
       "  'action': array([[ -0.22460079, -20.873924  ],\n",
       "         [ -8.997307  , -16.919733  ],\n",
       "         [-17.524712  , -16.577425  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  5.74212646, -39.85946465]), array([40, 38, 19])),\n",
       "  'info': {'type': array([40, 38, 19])}},\n",
       " {'iter': 4,\n",
       "  'episode': 16,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.21474133, 3.9329338 ],\n",
       "         [2.0598752 , 4.7874866 ],\n",
       "         [5.199211  , 2.263914  ]], dtype=float32),\n",
       "  'reward': 0.4707048836922762,\n",
       "  'newState': (array([92.52617264, 89.01566505]), array([44, 20, 21])),\n",
       "  'info': {'type': array([44, 20, 21])}},\n",
       " {'iter': 4,\n",
       "  'episode': 16,\n",
       "  'step': 1,\n",
       "  'oldState': (array([92.52617264, 89.01566505]), array([44, 20, 21])),\n",
       "  'action': array([[ 6.2495084, 45.792694 ],\n",
       "         [85.79173  , 49.586624 ],\n",
       "         [24.861809 ,  1.9592667]], dtype=float32),\n",
       "  'reward': 2.679735214264949,\n",
       "  'newState': (array([-24.37688065,  -8.32291985]), array([ 1,  4, 28])),\n",
       "  'info': {'type': array([ 1,  4, 28])}},\n",
       " {'iter': 4,\n",
       "  'episode': 16,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-24.37688065,  -8.32291985]), array([ 1,  4, 28])),\n",
       "  'action': array([[-4.0303464 , -6.00894   ],\n",
       "         [-1.1086082 , -3.2429466 ],\n",
       "         [-0.21469697, -2.214144  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-19.02322912,   3.14311028]), array([18,  4, 16])),\n",
       "  'info': {'type': array([18,  4, 16])}},\n",
       " {'iter': 4,\n",
       "  'episode': 17,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.7053736 , 2.6624968 ],\n",
       "         [0.05572723, 2.8886058 ],\n",
       "         [2.2488549 , 1.8758886 ]], dtype=float32),\n",
       "  'reward': 0.5726667311141128,\n",
       "  'newState': (array([96.99004436, 92.57300854]), array([14, 44, 35])),\n",
       "  'info': {'type': array([14, 44, 35])}},\n",
       " {'iter': 4,\n",
       "  'episode': 17,\n",
       "  'step': 1,\n",
       "  'oldState': (array([96.99004436, 92.57300854]), array([14, 44, 35])),\n",
       "  'action': array([[ 4.789018, 96.3311  ],\n",
       "         [92.18625 , 62.46906 ],\n",
       "         [93.76568 , 45.381824]], dtype=float32),\n",
       "  'reward': 4.049438767605812,\n",
       "  'newState': (array([ -93.75089192, -111.60896778]), array([39, 46, 32])),\n",
       "  'info': {'type': array([39, 46, 32])}},\n",
       " {'iter': 4,\n",
       "  'episode': 17,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -93.75089192, -111.60896778]), array([39, 46, 32])),\n",
       "  'action': array([[ -3.8879006, -93.435905 ],\n",
       "         [-73.467514 , -69.18343  ],\n",
       "         [-50.82662  , -64.277306 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 34.43114543, 115.28766918]), array([ 3, 11,  8])),\n",
       "  'info': {'type': array([ 3, 11,  8])}},\n",
       " {'iter': 4,\n",
       "  'episode': 18,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[33.185577, 47.064365],\n",
       "         [30.461308, 11.278499],\n",
       "         [92.35185 , 15.57027 ]], dtype=float32),\n",
       "  'reward': 2.9490315783459957,\n",
       "  'newState': (array([-55.99873352,  26.08686829]), array([34, 33, 46])),\n",
       "  'info': {'type': array([34, 33, 46])}},\n",
       " {'iter': 4,\n",
       "  'episode': 18,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-55.99873352,  26.08686829]), array([34, 33, 46])),\n",
       "  'action': array([[23.49456  , 10.997877 ],\n",
       "         [ 8.895052 , 22.463793 ],\n",
       "         [ 4.2649174,  9.570048 ]], dtype=float32),\n",
       "  'reward': 2.928089927806609,\n",
       "  'newState': (array([-92.65325928, -16.94485092]), array([28, 25,  3])),\n",
       "  'info': {'type': array([28, 25,  3])}},\n",
       " {'iter': 4,\n",
       "  'episode': 18,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-92.65325928, -16.94485092]), array([28, 25,  3])),\n",
       "  'action': array([[ -1.080892 ,  -1.1257232],\n",
       "         [ -7.648138 ,  -7.4807916],\n",
       "         [-13.897174 ,  -7.4303546]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-70.02705574,  -0.90798187]), array([ 1, 34,  8])),\n",
       "  'info': {'type': array([ 1, 34,  8])}},\n",
       " {'iter': 4,\n",
       "  'episode': 19,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.5506804 , -0.57744944],\n",
       "         [-0.5913681 , -0.6484529 ],\n",
       "         [-0.3259465 , -0.52390665]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([101.46799493, 101.74980903]), array([47, 25, 27])),\n",
       "  'info': {'type': array([47, 25, 27])}},\n",
       " {'iter': 4,\n",
       "  'episode': 19,\n",
       "  'step': 1,\n",
       "  'oldState': (array([101.46799493, 101.74980903]), array([47, 25, 27])),\n",
       "  'action': array([[51.0094  , 33.71607 ],\n",
       "         [30.618824, 43.275772],\n",
       "         [62.68246 , 99.304634]], dtype=float32),\n",
       "  'reward': 4.20562868504477,\n",
       "  'newState': (array([-42.84268928, -74.54666924]), array([29, 25, 13])),\n",
       "  'info': {'type': array([29, 25, 13])}},\n",
       " {'iter': 4,\n",
       "  'episode': 19,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-42.84268928, -74.54666924]), array([29, 25, 13])),\n",
       "  'action': array([[-15.337625, -14.712837],\n",
       "         [-28.343512, -27.322266],\n",
       "         [-24.676569, -31.616684]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([25.51501489, -0.89488244]), array([10, 16, 15])),\n",
       "  'info': {'type': array([10, 16, 15])}},\n",
       " {'iter': 4,\n",
       "  'episode': 20,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[25.217226, 12.545363],\n",
       "         [ 5.280021, 15.909567],\n",
       "         [25.210136, 18.341242]], dtype=float32),\n",
       "  'reward': 2.9940688730190175,\n",
       "  'newState': (array([44.2926178, 53.2038269]), array([10, 12, 33])),\n",
       "  'info': {'type': array([10, 12, 33])}},\n",
       " {'iter': 4,\n",
       "  'episode': 20,\n",
       "  'step': 1,\n",
       "  'oldState': (array([44.2926178, 53.2038269]), array([10, 12, 33])),\n",
       "  'action': array([[16.382494 , 52.38329  ],\n",
       "         [14.98655  ,  1.1228687],\n",
       "         [40.429016 , 18.630796 ]], dtype=float32),\n",
       "  'reward': 2.9808172174336653,\n",
       "  'newState': (array([-27.50544739, -18.93312836]), array([ 0, 30,  3])),\n",
       "  'info': {'type': array([ 0, 30,  3])}},\n",
       " {'iter': 4,\n",
       "  'episode': 20,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-27.50544739, -18.93312836]), array([ 0, 30,  3])),\n",
       "  'action': array([[ -4.9248323,  -1.0204053],\n",
       "         [ -3.8433363,  -5.4196544],\n",
       "         [-18.532755 , -11.59083  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-0.20452499, -0.90223885]), array([17,  0, 38])),\n",
       "  'info': {'type': array([17,  0, 38])}},\n",
       " {'iter': 4,\n",
       "  'episode': 21,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-0.19198494, -0.03407536],\n",
       "         [-0.1159426 , -0.11568987],\n",
       "         [-0.1703554 , -0.05879734]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([100.47828293, 100.20856257]), array([ 3, 30, 21])),\n",
       "  'info': {'type': array([ 3, 30, 21])}},\n",
       " {'iter': 4,\n",
       "  'episode': 21,\n",
       "  'step': 1,\n",
       "  'oldState': (array([100.47828293, 100.20856257]), array([ 3, 30, 21])),\n",
       "  'action': array([[45.793255, 77.20156 ],\n",
       "         [25.003263, 45.241608],\n",
       "         [53.22875 , 59.548153]], dtype=float32),\n",
       "  'reward': 4.1678994149779784,\n",
       "  'newState': (array([-23.54698563, -81.78275518]), array([26, 31, 10])),\n",
       "  'info': {'type': array([26, 31, 10])}},\n",
       " {'iter': 4,\n",
       "  'episode': 21,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-23.54698563, -81.78275518]), array([26, 31, 10])),\n",
       "  'action': array([[-12.516996 , -22.959087 ],\n",
       "         [-18.882757 ,  -6.714707 ],\n",
       "         [-11.9695215, -22.99377  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 19.82228851, -29.11519079]), array([ 5, 33, 36])),\n",
       "  'info': {'type': array([ 5, 33, 36])}},\n",
       " {'iter': 4,\n",
       "  'episode': 22,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[15.390222 , 18.000277 ],\n",
       "         [ 4.0009785,  0.6747175],\n",
       "         [15.759687 ,  9.321424 ]], dtype=float32),\n",
       "  'reward': 0.9546555075076908,\n",
       "  'newState': (array([64.84911346, 72.003582  ]), array([ 9, 46,  0])),\n",
       "  'info': {'type': array([ 9, 46,  0])}},\n",
       " {'iter': 4,\n",
       "  'episode': 22,\n",
       "  'step': 1,\n",
       "  'oldState': (array([64.84911346, 72.003582  ]), array([ 9, 46,  0])),\n",
       "  'action': array([[64.104294, 19.997808],\n",
       "         [ 5.291065, 66.771454],\n",
       "         [37.841732, 58.25376 ]], dtype=float32),\n",
       "  'reward': 4.19460512931416,\n",
       "  'newState': (array([-42.3879776 , -73.01944351]), array([39, 43, 45])),\n",
       "  'info': {'type': array([39, 43, 45])}},\n",
       " {'iter': 4,\n",
       "  'episode': 22,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-42.3879776 , -73.01944351]), array([39, 43, 45])),\n",
       "  'action': array([[-39.319294, -23.029808],\n",
       "         [-32.477196, -17.46277 ],\n",
       "         [-33.11656 , -32.0392  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([62.52507782, -0.48766708]), array([ 5, 10,  3])),\n",
       "  'info': {'type': array([ 5, 10,  3])}},\n",
       " {'iter': 4,\n",
       "  'episode': 23,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[37.56018 , 45.08185 ],\n",
       "         [39.07976 , 45.53661 ],\n",
       "         [54.32845 , 34.137703]], dtype=float32),\n",
       "  'reward': 3.788918449453149,\n",
       "  'newState': (array([-30.96838379, -24.75615692]), array([39, 13, 37])),\n",
       "  'info': {'type': array([39, 13, 37])}},\n",
       " {'iter': 4,\n",
       "  'episode': 23,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-30.96838379, -24.75615692]), array([39, 13, 37])),\n",
       "  'action': array([[ -9.607361 , -19.853836 ],\n",
       "         [ -4.7561426,  -5.8571672],\n",
       "         [ -3.9966235,  -6.866534 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-12.60825729,   7.82138062]), array([16, 25, 43])),\n",
       "  'info': {'type': array([16, 25, 43])}},\n",
       " {'iter': 4,\n",
       "  'episode': 23,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-12.60825729,   7.82138062]), array([16, 25, 43])),\n",
       "  'action': array([[0.078943 , 5.7393317],\n",
       "         [3.1582077, 3.7666426],\n",
       "         [2.322457 , 5.586758 ]], dtype=float32),\n",
       "  'reward': 0.9697066871538803,\n",
       "  'newState': (array([-18.1678648 ,  -7.27135086]), array([46,  7, 43])),\n",
       "  'info': {'type': array([46,  7, 43])}},\n",
       " {'iter': 4,\n",
       "  'episode': 24,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-5.686303 , -7.187246 ],\n",
       "         [-5.2044683, -4.0563884],\n",
       "         [-2.6483014, -4.1176357]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([113.53907299, 115.36126995]), array([ 0, 14, 14])),\n",
       "  'info': {'type': array([ 0, 14, 14])}},\n",
       " {'iter': 4,\n",
       "  'episode': 24,\n",
       "  'step': 1,\n",
       "  'oldState': (array([113.53907299, 115.36126995]), array([ 0, 14, 14])),\n",
       "  'action': array([[ 92.33257 ,  31.410215],\n",
       "         [ 89.95007 ,   9.732542],\n",
       "         [110.08657 , 114.195244]], dtype=float32),\n",
       "  'reward': 3.844189240861685,\n",
       "  'newState': (array([-178.83015919,  -39.97672749]), array([33, 46,  0])),\n",
       "  'info': {'type': array([33, 46,  0])}},\n",
       " {'iter': 4,\n",
       "  'episode': 24,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-178.83015919,  -39.97672749]), array([33, 46,  0])),\n",
       "  'action': array([[-30.312653, -21.722847],\n",
       "         [-24.498585, -38.90373 ],\n",
       "         [-22.403044, -38.164   ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-101.61588001,   58.81384563]), array([14,  2, 35])),\n",
       "  'info': {'type': array([14,  2, 35])}},\n",
       " {'iter': 4,\n",
       "  'episode': 25,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[44.08175  ,  1.8983463],\n",
       "         [34.16871  , 53.06472  ],\n",
       "         [11.913719 , 27.957067 ]], dtype=float32),\n",
       "  'reward': 3.887255244124149,\n",
       "  'newState': (array([ 9.83582306, 17.0798645 ]), array([31, 39,  7])),\n",
       "  'info': {'type': array([31, 39,  7])}},\n",
       " {'iter': 4,\n",
       "  'episode': 25,\n",
       "  'step': 1,\n",
       "  'oldState': (array([ 9.83582306, 17.0798645 ]), array([31, 39,  7])),\n",
       "  'action': array([[15.791267,  9.470899],\n",
       "         [ 9.499657, 12.656062],\n",
       "         [11.959551,  4.471247]], dtype=float32),\n",
       "  'reward': 2.650968685884494,\n",
       "  'newState': (array([-27.41464996,  -9.51834297]), array([ 7, 16,  2])),\n",
       "  'info': {'type': array([ 7, 16,  2])}},\n",
       " {'iter': 4,\n",
       "  'episode': 25,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-27.41464996,  -9.51834297]), array([ 7, 16,  2])),\n",
       "  'action': array([[-2.2029498, -9.283977 ],\n",
       "         [-9.163758 , -7.0014615],\n",
       "         [-2.7354016, -9.471546 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-13.31254005,  16.23864174]), array([ 5, 38, 15])),\n",
       "  'info': {'type': array([ 5, 38, 15])}},\n",
       " {'iter': 4,\n",
       "  'episode': 26,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 0.50314957,  0.9359318 ],\n",
       "         [16.055826  , 10.020631  ],\n",
       "         [ 4.1926823 ,  2.6152754 ]], dtype=float32),\n",
       "  'reward': 1.2000896065787616,\n",
       "  'newState': (array([79.24834251, 86.42816162]), array([14, 40, 13])),\n",
       "  'info': {'type': array([14, 40, 13])}},\n",
       " {'iter': 4,\n",
       "  'episode': 26,\n",
       "  'step': 1,\n",
       "  'oldState': (array([79.24834251, 86.42816162]), array([14, 40, 13])),\n",
       "  'action': array([[50.731094, 53.931866],\n",
       "         [39.245106, 60.997166],\n",
       "         [79.74639 , 43.008408]], dtype=float32),\n",
       "  'reward': 4.208016380195303,\n",
       "  'newState': (array([-90.4742527 , -71.50927734]), array([12, 37, 11])),\n",
       "  'info': {'type': array([12, 37, 11])}},\n",
       " {'iter': 4,\n",
       "  'episode': 26,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-90.4742527 , -71.50927734]), array([12, 37, 11])),\n",
       "  'action': array([[-23.308197, -23.032042],\n",
       "         [-28.984966,  -7.211883],\n",
       "         [ -5.574678, -28.650229]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-32.60641289, -12.61512375]), array([15, 31, 46])),\n",
       "  'info': {'type': array([15, 31, 46])}},\n",
       " {'iter': 4,\n",
       "  'episode': 27,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-9.806862 , -4.298515 ],\n",
       "         [-2.5577865, -1.0523145],\n",
       "         [-6.399523 , -1.4879453]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([118.7641716 , 106.83877468]), array([49, 34,  6])),\n",
       "  'info': {'type': array([49, 34,  6])}},\n",
       " {'iter': 4,\n",
       "  'episode': 27,\n",
       "  'step': 1,\n",
       "  'oldState': (array([118.7641716 , 106.83877468]), array([49, 34,  6])),\n",
       "  'action': array([[  8.30012 ,  93.11064 ],\n",
       "         [ 25.295073,  10.949129],\n",
       "         [117.870705,  50.54798 ]], dtype=float32),\n",
       "  'reward': 2.42502007123738,\n",
       "  'newState': (array([-32.70172501, -47.76898289]), array([42,  5, 21])),\n",
       "  'info': {'type': array([42,  5, 21])}},\n",
       " {'iter': 4,\n",
       "  'episode': 27,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-32.70172501, -47.76898289]), array([42,  5, 21])),\n",
       "  'action': array([[-24.154335 , -28.37991  ],\n",
       "         [-18.558372 ,  -0.5559088],\n",
       "         [-14.727058 , -29.367287 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([24.73804092, 10.53412151]), array([43, 44,  6])),\n",
       "  'info': {'type': array([43, 44,  6])}},\n",
       " {'iter': 4,\n",
       "  'episode': 28,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[11.076921 , 19.412012 ],\n",
       "         [ 2.3034422, 12.165934 ],\n",
       "         [ 5.8069944, 11.271239 ]], dtype=float32),\n",
       "  'reward': 2.4851764367256624,\n",
       "  'newState': (array([80.81264114, 57.15081406]), array([ 8, 12, 46])),\n",
       "  'info': {'type': array([ 8, 12, 46])}},\n",
       " {'iter': 4,\n",
       "  'episode': 28,\n",
       "  'step': 1,\n",
       "  'oldState': (array([80.81264114, 57.15081406]), array([ 8, 12, 46])),\n",
       "  'action': array([[23.65646 , 52.29648 ],\n",
       "         [14.365017, 12.182879],\n",
       "         [23.891483, 26.120125]], dtype=float32),\n",
       "  'reward': 3.5647455446643392,\n",
       "  'newState': (array([ 18.89968109, -33.44866562]), array([46, 18,  7])),\n",
       "  'info': {'type': array([46, 18,  7])}},\n",
       " {'iter': 4,\n",
       "  'episode': 28,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 18.89968109, -33.44866562]), array([46, 18,  7])),\n",
       "  'action': array([[16.430124 ,  4.8192506],\n",
       "         [16.197914 , 13.254365 ],\n",
       "         [10.981388 , 16.408718 ]], dtype=float32),\n",
       "  'reward': 2.795049529483459,\n",
       "  'newState': (array([-24.7097435 , -67.93099976]), array([29, 18,  9])),\n",
       "  'info': {'type': array([29, 18,  9])}},\n",
       " {'iter': 4,\n",
       "  'episode': 29,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-15.742189 , -23.53973  ],\n",
       "         [-19.966463 ,  -1.3013601],\n",
       "         [ -5.5685534,  -5.612965 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([141.27720642, 130.45405579]), array([46, 22, 20])),\n",
       "  'info': {'type': array([46, 22, 20])}},\n",
       " {'iter': 4,\n",
       "  'episode': 29,\n",
       "  'step': 1,\n",
       "  'oldState': (array([141.27720642, 130.45405579]), array([46, 22, 20])),\n",
       "  'action': array([[ 51.321285 ,  24.681372 ],\n",
       "         [100.917564 , 103.2049   ],\n",
       "         [  7.8763194,  31.332777 ]], dtype=float32),\n",
       "  'reward': 4.051577183448076,\n",
       "  'newState': (array([-18.83795166, -28.76499939]), array([33, 47, 24])),\n",
       "  'info': {'type': array([33, 47, 24])}},\n",
       " {'iter': 4,\n",
       "  'episode': 29,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-18.83795166, -28.76499939]), array([33, 47, 24])),\n",
       "  'action': array([[ -4.5197654,  -8.848557 ],\n",
       "         [-17.141926 ,  -9.776828 ],\n",
       "         [ -2.9407053, -15.785968 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([5.76444626, 5.64635468]), array([ 9, 12, 23])),\n",
       "  'info': {'type': array([ 9, 12, 23])}},\n",
       " {'iter': 4,\n",
       "  'episode': 30,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.4076746, 5.1069226],\n",
       "         [4.9873123, 4.292012 ],\n",
       "         [4.4951   , 2.2577574]], dtype=float32),\n",
       "  'reward': 1.4006627007299133,\n",
       "  'newState': (array([87.10991287, 88.3433075 ]), array([45, 36, 23])),\n",
       "  'info': {'type': array([45, 36, 23])}},\n",
       " {'iter': 4,\n",
       "  'episode': 30,\n",
       "  'step': 1,\n",
       "  'oldState': (array([87.10991287, 88.3433075 ]), array([45, 36, 23])),\n",
       "  'action': array([[26.484087, 13.299496],\n",
       "         [81.34688 , 77.50806 ],\n",
       "         [34.548424, 75.23649 ]], dtype=float32),\n",
       "  'reward': 3.962733290333575,\n",
       "  'newState': (array([-55.26948166, -77.70072937]), array([39, 37,  6])),\n",
       "  'info': {'type': array([39, 37,  6])}},\n",
       " {'iter': 4,\n",
       "  'episode': 30,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-55.26948166, -77.70072937]), array([39, 37,  6])),\n",
       "  'action': array([[-33.32096  , -31.834106 ],\n",
       "         [-26.296528 , -35.288433 ],\n",
       "         [-13.9919615, -29.47003  ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([18.33996964, 18.8918457 ]), array([43,  1, 19])),\n",
       "  'info': {'type': array([43,  1, 19])}},\n",
       " {'iter': 4,\n",
       "  'episode': 31,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 5.0813074 , 15.924803  ],\n",
       "         [ 2.4728286 ,  0.68977726],\n",
       "         [11.640779  , 12.254424  ]], dtype=float32),\n",
       "  'reward': 0.5639625522815065,\n",
       "  'newState': (array([80.80508423, 71.1309967 ]), array([29, 48, 45])),\n",
       "  'info': {'type': array([29, 48, 45])}},\n",
       " {'iter': 4,\n",
       "  'episode': 31,\n",
       "  'step': 1,\n",
       "  'oldState': (array([80.80508423, 71.1309967 ]), array([29, 48, 45])),\n",
       "  'action': array([[ 0.350212 ,  8.840054 ],\n",
       "         [62.73681  , 77.658585 ],\n",
       "         [25.84803  ,  6.2826347]], dtype=float32),\n",
       "  'reward': 2.742833352987819,\n",
       "  'newState': (array([ -8.12996674, -21.65028381]), array([ 8, 34, 29])),\n",
       "  'info': {'type': array([ 8, 34, 29])}},\n",
       " {'iter': 4,\n",
       "  'episode': 31,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -8.12996674, -21.65028381]), array([ 8, 34, 29])),\n",
       "  'action': array([[-5.87652  , -2.3720858],\n",
       "         [-6.253312 , -1.8921691],\n",
       "         [-4.519389 , -5.0102053]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  8.51925468, -12.37582397]), array([ 0, 15, 19])),\n",
       "  'info': {'type': array([ 0, 15, 19])}},\n",
       " {'iter': 4,\n",
       "  'episode': 32,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[3.5741603, 4.0682974],\n",
       "         [6.34255  , 6.6375093],\n",
       "         [7.588817 , 1.8726718]], dtype=float32),\n",
       "  'reward': 1.690354497722007,\n",
       "  'newState': (array([82.4944725 , 87.42152119]), array([4, 7, 1])),\n",
       "  'info': {'type': array([4, 7, 1])}},\n",
       " {'iter': 4,\n",
       "  'episode': 32,\n",
       "  'step': 1,\n",
       "  'oldState': (array([82.4944725 , 87.42152119]), array([4, 7, 1])),\n",
       "  'action': array([[10.770302, 30.609472],\n",
       "         [70.33999 , 60.312614],\n",
       "         [82.25453 , 16.885986]], dtype=float32),\n",
       "  'reward': 3.5667081012164337,\n",
       "  'newState': (array([-80.87034988, -20.38655376]), array([ 8, 26, 40])),\n",
       "  'info': {'type': array([ 8, 26, 40])}},\n",
       " {'iter': 4,\n",
       "  'episode': 32,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-80.87034988, -20.38655376]), array([ 8, 26, 40])),\n",
       "  'action': array([[-18.641743 ,  -7.3127894],\n",
       "         [ -5.463392 ,  -9.914873 ],\n",
       "         [ -2.5309725,  -8.998244 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-54.23424149,   5.83935261]), array([25, 32,  6])),\n",
       "  'info': {'type': array([25, 32,  6])}},\n",
       " {'iter': 4,\n",
       "  'episode': 33,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.81655604, 1.2431786 ],\n",
       "         [3.4527845 , 0.08514385],\n",
       "         [5.605894  , 2.1973267 ]], dtype=float32),\n",
       "  'reward': -1.3741076934833265,\n",
       "  'newState': (array([90.1247654 , 96.47435093]), array([32,  7, 38])),\n",
       "  'info': {'type': array([32,  7, 38])}},\n",
       " {'iter': 4,\n",
       "  'episode': 33,\n",
       "  'step': 1,\n",
       "  'oldState': (array([90.1247654 , 96.47435093]), array([32,  7, 38])),\n",
       "  'action': array([[79.42136 , 49.341724],\n",
       "         [49.990513, 20.906752],\n",
       "         [63.88439 , 73.68443 ]], dtype=float32),\n",
       "  'reward': 4.524542642525864,\n",
       "  'newState': (array([-103.17149925,  -47.45855618]), array([17, 29, 38])),\n",
       "  'info': {'type': array([17, 29, 38])}},\n",
       " {'iter': 4,\n",
       "  'episode': 33,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-103.17149925,  -47.45855618]), array([17, 29, 38])),\n",
       "  'action': array([[ -1.5070701,  -1.5237355],\n",
       "         [-25.045454 , -31.84617  ],\n",
       "         [ -9.938064 , -11.874272 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-66.68091011,  -2.2143774 ]), array([ 3, 10, 27])),\n",
       "  'info': {'type': array([ 3, 10, 27])}},\n",
       " {'iter': 4,\n",
       "  'episode': 34,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.2640654, -2.0157418],\n",
       "         [-1.7083743, -1.7427881],\n",
       "         [-2.2005482, -1.9754912]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([105.17298794, 105.73402119]), array([16, 49, 43])),\n",
       "  'info': {'type': array([16, 49, 43])}},\n",
       " {'iter': 4,\n",
       "  'episode': 34,\n",
       "  'step': 1,\n",
       "  'oldState': (array([105.17298794, 105.73402119]), array([16, 49, 43])),\n",
       "  'action': array([[19.832415,  8.082923],\n",
       "         [83.506226, 65.428795],\n",
       "         [39.774246, 19.777428]], dtype=float32),\n",
       "  'reward': 3.9666532653689077,\n",
       "  'newState': (array([-37.93989658,  12.44487476]), array([46, 42,  6])),\n",
       "  'info': {'type': array([46, 42,  6])}},\n",
       " {'iter': 4,\n",
       "  'episode': 34,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-37.93989658,  12.44487476]), array([46, 42,  6])),\n",
       "  'action': array([[ 5.1704197, 11.416763 ],\n",
       "         [ 5.1347094,  8.427154 ],\n",
       "         [ 2.1911814,  9.534438 ]], dtype=float32),\n",
       "  'reward': 1.9134873964637915,\n",
       "  'newState': (array([-50.43620682, -16.93348217]), array([ 8, 31, 25])),\n",
       "  'info': {'type': array([ 8, 31, 25])}},\n",
       " {'iter': 4,\n",
       "  'episode': 35,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-11.842915, -11.637149],\n",
       "         [-16.537846,  -8.829135],\n",
       "         [ -8.164246, -14.337062]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([136.5450058 , 134.80334473]), array([34, 33, 32])),\n",
       "  'info': {'type': array([34, 33, 32])}},\n",
       " {'iter': 4,\n",
       "  'episode': 35,\n",
       "  'step': 1,\n",
       "  'oldState': (array([136.5450058 , 134.80334473]), array([34, 33, 32])),\n",
       "  'action': array([[134.38939 ,  47.601532],\n",
       "         [ 92.75024 , 103.04775 ],\n",
       "         [ 81.38316 , 117.53196 ]], dtype=float32),\n",
       "  'reward': 4.938976418337706,\n",
       "  'newState': (array([-171.97776031, -133.37789917]), array([44,  6,  5])),\n",
       "  'info': {'type': array([44,  6,  5])}},\n",
       " {'iter': 4,\n",
       "  'episode': 35,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-171.97776031, -133.37789917]), array([44,  6,  5])),\n",
       "  'action': array([[ -12.497396,  -91.57163 ],\n",
       "         [-125.049034, -112.82743 ],\n",
       "         [ -36.877163,  -89.33233 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  2.44583893, 160.35348511]), array([37, 30, 24])),\n",
       "  'info': {'type': array([37, 30, 24])}},\n",
       " {'iter': 4,\n",
       "  'episode': 36,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 82.550476,  94.32696 ],\n",
       "         [ 99.46223 , 132.56033 ],\n",
       "         [109.83869 ,  77.11779 ]], dtype=float32),\n",
       "  'reward': 4.736560193588457,\n",
       "  'newState': (array([-191.85137939, -204.00509644]), array([46, 20, 22])),\n",
       "  'info': {'type': array([46, 20, 22])}},\n",
       " {'iter': 4,\n",
       "  'episode': 36,\n",
       "  'step': 1,\n",
       "  'oldState': (array([-191.85137939, -204.00509644]), array([46, 20, 22])),\n",
       "  'action': array([[ -27.967846,  -89.55612 ],\n",
       "         [-164.54106 , -133.36063 ],\n",
       "         [-149.32033 , -188.78406 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([149.97784424, 207.69570923]), array([ 0,  5, 22])),\n",
       "  'info': {'type': array([ 0,  5, 22])}},\n",
       " {'iter': 4,\n",
       "  'episode': 36,\n",
       "  'step': 2,\n",
       "  'oldState': (array([149.97784424, 207.69570923]), array([ 0,  5, 22])),\n",
       "  'action': array([[176.82306 ,  11.19426 ],\n",
       "         [124.26919 ,  47.339943],\n",
       "         [ 52.88491 ,  71.87232 ]], dtype=float32),\n",
       "  'reward': 4.646922430300728,\n",
       "  'newState': (array([-203.99932861,   77.28918457]), array([27, 39, 37])),\n",
       "  'info': {'type': array([27, 39, 37])}},\n",
       " {'iter': 4,\n",
       "  'episode': 37,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ 7.6218596, 18.565166 ],\n",
       "         [25.108168 , 59.700966 ],\n",
       "         [28.863462 , 37.92664  ]], dtype=float32),\n",
       "  'reward': 3.3521337265477777,\n",
       "  'newState': (array([ 38.4065094 , -16.19276428]), array([25, 48, 36])),\n",
       "  'info': {'type': array([25, 48, 36])}},\n",
       " {'iter': 4,\n",
       "  'episode': 37,\n",
       "  'step': 1,\n",
       "  'oldState': (array([ 38.4065094 , -16.19276428]), array([25, 48, 36])),\n",
       "  'action': array([[ 4.995555,  5.995976],\n",
       "         [ 9.88698 , 18.699558],\n",
       "         [ 5.122021, 14.674251]], dtype=float32),\n",
       "  'reward': 2.644582370365736,\n",
       "  'newState': (array([ 18.40195274, -55.56254959]), array([ 0, 45, 38])),\n",
       "  'info': {'type': array([ 0, 45, 38])}},\n",
       " {'iter': 4,\n",
       "  'episode': 37,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ 18.40195274, -55.56254959]), array([ 0, 45, 38])),\n",
       "  'action': array([[13.740539 ,  7.8516192],\n",
       "         [12.230902 , 17.404148 ],\n",
       "         [ 1.4219922, 17.684132 ]], dtype=float32),\n",
       "  'reward': 2.8994243869476497,\n",
       "  'newState': (array([ -8.99147797, -98.50244904]), array([32,  5, 15])),\n",
       "  'info': {'type': array([32,  5, 15])}},\n",
       " {'iter': 4,\n",
       "  'episode': 38,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-5.704219 , -6.5798426],\n",
       "         [-6.803669 , -1.2373086],\n",
       "         [-3.6064696, -5.3379264]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([116.11435699, 113.15507698]), array([ 5, 33,  0])),\n",
       "  'info': {'type': array([ 5, 33,  0])}},\n",
       " {'iter': 4,\n",
       "  'episode': 38,\n",
       "  'step': 1,\n",
       "  'oldState': (array([116.11435699, 113.15507698]), array([ 5, 33,  0])),\n",
       "  'action': array([[ 42.912666 ,   3.4795656],\n",
       "         [ 23.198952 ,  41.222454 ],\n",
       "         [111.244576 ,   5.3162403]], dtype=float32),\n",
       "  'reward': 3.7242704681688377,\n",
       "  'newState': (array([-61.24184418,  63.13681984]), array([12, 16, 32])),\n",
       "  'info': {'type': array([12, 16, 32])}},\n",
       " {'iter': 4,\n",
       "  'episode': 38,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-61.24184418,  63.13681984]), array([12, 16, 32])),\n",
       "  'action': array([[ 0.25759473,  6.368943  ],\n",
       "         [16.736551  , 50.195377  ],\n",
       "         [56.594536  ,  5.7133074 ]], dtype=float32),\n",
       "  'reward': 2.9767524713448763,\n",
       "  'newState': (array([-134.83052826,    0.8591938 ]), array([33, 16, 41])),\n",
       "  'info': {'type': array([33, 16, 41])}},\n",
       " {'iter': 4,\n",
       "  'episode': 39,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.7860892 , 0.5816591 ],\n",
       "         [0.43007085, 0.1799661 ],\n",
       "         [0.2693737 , 0.12941107]], dtype=float32),\n",
       "  'reward': -1.1341756837765988,\n",
       "  'newState': (array([98.51446629, 99.10896373]), array([12, 21, 10])),\n",
       "  'info': {'type': array([12, 21, 10])}},\n",
       " {'iter': 4,\n",
       "  'episode': 39,\n",
       "  'step': 1,\n",
       "  'oldState': (array([98.51446629, 99.10896373]), array([12, 21, 10])),\n",
       "  'action': array([[12.346362 , 45.32542  ],\n",
       "         [ 5.8160534,  6.718253 ],\n",
       "         [68.159706 , 10.747259 ]], dtype=float32),\n",
       "  'reward': 2.647544745759476,\n",
       "  'newState': (array([12.19234562, 36.31803203]), array([17, 14,  7])),\n",
       "  'info': {'type': array([17, 14,  7])}},\n",
       " {'iter': 4,\n",
       "  'episode': 39,\n",
       "  'step': 2,\n",
       "  'oldState': (array([12.19234562, 36.31803203]), array([17, 14,  7])),\n",
       "  'action': array([[36.148354, 13.900627],\n",
       "         [21.507395,  9.361042],\n",
       "         [24.932789, 16.124445]], dtype=float32),\n",
       "  'reward': 3.113323570978646,\n",
       "  'newState': (array([-70.39618587,  -3.068084  ]), array([20, 29, 12])),\n",
       "  'info': {'type': array([20, 29, 12])}},\n",
       " {'iter': 4,\n",
       "  'episode': 40,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-2.6390114 , -1.5989517 ],\n",
       "         [-2.4596527 , -1.4933407 ],\n",
       "         [-0.22003263, -2.9533577 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([105.31869698, 106.04565001]), array([ 7,  6, 18])),\n",
       "  'info': {'type': array([ 7,  6, 18])}},\n",
       " {'iter': 4,\n",
       "  'episode': 40,\n",
       "  'step': 1,\n",
       "  'oldState': (array([105.31869698, 106.04565001]), array([ 7,  6, 18])),\n",
       "  'action': array([[87.861   , 25.1846  ],\n",
       "         [83.1497  , 43.8752  ],\n",
       "         [21.202581, 77.59345 ]], dtype=float32),\n",
       "  'reward': 4.409465214795331,\n",
       "  'newState': (array([-86.89457512, -40.60760927]), array([ 0, 42, 44])),\n",
       "  'info': {'type': array([ 0, 42, 44])}},\n",
       " {'iter': 4,\n",
       "  'episode': 40,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-86.89457512, -40.60760927]), array([ 0, 42, 44])),\n",
       "  'action': array([[-22.969261, -17.665134],\n",
       "         [-10.291992, -39.25048 ],\n",
       "         [-31.072363,  -6.046688]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-22.56095695,  22.35469389]), array([ 5, 11, 47])),\n",
       "  'info': {'type': array([ 5, 11, 47])}},\n",
       " {'iter': 4,\n",
       "  'episode': 41,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[11.647769  ,  0.89874107],\n",
       "         [12.9195795 ,  0.25983575],\n",
       "         [ 5.686197  , 17.402918  ]], dtype=float32),\n",
       "  'reward': 0.29711299195983626,\n",
       "  'newState': (array([69.74645424, 81.43850517]), array([24, 34, 14])),\n",
       "  'info': {'type': array([24, 34, 14])}},\n",
       " {'iter': 4,\n",
       "  'episode': 41,\n",
       "  'step': 1,\n",
       "  'oldState': (array([69.74645424, 81.43850517]), array([24, 34, 14])),\n",
       "  'action': array([[33.17239  , 25.773989 ],\n",
       "         [61.749844 ,  4.326277 ],\n",
       "         [71.76309  ,  7.6423445]], dtype=float32),\n",
       "  'reward': 2.709516857955578,\n",
       "  'newState': (array([-96.93887901,  43.69589424]), array([38, 24, 42])),\n",
       "  'info': {'type': array([38, 24, 42])}},\n",
       " {'iter': 4,\n",
       "  'episode': 41,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-96.93887901,  43.69589424]), array([38, 24, 42])),\n",
       "  'action': array([[25.586018 , 19.076395 ],\n",
       "         [42.706673 , 34.633186 ],\n",
       "         [ 8.4393015, 39.138275 ]], dtype=float32),\n",
       "  'reward': 3.5624272243105053,\n",
       "  'newState': (array([-173.67087364,  -49.15196037]), array([33, 24,  3])),\n",
       "  'info': {'type': array([33, 24,  3])}},\n",
       " {'iter': 4,\n",
       "  'episode': 42,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[ -5.693079,  -8.128342],\n",
       "         [-16.612148,  -8.491608],\n",
       "         [-29.63929 , -28.032219]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([151.94451904, 144.65216827]), array([41, 30, 39])),\n",
       "  'info': {'type': array([41, 30, 39])}},\n",
       " {'iter': 4,\n",
       "  'episode': 42,\n",
       "  'step': 1,\n",
       "  'oldState': (array([151.94451904, 144.65216827]), array([41, 30, 39])),\n",
       "  'action': array([[121.68174 ,  17.792286],\n",
       "         [ 67.018974,  45.861034],\n",
       "         [122.13543 , 123.385506]], dtype=float32),\n",
       "  'reward': 4.7841649845491885,\n",
       "  'newState': (array([-158.89163208,  -42.38665009]), array([22, 38, 41])),\n",
       "  'info': {'type': array([22, 38, 41])}},\n",
       " {'iter': 4,\n",
       "  'episode': 42,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-158.89163208,  -42.38665009]), array([22, 38, 41])),\n",
       "  'action': array([[-23.538025 , -16.756096 ],\n",
       "         [-34.651344 , -24.946117 ],\n",
       "         [ -7.8234377, -30.866894 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-92.87882233,  30.18245697]), array([32, 27, 27])),\n",
       "  'info': {'type': array([32, 27, 27])}},\n",
       " {'iter': 4,\n",
       "  'episode': 43,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[25.582993 ,  6.5192065],\n",
       "         [28.560518 , 23.627495 ],\n",
       "         [ 7.250384 , 13.580982 ]], dtype=float32),\n",
       "  'reward': 3.1835646237596027,\n",
       "  'newState': (array([38.6061058 , 56.27231598]), array([18, 33, 36])),\n",
       "  'info': {'type': array([18, 33, 36])}},\n",
       " {'iter': 4,\n",
       "  'episode': 43,\n",
       "  'step': 1,\n",
       "  'oldState': (array([38.6061058 , 56.27231598]), array([18, 33, 36])),\n",
       "  'action': array([[53.853992, 54.23373 ],\n",
       "         [51.296627, 42.053886],\n",
       "         [46.164577, 19.851816]], dtype=float32),\n",
       "  'reward': 3.976722976247266,\n",
       "  'newState': (array([-112.709095  ,  -59.86711121]), array([44,  6, 38])),\n",
       "  'info': {'type': array([44,  6, 38])}},\n",
       " {'iter': 4,\n",
       "  'episode': 43,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-112.709095  ,  -59.86711121]), array([44,  6, 38])),\n",
       "  'action': array([[-31.197863, -18.603655],\n",
       "         [-57.671753,  -6.890914],\n",
       "         [-32.658318, -28.580484]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 8.81883621, -5.79206085]), array([45, 48, 34])),\n",
       "  'info': {'type': array([45, 48, 34])}},\n",
       " {'iter': 4,\n",
       "  'episode': 44,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.5521816, 7.6628   ],\n",
       "         [6.0724874, 8.014525 ],\n",
       "         [3.944667 , 8.244158 ]], dtype=float32),\n",
       "  'reward': 1.1395965807022668,\n",
       "  'newState': (array([89.43066406, 76.07851791]), array([31, 47, 34])),\n",
       "  'info': {'type': array([31, 47, 34])}},\n",
       " {'iter': 4,\n",
       "  'episode': 44,\n",
       "  'step': 1,\n",
       "  'oldState': (array([89.43066406, 76.07851791]), array([31, 47, 34])),\n",
       "  'action': array([[18.045395, 60.539604],\n",
       "         [ 0.699621, 73.33513 ],\n",
       "         [84.315475, 12.025003]], dtype=float32),\n",
       "  'reward': 3.9897739772123684,\n",
       "  'newState': (array([-13.62982941, -69.82121658]), array([ 7, 42, 20])),\n",
       "  'info': {'type': array([ 7, 42, 20])}},\n",
       " {'iter': 4,\n",
       "  'episode': 44,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-13.62982941, -69.82121658]), array([ 7, 42, 20])),\n",
       "  'action': array([[ -4.7422304,  -5.530799 ],\n",
       "         [-11.770922 ,  -4.5619226],\n",
       "         [ -8.188143 , -12.504724 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([ 11.07146645, -47.22377014]), array([49, 26, 22])),\n",
       "  'info': {'type': array([49, 26, 22])}},\n",
       " {'iter': 4,\n",
       "  'episode': 45,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[10.086667  , 10.148442  ],\n",
       "         [ 9.800697  ,  0.03956252],\n",
       "         [ 2.023489  ,  1.3513192 ]], dtype=float32),\n",
       "  'reward': -0.9592262861488932,\n",
       "  'newState': (array([78.08914757, 88.46067619]), array([ 2, 41,  0])),\n",
       "  'info': {'type': array([ 2, 41,  0])}},\n",
       " {'iter': 4,\n",
       "  'episode': 45,\n",
       "  'step': 1,\n",
       "  'oldState': (array([78.08914757, 88.46067619]), array([ 2, 41,  0])),\n",
       "  'action': array([[ 9.190745 , 23.821049 ],\n",
       "         [ 1.6705645, 30.764233 ],\n",
       "         [74.68041  , 49.37356  ]], dtype=float32),\n",
       "  'reward': 3.370159448772278,\n",
       "  'newState': (array([ -7.45257759, -15.49817085]), array([28, 39,  5])),\n",
       "  'info': {'type': array([28, 39,  5])}},\n",
       " {'iter': 4,\n",
       "  'episode': 45,\n",
       "  'step': 2,\n",
       "  'oldState': (array([ -7.45257759, -15.49817085]), array([28, 39,  5])),\n",
       "  'action': array([[-2.9587593, -4.9051123],\n",
       "         [-4.556673 , -5.9588003],\n",
       "         [-0.9076204, -6.796989 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([0.9704752 , 2.16273117]), array([ 8,  9, 30])),\n",
       "  'info': {'type': array([ 8,  9, 30])}},\n",
       " {'iter': 4,\n",
       "  'episode': 46,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.80722606, 1.6048042 ],\n",
       "         [0.42961857, 0.28783983],\n",
       "         [1.3981811 , 0.846725  ]], dtype=float32),\n",
       "  'reward': -0.7488925313016407,\n",
       "  'newState': (array([97.36497426, 97.26063108]), array([33, 11, 34])),\n",
       "  'info': {'type': array([33, 11, 34])}},\n",
       " {'iter': 4,\n",
       "  'episode': 46,\n",
       "  'step': 1,\n",
       "  'oldState': (array([97.36497426, 97.26063108]), array([33, 11, 34])),\n",
       "  'action': array([[46.572712, 56.29412 ],\n",
       "         [13.851121, 31.522165],\n",
       "         [40.094257, 12.136743]], dtype=float32),\n",
       "  'reward': 3.8359497301542387,\n",
       "  'newState': (array([-3.15311503, -2.69239473]), array([40, 27, 12])),\n",
       "  'info': {'type': array([40, 27, 12])}},\n",
       " {'iter': 4,\n",
       "  'episode': 46,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-3.15311503, -2.69239473]), array([40, 27, 12])),\n",
       "  'action': array([[-1.6608175 , -1.5349381 ],\n",
       "         [-0.03506886, -1.9869735 ],\n",
       "         [-1.2844996 , -0.1170316 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([-0.17272902,  0.94654846]), array([23, 43, 40])),\n",
       "  'info': {'type': array([23, 43, 40])}},\n",
       " {'iter': 4,\n",
       "  'episode': 47,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.790869  , 0.6273741 ],\n",
       "         [0.5692451 , 0.47719383],\n",
       "         [0.02499775, 0.5112854 ]], dtype=float32),\n",
       "  'reward': -0.5501941403166613,\n",
       "  'newState': (array([98.61488819, 98.38414657]), array([ 2, 22, 18])),\n",
       "  'info': {'type': array([ 2, 22, 18])}},\n",
       " {'iter': 4,\n",
       "  'episode': 47,\n",
       "  'step': 1,\n",
       "  'oldState': (array([98.61488819, 98.38414657]), array([ 2, 22, 18])),\n",
       "  'action': array([[95.559845 , 35.89925  ],\n",
       "         [61.61559  , 51.791534 ],\n",
       "         [44.784298 ,  6.3745584]], dtype=float32),\n",
       "  'reward': 3.9711270043821765,\n",
       "  'newState': (array([-103.34484386,    4.31880844]), array([29, 41, 34])),\n",
       "  'info': {'type': array([29, 41, 34])}},\n",
       " {'iter': 4,\n",
       "  'episode': 47,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-103.34484386,    4.31880844]), array([29, 41, 34])),\n",
       "  'action': array([[1.3793675, 1.520983 ],\n",
       "         [3.2136884, 3.8531992],\n",
       "         [3.0423052, 0.2450001]], dtype=float32),\n",
       "  'reward': 1.010524029187891,\n",
       "  'newState': (array([-110.98020458,   -1.30037367]), array([47, 29, 31])),\n",
       "  'info': {'type': array([47, 29, 31])}},\n",
       " {'iter': 4,\n",
       "  'episode': 48,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[-1.2426779 , -0.6177772 ],\n",
       "         [-0.26198018, -0.23132576],\n",
       "         [-0.65614516, -0.7462392 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([102.16080332, 101.59534216]), array([34, 16, 49])),\n",
       "  'info': {'type': array([34, 16, 49])}},\n",
       " {'iter': 4,\n",
       "  'episode': 48,\n",
       "  'step': 1,\n",
       "  'oldState': (array([102.16080332, 101.59534216]), array([34, 16, 49])),\n",
       "  'action': array([[ 85.256874 ,  71.797905 ],\n",
       "         [ 51.246536 , 101.36269  ],\n",
       "         [ 47.49206  ,   5.6377416]], dtype=float32),\n",
       "  'reward': 4.239557403690211,\n",
       "  'newState': (array([-81.83468008, -77.20299768]), array([ 1, 11,  1])),\n",
       "  'info': {'type': array([ 1, 11,  1])}},\n",
       " {'iter': 4,\n",
       "  'episode': 48,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-81.83468008, -77.20299768]), array([ 1, 11,  1])),\n",
       "  'action': array([[-10.340883, -76.54902 ],\n",
       "         [-14.951757, -34.233986],\n",
       "         [-74.90237 , -54.991077]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([18.36032724, 88.57108068]), array([28, 49,  0])),\n",
       "  'info': {'type': array([28, 49,  0])}},\n",
       " {'iter': 4,\n",
       "  'episode': 49,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[28.04158 , 63.94623 ],\n",
       "         [17.793886, 40.724174],\n",
       "         [39.231194, 31.295656]], dtype=float32),\n",
       "  'reward': 3.605036992020224,\n",
       "  'newState': (array([ 14.93334198, -35.96606445]), array([11, 37, 14])),\n",
       "  'info': {'type': array([11, 37, 14])}},\n",
       " {'iter': 4,\n",
       "  'episode': 49,\n",
       "  'step': 1,\n",
       "  'oldState': (array([ 14.93334198, -35.96606445]), array([11, 37, 14])),\n",
       "  'action': array([[14.040387 ,  9.6993   ],\n",
       "         [ 7.377347 ,  9.615375 ],\n",
       "         [ 6.8090386,  8.217558 ]], dtype=float32),\n",
       "  'reward': 2.431342989738923,\n",
       "  'newState': (array([-13.29343033, -63.49829674]), array([43, 12, 48])),\n",
       "  'info': {'type': array([43, 12, 48])}},\n",
       " {'iter': 4,\n",
       "  'episode': 49,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-13.29343033, -63.49829674]), array([43, 12, 48])),\n",
       "  'action': array([[ -1.9146415,  -8.293039 ],\n",
       "         [ -9.726189 ,  -5.225964 ],\n",
       "         [ -3.201676 , -11.226345 ]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([  1.54907608, -38.75294876]), array([36, 49, 14])),\n",
       "  'info': {'type': array([36, 49, 14])}},\n",
       " {'iter': 4,\n",
       "  'episode': 50,\n",
       "  'step': 0,\n",
       "  'oldState': (array([100., 100.]), array([30, 48,  5])),\n",
       "  'action': array([[0.46441615, 0.63572717],\n",
       "         [0.03388336, 1.4022273 ],\n",
       "         [1.0254552 , 0.3192958 ]], dtype=float32),\n",
       "  'reward': -0.06387003325574532,\n",
       "  'newState': (array([98.47624528, 97.64274979]), array([ 9, 21, 32])),\n",
       "  'info': {'type': array([ 9, 21, 32])}},\n",
       " {'iter': 4,\n",
       "  'episode': 50,\n",
       "  'step': 1,\n",
       "  'oldState': (array([98.47624528, 97.64274979]), array([ 9, 21, 32])),\n",
       "  'action': array([[23.967028, 73.881516],\n",
       "         [16.564861, 56.812588],\n",
       "         [93.71301 , 56.001522]], dtype=float32),\n",
       "  'reward': 4.414587092341414,\n",
       "  'newState': (array([-35.76865828, -89.05288315]), array([ 7,  0, 46])),\n",
       "  'info': {'type': array([ 7,  0, 46])}},\n",
       " {'iter': 4,\n",
       "  'episode': 50,\n",
       "  'step': 2,\n",
       "  'oldState': (array([-35.76865828, -89.05288315]), array([ 7,  0, 46])),\n",
       "  'action': array([[-24.60668 , -23.275389],\n",
       "         [-29.398235, -35.54508 ],\n",
       "         [-29.659304, -30.029867]], dtype=float32),\n",
       "  'reward': nan,\n",
       "  'newState': (array([47.89555681, -0.20254898]), array([24, 16, 37])),\n",
       "  'info': {'type': array([24, 16, 37])}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hearing-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#    Figure how to go from dataframe of a trajectory to calculating the fairness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-preserve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-nudist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
